{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish a connection to the PostgreSQL database\n",
    "conn = psycopg2.connect(\n",
    "    dbname = \"dw_cs\", \n",
    "    user = \"postgres\", \n",
    "    host= 'localhost',\n",
    "    # host = '172.30.160.1',\n",
    "    password = \"postgres\",\n",
    "    port = 5432\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur.close()\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check the indexes on a table\n",
    "\n",
    "def check_indexes(table_name):\n",
    "\n",
    "    with conn.cursor() as cur:\n",
    "        query = f\"\"\"\n",
    "        SELECT\n",
    "            indexname,\n",
    "            indexdef\n",
    "        FROM\n",
    "            pg_indexes\n",
    "        WHERE\n",
    "            tablename = '{table_name}';\n",
    "        \"\"\"\n",
    "\n",
    "        cur.execute(query)      \n",
    "        \n",
    "        indexes = cur.fetchall()\n",
    "        \n",
    "        for index in indexes:\n",
    "            print(f\"Index Name: {index[0]}\")\n",
    "            print(f\"Index Definition: {index[1]}\\n\")\n",
    "\n",
    "\n",
    "# function to explain-analyze a query\n",
    "\n",
    "def explain_analyze(query, analyze = True):\n",
    "    conn.rollback()\n",
    "    with conn.cursor() as cur:\n",
    "        if analyze:\n",
    "            cur.execute(f\"EXPLAIN ANALYZE {query}\")\n",
    "        else:\n",
    "            cur.execute(f\"EXPLAIN {query}\")\n",
    "        explain = cur.fetchall()\n",
    "\n",
    "        for line in explain:\n",
    "            print(line[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First step\n",
    "Compute size and time for executing the queries without additional structure support. Record the size of the result set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the first value is the startup cost, the second the total cost.\n",
    "\n",
    "Startup Cost: This represents the amount of work the query planner estimates is required before the first row can be returned. For a sequential scan (Seq Scan), this value is typically very low or zero because the first row can be returned almost immediately.\n",
    "\n",
    "Total Cost: This represents the total estimated cost to execute the entire query. It is the sum of the startup cost and the cost to process all rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = on;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = off;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_tidscan = off;\")\n",
    "    cur.execute(\"SET enable_material = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = on;\")\n",
    "    cur.execute(\"SET enable_mergejoin = on;\")\n",
    "    cur.execute(\"SET enable_hashjoin = off;\")\n",
    "    cur.execute(\"SET enable_hashagg = on;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    cur.execute(\"SET enable_partition_pruning = off;\")\n",
    "    cur.execute(\"SET enable_partitionwise_join = off;\")\n",
    "    cur.execute(\"SET enable_partitionwise_aggregate = off;\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_1 = \"\"\"\n",
    "SELECT\n",
    "    l_returnflag,\n",
    "    l_linestatus,\n",
    "    SUM(l_quantity) AS sum_qty,\n",
    "    SUM(l_extendedprice) AS sum_base_price,\n",
    "    SUM(l_extendedprice * (1 - l_discount)) AS sum_disc_price,\n",
    "    SUM(l_extendedprice * (1 - l_discount) * (1 + l_tax)) AS sum_charge,\n",
    "    AVG(l_quantity) AS avg_qty,\n",
    "    AVG(l_extendedprice) AS avg_price,\n",
    "    AVG(l_discount) AS avg_disc,\n",
    "    COUNT(*) AS count_order\n",
    "FROM\n",
    "    lineitem\n",
    "WHERE\n",
    "    l_shipdate <= DATE '1998-12-01' - INTERVAL '90' DAY\n",
    "GROUP BY\n",
    "    l_returnflag,\n",
    "    l_linestatus\n",
    "ORDER BY\n",
    "    l_returnflag,\n",
    "    l_linestatus;\n",
    "\"\"\"\n",
    "\n",
    "query_10 = \"\"\"\n",
    "SELECT\n",
    "    c_custkey,\n",
    "    c_name,\n",
    "    SUM(l_extendedprice * (1 - l_discount)) AS revenue,\n",
    "    c_acctbal,\n",
    "    n_name,\n",
    "    c_address,\n",
    "    c_phone,\n",
    "    c_comment\n",
    "FROM\n",
    "    customer,\n",
    "    orders,\n",
    "    lineitem,\n",
    "    nation\n",
    "WHERE\n",
    "    c_custkey = o_custkey\n",
    "    AND l_orderkey = o_orderkey\n",
    "    AND o_orderdate >= DATE '1993-10-01'\n",
    "    AND o_orderdate < DATE '1993-10-01' + INTERVAL '3' MONTH\n",
    "    AND l_returnflag = 'R'\n",
    "    AND c_nationkey = n_nationkey\n",
    "GROUP BY\n",
    "    c_custkey,\n",
    "    c_name,\n",
    "    c_acctbal,\n",
    "    c_phone,\n",
    "    n_name,\n",
    "    c_address,\n",
    "    c_comment\n",
    "ORDER BY\n",
    "    revenue DESC;\n",
    "\"\"\"\n",
    "\n",
    "query_14 = \"\"\"\n",
    "SELECT\n",
    "    100.00 * SUM(CASE\n",
    "        WHEN p_type LIKE 'PROMO%'\n",
    "        THEN l_extendedprice * (1 - l_discount)\n",
    "        ELSE 0\n",
    "    END) / SUM(l_extendedprice * (1 - l_discount)) AS promo_revenue\n",
    "FROM\n",
    "    lineitem,\n",
    "    part\n",
    "WHERE\n",
    "    l_partkey = p_partkey\n",
    "    AND l_shipdate >= DATE '1995-09-01'\n",
    "    AND l_shipdate < DATE '1995-09-01' + INTERVAL '1' MONTH;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "query_17 = \"\"\"\n",
    "SELECT\n",
    "    SUM(l_extendedprice) / 7.0 AS avg_yearly\n",
    "FROM\n",
    "    lineitem,\n",
    "    part\n",
    "WHERE\n",
    "    l_partkey = p_partkey\n",
    "    AND p_brand = 'Brand#23'\n",
    "    AND p_container = 'MED BOX'\n",
    "    AND l_quantity < (\n",
    "        SELECT\n",
    "            0.2 * AVG(l_quantity)\n",
    "        FROM\n",
    "            lineitem\n",
    "        WHERE\n",
    "            p_partkey = l_partkey\n",
    "    );\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalize GroupAggregate  (cost=2300104.98..2300106.93 rows=6 width=236) (actual time=59925.710..59938.396 rows=4 loops=1)\n",
      "  Group Key: l_returnflag, l_linestatus\n",
      "  ->  Gather Merge  (cost=2300104.98..2300106.38 rows=12 width=236) (actual time=59925.686..59938.354 rows=12 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Sort  (cost=2299104.95..2299104.97 rows=6 width=236) (actual time=59910.550..59910.551 rows=4 loops=3)\n",
      "              Sort Key: l_returnflag, l_linestatus\n",
      "              Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 0:  Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 1:  Sort Method: quicksort  Memory: 27kB\n",
      "              ->  Partial HashAggregate  (cost=2299104.74..2299104.87 rows=6 width=236) (actual time=59910.509..59910.514 rows=4 loops=3)\n",
      "                    Group Key: l_returnflag, l_linestatus\n",
      "                    Batches: 1  Memory Usage: 24kB\n",
      "                    Worker 0:  Batches: 1  Memory Usage: 24kB\n",
      "                    Worker 1:  Batches: 1  Memory Usage: 24kB\n",
      "                    ->  Parallel Seq Scan on lineitem  (cost=0.00..1436970.35 rows=24632411 width=25) (actual time=0.686..46467.570 rows=19714203 loops=3)\n",
      "                          Filter: (l_shipdate <= '1998-09-02 00:00:00'::timestamp without time zone)\n",
      "                          Rows Removed by Filter: 281148\n",
      "Planning Time: 12.066 ms\n",
      "Execution Time: 59938.536 ms\n"
     ]
    }
   ],
   "source": [
    "explain_analyze(query_1, analyze = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort  (cost=3344325.21..3345720.08 rows=557947 width=279) (actual time=50605.739..50650.388 rows=381105 loops=1)\n",
      "  Sort Key: (sum((lineitem.l_extendedprice * ('1'::numeric - lineitem.l_discount)))) DESC\n",
      "  Sort Method: external merge  Disk: 71032kB\n",
      "  ->  GroupAggregate  (cost=2942891.02..3146127.82 rows=557947 width=279) (actual time=48503.664..50219.044 rows=381105 loops=1)\n",
      "        Group Key: customer.c_custkey, nation.n_name\n",
      "        ->  Incremental Sort  (cost=2942891.02..3132179.14 rows=557947 width=259) (actual time=48503.649..49758.638 rows=1147084 loops=1)\n",
      "              Sort Key: customer.c_custkey, nation.n_name\n",
      "              Presorted Key: customer.c_custkey\n",
      "              Full-sort Groups: 34124  Sort Method: quicksort  Average Memory: 31kB  Peak Memory: 31kB\n",
      "              ->  Nested Loop  (cost=2942890.72..3107071.53 rows=557947 width=259) (actual time=48503.588..49479.230 rows=1147084 loops=1)\n",
      "                    ->  Merge Join  (cost=2942890.57..3093377.71 rows=557947 width=159) (actual time=48502.880..49242.806 rows=1147084 loops=1)\n",
      "                          Merge Cond: (orders.o_custkey = customer.c_custkey)\n",
      "                          ->  Gather Merge  (cost=2942883.48..3007865.60 rows=557947 width=16) (actual time=48502.535..48621.037 rows=1147084 loops=1)\n",
      "                                Workers Planned: 2\n",
      "                                Workers Launched: 2\n",
      "                                ->  Sort  (cost=2941883.46..2942464.65 rows=232478 width=16) (actual time=48421.267..48445.093 rows=382361 loops=3)\n",
      "                                      Sort Key: orders.o_custkey\n",
      "                                      Sort Method: external merge  Disk: 10680kB\n",
      "                                      Worker 0:  Sort Method: external merge  Disk: 10088kB\n",
      "                                      Worker 1:  Sort Method: external merge  Disk: 10176kB\n",
      "                                      ->  Merge Join  (cost=2881503.92..2917185.84 rows=232478 width=16) (actual time=47582.734..48307.261 rows=382361 loops=3)\n",
      "                                            Merge Cond: (lineitem.l_orderkey = orders.o_orderkey)\n",
      "                                            ->  Sort  (cost=2333118.63..2348371.33 rows=6101082 width=16) (actual time=43977.010..44413.997 rows=4936061 loops=3)\n",
      "                                                  Sort Key: lineitem.l_orderkey\n",
      "                                                  Sort Method: external merge  Disk: 145000kB\n",
      "                                                  Worker 0:  Sort Method: external merge  Disk: 137200kB\n",
      "                                                  Worker 1:  Sort Method: external merge  Disk: 138376kB\n",
      "                                                  ->  Parallel Seq Scan on lineitem  (cost=0.00..1436970.35 rows=6101082 width=16) (actual time=2.251..40554.473 rows=4936061 loops=3)\n",
      "                                                        Filter: (l_returnflag = 'R'::bpchar)\n",
      "                                                        Rows Removed by Filter: 15059290\n",
      "                                            ->  Sort  (cost=548382.24..549811.16 rows=571566 width=8) (actual time=3605.659..3634.960 rows=573157 loops=3)\n",
      "                                                  Sort Key: orders.o_orderkey\n",
      "                                                  Sort Method: external merge  Disk: 10128kB\n",
      "                                                  Worker 0:  Sort Method: external merge  Disk: 10128kB\n",
      "                                                  Worker 1:  Sort Method: external merge  Disk: 10128kB\n",
      "                                                  ->  Seq Scan on orders  (cost=0.00..485912.00 rows=571566 width=8) (actual time=0.801..3389.869 rows=573157 loops=3)\n",
      "                                                        Filter: ((o_orderdate >= '1993-10-01'::date) AND (o_orderdate < '1994-01-01 00:00:00'::timestamp without time zone))\n",
      "                                                        Rows Removed by Filter: 14426843\n",
      "                          ->  Index Scan using customer_pkey on customer  (cost=0.43..74794.43 rows=1500000 width=147) (actual time=0.334..424.399 rows=1499998 loops=1)\n",
      "                    ->  Memoize  (cost=0.15..2.17 rows=1 width=108) (actual time=0.000..0.000 rows=1 loops=1147084)\n",
      "                          Cache Key: customer.c_nationkey\n",
      "                          Cache Mode: logical\n",
      "                          Hits: 1147059  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                          ->  Index Scan using nation_pkey on nation  (cost=0.14..2.16 rows=1 width=108) (actual time=0.028..0.028 rows=1 loops=25)\n",
      "                                Index Cond: (n_nationkey = customer.c_nationkey)\n",
      "Planning Time: 12.527 ms\n",
      "Execution Time: 50692.733 ms\n"
     ]
    }
   ],
   "source": [
    "explain_analyze(query_10, analyze = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate  (cost=1800922.34..1800922.35 rows=1 width=32) (actual time=38352.426..38352.462 rows=1 loops=1)\n",
      "  ->  Merge Join  (cost=1676444.04..1786617.50 rows=817419 width=33) (actual time=37591.652..38222.425 rows=749223 loops=1)\n",
      "        Merge Cond: (part.p_partkey = lineitem.l_partkey)\n",
      "        ->  Index Scan using part_pkey on part  (cost=0.43..92913.43 rows=2000000 width=25) (actual time=0.879..422.172 rows=1999994 loops=1)\n",
      "        ->  Sort  (cost=1676443.20..1678486.75 rows=817419 width=16) (actual time=37590.732..37626.491 rows=749223 loops=1)\n",
      "              Sort Key: lineitem.l_partkey\n",
      "              Sort Method: external sort  Disk: 24288kB\n",
      "              ->  Gather  (cost=1000.00..1582197.72 rows=817419 width=16) (actual time=1.168..36369.465 rows=749223 loops=1)\n",
      "                    Workers Planned: 2\n",
      "                    Workers Launched: 2\n",
      "                    ->  Parallel Seq Scan on lineitem  (cost=0.00..1499455.82 rows=340591 width=16) (actual time=1.262..36981.023 rows=249741 loops=3)\n",
      "                          Filter: ((l_shipdate >= '1995-09-01'::date) AND (l_shipdate < '1995-10-01 00:00:00'::timestamp without time zone))\n",
      "                          Rows Removed by Filter: 19745610\n",
      "Planning Time: 29.799 ms\n",
      "Execution Time: 38389.912 ms\n"
     ]
    }
   ],
   "source": [
    "explain_analyze(query_14, analyze = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set hashjoin and hashaggregate off, we only analyze the situation with indexes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to put an index on (l_returnflag, l_linestatus). since they do not have many distinct values: (3,2) respectively, we could use a bitmap index, but in postgre it is not implemented.\n",
    "\n",
    "Let's use btree, hash index cannot be done on a pair\n",
    "\n",
    "Maybe we can leverage bitmap scan.\n",
    "\n",
    "I tried to create an index on the pair (l_returnflag, l_linestatus) but it was not used by the optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if with an index on shipdate we get better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create index on lineitem: 49.96327495574951 seconds\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_l_shipdate ON lineitem (l_shipdate);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create index on lineitem: {end_time - start_time} seconds\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of idx_l_shipdate ON lineitem (l_shipdate): 397.546875 MB\n",
      "Size of idx_l_shipdate ON lineitem (l_shipdate): 0.3882293701171875 GB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "\n",
    "    cur.execute(\"SELECT pg_relation_size('idx_l_shipdate');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of idx_l_shipdate ON lineitem (l_shipdate): {index_size/(1024**2)} MB\")\n",
    "    print(f\"Size of idx_l_shipdate ON lineitem (l_shipdate): {index_size/(1024**3)} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalize GroupAggregate  (cost=2958736.61..2958738.57 rows=6 width=236) (actual time=35196.474..35199.506 rows=4 loops=1)\n",
      "  Group Key: l_returnflag, l_linestatus\n",
      "  ->  Gather Merge  (cost=2958736.61..2958738.01 rows=12 width=236) (actual time=35196.439..35199.444 rows=12 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Sort  (cost=2957736.59..2957736.60 rows=6 width=236) (actual time=35192.556..35192.557 rows=4 loops=3)\n",
      "              Sort Key: l_returnflag, l_linestatus\n",
      "              Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 0:  Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 1:  Sort Method: quicksort  Memory: 27kB\n",
      "              ->  Partial HashAggregate  (cost=2957736.37..2957736.51 rows=6 width=236) (actual time=35192.515..35192.523 rows=4 loops=3)\n",
      "                    Group Key: l_returnflag, l_linestatus\n",
      "                    Batches: 1  Memory Usage: 24kB\n",
      "                    Worker 0:  Batches: 1  Memory Usage: 24kB\n",
      "                    Worker 1:  Batches: 1  Memory Usage: 24kB\n",
      "                    ->  Parallel Bitmap Heap Scan on lineitem  (cost=658763.41..2095601.99 rows=24632411 width=25) (actual time=1104.605..11538.072 rows=19714203 loops=3)\n",
      "                          Recheck Cond: (l_shipdate <= '1998-09-02 00:00:00'::timestamp without time zone)\n",
      "                          Rows Removed by Index Recheck: 270333\n",
      "                          Heap Blocks: exact=11632 lossy=364768\n",
      "                          ->  Bitmap Index Scan on idx_l_shipdate  (cost=0.00..643983.96 rows=59117786 width=0) (actual time=1099.644..1099.644 rows=59142609 loops=1)\n",
      "                                Index Cond: (l_shipdate <= '1998-09-02 00:00:00'::timestamp without time zone)\n",
      "Planning Time: 12.236 ms\n",
      "Execution Time: 35200.202 ms\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = off;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_tidscan = off;\")\n",
    "    cur.execute(\"SET enable_material = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = off;\")\n",
    "    cur.execute(\"SET enable_mergejoin = off;\")\n",
    "    cur.execute(\"SET enable_hashjoin = on;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of the day, the index on (l_returnflag, l_linestatus) is not used for sorting nor grouping, so I would not use it. \n",
    "\n",
    "On the contrary we can see an improvement using an index on l_shipdate with a bitmapscan. if we used indexonlyscan we get worse results.\n",
    "\n",
    "What I would suggest is to keep the index on l_shipdate since it may help us also in query 14, even if it has low selectivity and probably it won't help much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate and record the size of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: \n",
      " ('A', 'F', Decimal('377518399'), Decimal('566065727797.25'), Decimal('537759104278.0656'), Decimal('559276670892.116819'), Decimal('25.5009751030070973'), Decimal('38237.151008958546'), Decimal('0.05000657454024320463'), 14804077)\n",
      "Size of query_1 result table: 0.015625 MB\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = off;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_tidscan = off;\")\n",
    "    cur.execute(\"SET enable_material = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = off;\")\n",
    "    cur.execute(\"SET enable_mergejoin = off;\")\n",
    "    cur.execute(\"SET enable_hashjoin = on;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    conn.commit()\n",
    "    \n",
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(f\"CREATE TEMP TABLE temp_result AS {query_1};\")\n",
    "    cur.execute(\"SELECT * FROM temp_result;\")\n",
    "    result = cur.fetchone()\n",
    "    print(f\"First row: \\n {result}\")\n",
    "    cur.execute(\"SELECT pg_total_relation_size('temp_result');\")\n",
    "    size = cur.fetchall()\n",
    "    print(f\"Size of query_1 result table: {size[0][0]/(1024**2)} MB\")\n",
    "    cur.execute(\"DROP TABLE temp_result;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SELECT pg_total_relation_size('lineitem');\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create gin index on lineitem (l_shipdate): 70.45620393753052 seconds\n"
     ]
    }
   ],
   "source": [
    "# l_shipdate has selectivity of 90/(6*12*365) = 0,003424657534 , so an index may be useful, \n",
    "# but since we have <=, an hash index can't be used. \n",
    "# we may use an inverted list\n",
    "\n",
    "# tried with btree_gin extension, but it gave worse results\n",
    "\n",
    "\"\"\"\n",
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"CREATE EXTENSION IF NOT EXISTS btree_gin;\")\n",
    "    cur.execute(\"CREATE INDEX idx_lineitem_shipdate ON lineitem USING gin (l_shipdate);\")\n",
    "\n",
    "\"\"\"\n",
    "# we may try to put an index also on (l_returnflag, l_linestatus) since they are used in the GROUP BY and ORDER BY clauses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Order_Date is quite selective 3 months / 7*12 months, so probably an index can be beneficial.\n",
    "\n",
    "ordering by revenue, which is computed in the query, can't be optimised.\n",
    "what can be optimised is the join.\n",
    "\n",
    "l_return flag is not selective, so we don't put an index on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create idx_o_orderdate ON orders (o_orderdate): 10.395975828170776 seconds\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_o_orderdate ON orders (o_orderdate);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create idx_o_orderdate ON orders (o_orderdate): {end_time - start_time} seconds\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort  (cost=10003291048.47..10003292443.34 rows=557947 width=279) (actual time=38244.429..38295.235 rows=381105 loops=1)\n",
      "  Sort Key: (sum((lineitem.l_extendedprice * ('1'::numeric - lineitem.l_discount)))) DESC\n",
      "  Sort Method: external merge  Disk: 71032kB\n",
      "  ->  Finalize GroupAggregate  (cost=10002923518.50..10003092851.07 rows=557947 width=279) (actual time=36721.926..37842.118 rows=381105 loops=1)\n",
      "        Group Key: customer.c_custkey, nation.n_name\n",
      "        ->  Gather Merge  (cost=10002923518.50..10003081227.18 rows=464956 width=279) (actual time=36721.920..37559.885 rows=450558 loops=1)\n",
      "              Workers Planned: 2\n",
      "              Workers Launched: 2\n",
      "              ->  Partial GroupAggregate  (cost=10002922518.47..10003026559.69 rows=232478 width=279) (actual time=36698.604..37499.219 rows=150186 loops=3)\n",
      "                    Group Key: customer.c_custkey, nation.n_name\n",
      "                    ->  Incremental Sort  (cost=10002922518.47..10003020747.74 rows=232478 width=259) (actual time=36698.590..37294.358 rows=382361 loops=3)\n",
      "                          Sort Key: customer.c_custkey, nation.n_name\n",
      "                          Presorted Key: customer.c_custkey\n",
      "                          Full-sort Groups: 11703  Sort Method: quicksort  Average Memory: 32kB  Peak Memory: 32kB\n",
      "                          Worker 0:  Full-sort Groups: 11506  Sort Method: quicksort  Average Memory: 32kB  Peak Memory: 32kB\n",
      "                          Worker 1:  Full-sort Groups: 11334  Sort Method: quicksort  Average Memory: 32kB  Peak Memory: 32kB\n",
      "                          ->  Nested Loop  (cost=10002922518.08..10003010286.23 rows=232478 width=259) (actual time=36698.379..37184.644 rows=382361 loops=3)\n",
      "                                ->  Merge Join  (cost=10002922517.94..10003004548.88 rows=232478 width=159) (actual time=36698.168..37085.031 rows=382361 loops=3)\n",
      "                                      Merge Cond: (orders.o_custkey = customer.c_custkey)\n",
      "                                      ->  Sort  (cost=10002922517.39..10002923098.59 rows=232478 width=16) (actual time=36697.349..36724.004 rows=382361 loops=3)\n",
      "                                            Sort Key: orders.o_custkey\n",
      "                                            Sort Method: external merge  Disk: 10480kB\n",
      "                                            Worker 0:  Sort Method: external merge  Disk: 10312kB\n",
      "                                            Worker 1:  Sort Method: external merge  Disk: 10152kB\n",
      "                                            ->  Merge Join  (cost=10002862137.86..10002897819.78 rows=232478 width=16) (actual time=35772.784..36572.511 rows=382361 loops=3)\n",
      "                                                  Merge Cond: (lineitem.l_orderkey = orders.o_orderkey)\n",
      "                                                  ->  Sort  (cost=10002333118.63..10002348371.33 rows=6101082 width=16) (actual time=28490.306..28921.857 rows=4936061 loops=3)\n",
      "                                                        Sort Key: lineitem.l_orderkey\n",
      "                                                        Sort Method: external merge  Disk: 142488kB\n",
      "                                                        Worker 0:  Sort Method: external merge  Disk: 139856kB\n",
      "                                                        Worker 1:  Sort Method: external merge  Disk: 138232kB\n",
      "                                                        ->  Parallel Seq Scan on lineitem  (cost=10000000000.00..10001436970.35 rows=6101082 width=16) (actual time=0.094..26341.979 rows=4936061 loops=3)\n",
      "                                                              Filter: (l_returnflag = 'R'::bpchar)\n",
      "                                                              Rows Removed by Filter: 15059290\n",
      "                                                  ->  Sort  (cost=529016.18..530445.09 rows=571566 width=8) (actual time=7282.401..7330.507 rows=573109 loops=3)\n",
      "                                                        Sort Key: orders.o_orderkey\n",
      "                                                        Sort Method: external merge  Disk: 10128kB\n",
      "                                                        Worker 0:  Sort Method: external merge  Disk: 10128kB\n",
      "                                                        Worker 1:  Sort Method: external merge  Disk: 10128kB\n",
      "                                                        ->  Bitmap Heap Scan on orders  (cost=7814.99..466545.94 rows=571566 width=8) (actual time=60.098..7095.973 rows=573157 loops=3)\n",
      "                                                              Recheck Cond: ((o_orderdate >= '1993-10-01'::date) AND (o_orderdate < '1994-01-01 00:00:00'::timestamp without time zone))\n",
      "                                                              Rows Removed by Index Recheck: 10885890\n",
      "                                                              Heap Blocks: exact=34987 lossy=198319\n",
      "                                                              ->  Bitmap Index Scan on idx_o_orderdate  (cost=0.00..7672.10 rows=571566 width=0) (actual time=53.583..53.583 rows=573157 loops=3)\n",
      "                                                                    Index Cond: ((o_orderdate >= '1993-10-01'::date) AND (o_orderdate < '1994-01-01 00:00:00'::timestamp without time zone))\n",
      "                                      ->  Index Scan using customer_pkey on customer  (cost=0.43..74794.43 rows=1500000 width=147) (actual time=0.799..229.340 rows=1499989 loops=3)\n",
      "                                ->  Memoize  (cost=0.15..2.17 rows=1 width=108) (actual time=0.000..0.000 rows=1 loops=1147084)\n",
      "                                      Cache Key: customer.c_nationkey\n",
      "                                      Cache Mode: logical\n",
      "                                      Hits: 388565  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                                      Worker 0:  Hits: 382208  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                                      Worker 1:  Hits: 376236  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                                      ->  Index Scan using nation_pkey on nation  (cost=0.14..2.16 rows=1 width=108) (actual time=0.008..0.008 rows=1 loops=75)\n",
      "                                            Index Cond: (n_nationkey = customer.c_nationkey)\n",
      "Planning Time: 6.962 ms\n",
      "Execution Time: 38337.595 ms\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = off;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_tidscan = off;\")\n",
    "    cur.execute(\"SET enable_material = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = on;\")\n",
    "    cur.execute(\"SET enable_mergejoin = on;\")\n",
    "    cur.execute(\"SET enable_hashjoin = off;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting to note that it leverages an index on l_returnflag because we have an index on (l_returnflag, l_linestatus). but it may be dropped, sooo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate and record the size of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: \n",
      " (1237537, 'Customer#001237537', Decimal('884989.6657'), Decimal('7840.17'), 'RUSSIA                   ', 'FNG6WgB1mopyyY,ajQTU qUPW5o', '32-367-120-4327', 'nag carefully about the regular packages. carefully reg')\n",
      "Size of query_10 result table: 78.5078125 MB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(f\"CREATE TEMP TABLE temp_result AS {query_10};\")\n",
    "    cur.execute(\"SELECT * FROM temp_result;\")\n",
    "    result = cur.fetchone()\n",
    "    print(f\"First row: \\n {result}\")\n",
    "    cur.execute(\"SELECT pg_total_relation_size('temp_result');\")\n",
    "    size = cur.fetchall()\n",
    "    print(f\"Size of query_10 result table: {size[0][0]/(1024**2)} MB\")\n",
    "    cur.execute(\"DROP TABLE temp_result;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shipdate is selective and we know that we have already an index on it, so we can leverage it \n",
    "\n",
    "we know we have a btree index in both l_partkey, p_partkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate  (cost=1752182.01..1752182.03 rows=1 width=32) (actual time=17888.858..17889.252 rows=1 loops=1)\n",
      "  ->  Merge Join  (cost=1627703.71..1737877.17 rows=817419 width=33) (actual time=17072.889..17683.330 rows=749223 loops=1)\n",
      "        Merge Cond: (part.p_partkey = lineitem.l_partkey)\n",
      "        ->  Index Scan using part_pkey on part  (cost=0.43..92913.43 rows=2000000 width=25) (actual time=0.154..317.587 rows=1999994 loops=1)\n",
      "        ->  Sort  (cost=1627702.87..1629746.42 rows=817419 width=16) (actual time=17072.726..17133.166 rows=749223 loops=1)\n",
      "              Sort Key: lineitem.l_partkey\n",
      "              Sort Method: external sort  Disk: 24288kB\n",
      "              ->  Gather  (cost=12155.11..1533457.40 rows=817419 width=16) (actual time=69.304..16334.072 rows=749223 loops=1)\n",
      "                    Workers Planned: 2\n",
      "                    Workers Launched: 2\n",
      "                    ->  Parallel Bitmap Heap Scan on lineitem  (cost=11155.11..1450715.50 rows=340591 width=16) (actual time=61.670..16657.261 rows=249741 loops=3)\n",
      "                          Recheck Cond: ((l_shipdate >= '1995-09-01'::date) AND (l_shipdate < '1995-10-01 00:00:00'::timestamp without time zone))\n",
      "                          Rows Removed by Index Recheck: 6279649\n",
      "                          Heap Blocks: exact=14401 lossy=118387\n",
      "                          ->  Bitmap Index Scan on idx_l_shipdate  (cost=0.00..10950.76 rows=817419 width=0) (actual time=60.057..60.057 rows=749223 loops=1)\n",
      "                                Index Cond: ((l_shipdate >= '1995-09-01'::date) AND (l_shipdate < '1995-10-01 00:00:00'::timestamp without time zone))\n",
      "Planning Time: 3.966 ms\n",
      "Execution Time: 17895.219 ms\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = on;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = on;\")\n",
    "    cur.execute(\"SET enable_mergejoin = on;\")\n",
    "    cur.execute(\"SET enable_hashjoin = off;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    cur.execute(\"SET enable_hashagg = on;\")\n",
    "    \n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using sort seems to improve the result of 5 seconds.\n",
    "\n",
    "bitmap scan improves of 9 seconds the time.\n",
    "\n",
    "as it is clear, the index on lineitem is not used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate and record size result table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: \n",
      " (Decimal('16.6475949416150953'),)\n",
      "Size of query_14 result table: 0.015625 MB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(f\"CREATE TEMP TABLE temp_result AS {query_14};\")\n",
    "    cur.execute(\"SELECT * FROM temp_result;\")\n",
    "    result = cur.fetchone()\n",
    "    print(f\"First row: \\n {result}\")\n",
    "    cur.execute(\"SELECT pg_total_relation_size('temp_result');\")\n",
    "    size = cur.fetchall()\n",
    "    print(f\"Size of query_14 result table: {size[0][0]/(1024**2)} MB\")\n",
    "    cur.execute(\"DROP TABLE temp_result;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This query takes a lot of time if we don't use indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index Name: idx_l_shipdate\n",
      "Index Definition: CREATE INDEX idx_l_shipdate ON public.lineitem USING btree (l_shipdate)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_indexes('lineitem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create idx_l_partkey ON lineitem (l_partkey): 53.212462186813354 seconds\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_l_partkey ON lineitem (l_partkey);\")    \n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create idx_l_partkey ON lineitem (l_partkey): {end_time - start_time} seconds\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that it is already a fast query, but we can try to put an index also on containier and brand to see if it speeds up the query. they have respectively 40 and 25 distinc values, so they are not that selective, but we can try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create index on lineitem: 55.932111978530884 seconds\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_p_brand ON part USING hash (p_brand);\")    \n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create index on part: {end_time - start_time} seconds\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create index on lineitem: 36.967782974243164 seconds\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_p_container ON part USING hash (p_container);\")    \n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create index on part: {end_time - start_time} seconds\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index Name: part_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX part_pkey ON public.part USING btree (p_partkey)\n",
      "\n",
      "Index Name: idx_p_brand\n",
      "Index Definition: CREATE INDEX idx_p_brand ON public.part USING hash (p_brand)\n",
      "\n",
      "Index Name: idx_p_container\n",
      "Index Definition: CREATE INDEX idx_p_container ON public.part USING hash (p_container)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_indexes(\"part\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate  (cost=9428617.44..9428617.45 rows=1 width=32) (actual time=13964.683..13964.684 rows=1 loops=1)\n",
      "  ->  Nested Loop  (cost=0.87..9428567.40 rows=20015 width=8) (actual time=16.833..13963.177 rows=5526 loops=1)\n",
      "        ->  Index Scan using part_pkey on part  (cost=0.43..102913.43 rows=2002 width=4) (actual time=1.922..402.807 rows=2044 loops=1)\n",
      "              Filter: ((p_brand = 'Brand#23'::bpchar) AND (p_container = 'MED BOX'::bpchar))\n",
      "              Rows Removed by Filter: 1997956\n",
      "        ->  Index Scan using idx_l_partkey on lineitem  (cost=0.44..4658.06 rows=11 width=17) (actual time=6.407..6.633 rows=3 loops=2044)\n",
      "              Index Cond: (l_partkey = part.p_partkey)\n",
      "              Filter: (l_quantity < (SubPlan 1))\n",
      "              Rows Removed by Filter: 27\n",
      "              SubPlan 1\n",
      "                ->  Aggregate  (cost=137.10..137.11 rows=1 width=32) (actual time=0.198..0.198 rows=1 loops=61385)\n",
      "                      ->  Index Scan using idx_l_partkey on lineitem lineitem_1  (cost=0.44..137.02 rows=33 width=5) (actual time=0.001..0.195 rows=31 loops=61385)\n",
      "                            Index Cond: (l_partkey = part.p_partkey)\n",
      "Planning Time: 41.941 ms\n",
      "Execution Time: 13964.764 ms\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = off;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = on;\")\n",
    "    cur.execute(\"SET enable_mergejoin = on;\")\n",
    "    cur.execute(\"SET enable_hashjoin = off;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    cur.execute(\"SET enable_hashagg = on;\")\n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_17, analyze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we get a small improvemtn, i don't think it is worth keeping those indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(f\"CREATE TEMP TABLE temp_result AS {query_17};\")\n",
    "    cur.execute(\"SELECT pg_total_relation_size('temp_result');\")\n",
    "    size = cur.fetchall()\n",
    "    print(f\"Size of query_17 result table: {size[0][0]/(1024**2)} MB\")\n",
    "    cur.execute(\"DROP TABLE temp_result;\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Part 2: Indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some useful commands:\n",
    "\n",
    "To create and index:\n",
    "\n",
    "default is b+tree\n",
    "CREATE INDEX idx_customer_name ON customer (c_name);\n",
    "\n",
    "available indexes:\n",
    "\n",
    "B-tree: The default and most common type of index.\n",
    "\n",
    "Hash: Used for equality comparisons.\n",
    "\n",
    "GIN (Generalized Inverted Index): Useful for indexing array values and full-text search.\n",
    "\n",
    "GiST (Generalized Search Tree): Supports many types of queries, including full-text search.\n",
    "\n",
    "SP-GiST (Space-Partitioned Generalized Search Tree): Useful for partitioning data.\n",
    "\n",
    "BRIN (Block Range INdexes): Efficient for large tables where the column values are correlated with their physical location.\n",
    "\n",
    "other possibilities:\n",
    "\n",
    "Partial Indexes\n",
    "Description: Indexes only a portion of a table, based on a condition.\n",
    "Use Case: When you frequently query a subset of rows.\n",
    "\n",
    "CREATE INDEX idx_active_customers ON customer (c_name) WHERE active = true;\n",
    "\n",
    "Expression Indexes\n",
    "Description: Indexes the result of an expression or function rather than a raw column.\n",
    "Use Case: When queries involve expressions or function calls.\n",
    "\n",
    "CREATE INDEX idx_lower_customer_name ON customer ((lower(c_name)));\n",
    "\n",
    "\n",
    "To disable the indexscan\n",
    "\n",
    "SET enable_seqscan = on;\n",
    "SET enable_indexscan = off;\n",
    "SET enable_bitmapscan = off;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create index on lineitem: 146.5280566215515 seconds\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_lineitem_partkey ON lineitem USING hash (l_partkey);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create index on lineitem: {end_time - start_time} seconds\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of index on lineitem: 1896.65625 MB\n",
      "Size of index on lineitem: 1.852203369140625 GB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "\n",
    "    cur.execute(\"SELECT pg_relation_size('idx_lineitem_partkey');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of index on lineitem: {index_size/(1024**2)} MB\")\n",
    "    print(f\"Size of index on lineitem: {index_size/(1024**3)} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPLAIN ANALYZE result:\n",
      "Aggregate  (cost=1937805.96..1937805.97 rows=1 width=32) (actual time=240896.545..240896.670 rows=1 loops=1)\n",
      "  ->  Hash Join  (cost=54683.72..1937756.72 rows=19695 width=8) (actual time=1156.271..240892.848 rows=5526 loops=1)\n",
      "        Hash Cond: (lineitem.l_partkey = part.p_partkey)\n",
      "        Join Filter: (lineitem.l_quantity < (SubPlan 1))\n",
      "        Rows Removed by Join Filter: 55859\n",
      "        ->  Seq Scan on lineitem  (cost=0.00..1724403.52 rows=59986052 width=17) (actual time=0.335..23018.323 rows=59986052 loops=1)\n",
      "        ->  Hash  (cost=54659.10..54659.10 rows=1970 width=4) (actual time=989.198..989.319 rows=2044 loops=1)\n",
      "              Buckets: 2048  Batches: 1  Memory Usage: 88kB\n",
      "              ->  Gather  (cost=1000.00..54659.10 rows=1970 width=4) (actual time=3.643..975.057 rows=2044 loops=1)\n",
      "                    Workers Planned: 2\n",
      "                    Workers Launched: 2\n",
      "                    ->  Parallel Seq Scan on part  (cost=0.00..53462.10 rows=821 width=4) (actual time=1.157..911.640 rows=681 loops=3)\n",
      "                          Filter: ((p_brand = 'Brand#23'::bpchar) AND (p_container = 'MED BOX'::bpchar))\n",
      "                          Rows Removed by Filter: 665985\n",
      "        SubPlan 1\n",
      "          ->  Aggregate  (cost=120.58..120.60 rows=1 width=32) (actual time=3.453..3.453 rows=1 loops=61385)\n",
      "                ->  Index Scan using idx_lineitem_partkey on lineitem lineitem_1  (cost=0.00..120.51 rows=29 width=5) (actual time=0.259..3.447 rows=31 loops=61385)\n",
      "                      Index Cond: (l_partkey = part.p_partkey)\n",
      "Planning Time: 13.348 ms\n",
      "Execution Time: 240897.794 ms\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(f\"EXPLAIN ANALYZE {query_17}\")\n",
    "    explain_result = cur.fetchall()\n",
    "    print(\"EXPLAIN ANALYZE result:\")\n",
    "    for row in explain_result:\n",
    "        print(row[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very good! A query that almost can't be executed now is completed in 4 minutes! But the cost is huge 1.85 GB ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: \n",
      " (Decimal('3295493.512857142857'),)\n",
      "Size of query_17 result table: 0.015625 MB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(f\"CREATE TEMP TABLE temp_result AS {query_17};\")\n",
    "    cur.execute(\"SELECT * FROM temp_result;\")\n",
    "    result = cur.fetchall()\n",
    "    for row in result:\n",
    "        print(row)\n",
    "\n",
    "    cur.execute(\"SELECT pg_total_relation_size('temp_result');\")\n",
    "    size = cur.fetchall()\n",
    "    print(f\"Size of query_17 result table: {size[0][0]/(1024**2)} MB\")\n",
    "    cur.execute(\"DROP TABLE temp_result;\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
