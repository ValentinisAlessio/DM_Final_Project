{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish a connection to the PostgreSQL database\n",
    "conn = psycopg2.connect(\n",
    "    dbname = \"dw_cs\", \n",
    "    user = \"postgres\", \n",
    "    host= 'localhost',\n",
    "    # host = '172.30.160.1',\n",
    "    password = \"postgres\",\n",
    "    port = 5432\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur.close()\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check the indexes on a table\n",
    "\n",
    "def check_indexes(table_name):\n",
    "\n",
    "    with conn.cursor() as cur:\n",
    "        query = f\"\"\"\n",
    "        SELECT\n",
    "            indexname,\n",
    "            indexdef\n",
    "        FROM\n",
    "            pg_indexes\n",
    "        WHERE\n",
    "            tablename = '{table_name}';\n",
    "        \"\"\"\n",
    "\n",
    "        cur.execute(query)      \n",
    "        \n",
    "        indexes = cur.fetchall()\n",
    "        \n",
    "        for index in indexes:\n",
    "            print(f\"Index Name: {index[0]}\")\n",
    "            print(f\"Index Definition: {index[1]}\\n\")\n",
    "\n",
    "\n",
    "# function to explain-analyze a query\n",
    "\n",
    "def explain_analyze(query, analyze = True):\n",
    "    conn.rollback()\n",
    "    with conn.cursor() as cur:\n",
    "        if analyze:\n",
    "            cur.execute(f\"EXPLAIN ANALYZE {query}\")\n",
    "        else:\n",
    "            cur.execute(f\"EXPLAIN {query}\")\n",
    "        explain = cur.fetchall()\n",
    "\n",
    "        for line in explain:\n",
    "            print(line[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First step\n",
    "Compute size and time for executing the queries without additional structure support. Record the size of the result set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the first value is the startup cost, the second the total cost.\n",
    "\n",
    "Startup Cost: This represents the amount of work the query planner estimates is required before the first row can be returned. For a sequential scan (Seq Scan), this value is typically very low or zero because the first row can be returned almost immediately.\n",
    "\n",
    "Total Cost: This represents the total estimated cost to execute the entire query. It is the sum of the startup cost and the cost to process all rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = on;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = off;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_tidscan = off;\")\n",
    "    cur.execute(\"SET enable_material = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = on;\")\n",
    "    cur.execute(\"SET enable_mergejoin = on;\")\n",
    "    cur.execute(\"SET enable_hashjoin = off;\")\n",
    "    cur.execute(\"SET enable_hashagg = on;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    cur.execute(\"SET enable_partition_pruning = off;\")\n",
    "    cur.execute(\"SET enable_partitionwise_join = off;\")\n",
    "    cur.execute(\"SET enable_partitionwise_aggregate = off;\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_1 = \"\"\"\n",
    "SELECT\n",
    "    l_returnflag,\n",
    "    l_linestatus,\n",
    "    SUM(l_quantity) AS sum_qty,\n",
    "    SUM(l_extendedprice) AS sum_base_price,\n",
    "    SUM(l_extendedprice * (1 - l_discount)) AS sum_disc_price,\n",
    "    SUM(l_extendedprice * (1 - l_discount) * (1 + l_tax)) AS sum_charge,\n",
    "    AVG(l_quantity) AS avg_qty,\n",
    "    AVG(l_extendedprice) AS avg_price,\n",
    "    AVG(l_discount) AS avg_disc,\n",
    "    COUNT(*) AS count_order\n",
    "FROM\n",
    "    lineitem\n",
    "WHERE\n",
    "    l_shipdate <= DATE '1998-12-01' - INTERVAL '90' DAY\n",
    "GROUP BY\n",
    "    l_returnflag,\n",
    "    l_linestatus\n",
    "ORDER BY\n",
    "    l_returnflag,\n",
    "    l_linestatus;\n",
    "\"\"\"\n",
    "\n",
    "query_10 = \"\"\"\n",
    "SELECT\n",
    "    c_custkey,\n",
    "    c_name,\n",
    "    SUM(l_extendedprice * (1 - l_discount)) AS revenue,\n",
    "    c_acctbal,\n",
    "    n_name,\n",
    "    c_address,\n",
    "    c_phone,\n",
    "    c_comment\n",
    "FROM\n",
    "    customer,\n",
    "    orders,\n",
    "    lineitem,\n",
    "    nation\n",
    "WHERE\n",
    "    c_custkey = o_custkey\n",
    "    AND l_orderkey = o_orderkey\n",
    "    AND o_orderdate >= DATE '1993-10-01'\n",
    "    AND o_orderdate < DATE '1993-10-01' + INTERVAL '3' MONTH\n",
    "    AND l_returnflag = 'R'\n",
    "    AND c_nationkey = n_nationkey\n",
    "GROUP BY\n",
    "    c_custkey,\n",
    "    c_name,\n",
    "    c_acctbal,\n",
    "    c_phone,\n",
    "    n_name,\n",
    "    c_address,\n",
    "    c_comment\n",
    "ORDER BY\n",
    "    revenue DESC;\n",
    "\"\"\"\n",
    "\n",
    "query_14 = \"\"\"\n",
    "SELECT\n",
    "    100.00 * SUM(CASE\n",
    "        WHEN p_type LIKE 'PROMO%'\n",
    "        THEN l_extendedprice * (1 - l_discount)\n",
    "        ELSE 0\n",
    "    END) / SUM(l_extendedprice * (1 - l_discount)) AS promo_revenue\n",
    "FROM\n",
    "    lineitem,\n",
    "    part\n",
    "WHERE\n",
    "    l_partkey = p_partkey\n",
    "    AND l_shipdate >= DATE '1995-09-01'\n",
    "    AND l_shipdate < DATE '1995-09-01' + INTERVAL '1' MONTH;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "query_17 = \"\"\"\n",
    "SELECT\n",
    "    SUM(l_extendedprice) / 7.0 AS avg_yearly\n",
    "FROM\n",
    "    lineitem,\n",
    "    part\n",
    "WHERE\n",
    "    l_partkey = p_partkey\n",
    "    AND p_brand = 'Brand#23'\n",
    "    AND p_container = 'MED BOX'\n",
    "    AND l_quantity < (\n",
    "        SELECT\n",
    "            0.2 * AVG(l_quantity)\n",
    "        FROM\n",
    "            lineitem\n",
    "        WHERE\n",
    "            p_partkey = l_partkey\n",
    "    );\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalize GroupAggregate  (cost=2300104.98..2300106.93 rows=6 width=236) (actual time=59925.710..59938.396 rows=4 loops=1)\n",
      "  Group Key: l_returnflag, l_linestatus\n",
      "  ->  Gather Merge  (cost=2300104.98..2300106.38 rows=12 width=236) (actual time=59925.686..59938.354 rows=12 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Sort  (cost=2299104.95..2299104.97 rows=6 width=236) (actual time=59910.550..59910.551 rows=4 loops=3)\n",
      "              Sort Key: l_returnflag, l_linestatus\n",
      "              Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 0:  Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 1:  Sort Method: quicksort  Memory: 27kB\n",
      "              ->  Partial HashAggregate  (cost=2299104.74..2299104.87 rows=6 width=236) (actual time=59910.509..59910.514 rows=4 loops=3)\n",
      "                    Group Key: l_returnflag, l_linestatus\n",
      "                    Batches: 1  Memory Usage: 24kB\n",
      "                    Worker 0:  Batches: 1  Memory Usage: 24kB\n",
      "                    Worker 1:  Batches: 1  Memory Usage: 24kB\n",
      "                    ->  Parallel Seq Scan on lineitem  (cost=0.00..1436970.35 rows=24632411 width=25) (actual time=0.686..46467.570 rows=19714203 loops=3)\n",
      "                          Filter: (l_shipdate <= '1998-09-02 00:00:00'::timestamp without time zone)\n",
      "                          Rows Removed by Filter: 281148\n",
      "Planning Time: 12.066 ms\n",
      "Execution Time: 59938.536 ms\n"
     ]
    }
   ],
   "source": [
    "explain_analyze(query_1, analyze = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort  (cost=3344325.21..3345720.08 rows=557947 width=279) (actual time=50605.739..50650.388 rows=381105 loops=1)\n",
      "  Sort Key: (sum((lineitem.l_extendedprice * ('1'::numeric - lineitem.l_discount)))) DESC\n",
      "  Sort Method: external merge  Disk: 71032kB\n",
      "  ->  GroupAggregate  (cost=2942891.02..3146127.82 rows=557947 width=279) (actual time=48503.664..50219.044 rows=381105 loops=1)\n",
      "        Group Key: customer.c_custkey, nation.n_name\n",
      "        ->  Incremental Sort  (cost=2942891.02..3132179.14 rows=557947 width=259) (actual time=48503.649..49758.638 rows=1147084 loops=1)\n",
      "              Sort Key: customer.c_custkey, nation.n_name\n",
      "              Presorted Key: customer.c_custkey\n",
      "              Full-sort Groups: 34124  Sort Method: quicksort  Average Memory: 31kB  Peak Memory: 31kB\n",
      "              ->  Nested Loop  (cost=2942890.72..3107071.53 rows=557947 width=259) (actual time=48503.588..49479.230 rows=1147084 loops=1)\n",
      "                    ->  Merge Join  (cost=2942890.57..3093377.71 rows=557947 width=159) (actual time=48502.880..49242.806 rows=1147084 loops=1)\n",
      "                          Merge Cond: (orders.o_custkey = customer.c_custkey)\n",
      "                          ->  Gather Merge  (cost=2942883.48..3007865.60 rows=557947 width=16) (actual time=48502.535..48621.037 rows=1147084 loops=1)\n",
      "                                Workers Planned: 2\n",
      "                                Workers Launched: 2\n",
      "                                ->  Sort  (cost=2941883.46..2942464.65 rows=232478 width=16) (actual time=48421.267..48445.093 rows=382361 loops=3)\n",
      "                                      Sort Key: orders.o_custkey\n",
      "                                      Sort Method: external merge  Disk: 10680kB\n",
      "                                      Worker 0:  Sort Method: external merge  Disk: 10088kB\n",
      "                                      Worker 1:  Sort Method: external merge  Disk: 10176kB\n",
      "                                      ->  Merge Join  (cost=2881503.92..2917185.84 rows=232478 width=16) (actual time=47582.734..48307.261 rows=382361 loops=3)\n",
      "                                            Merge Cond: (lineitem.l_orderkey = orders.o_orderkey)\n",
      "                                            ->  Sort  (cost=2333118.63..2348371.33 rows=6101082 width=16) (actual time=43977.010..44413.997 rows=4936061 loops=3)\n",
      "                                                  Sort Key: lineitem.l_orderkey\n",
      "                                                  Sort Method: external merge  Disk: 145000kB\n",
      "                                                  Worker 0:  Sort Method: external merge  Disk: 137200kB\n",
      "                                                  Worker 1:  Sort Method: external merge  Disk: 138376kB\n",
      "                                                  ->  Parallel Seq Scan on lineitem  (cost=0.00..1436970.35 rows=6101082 width=16) (actual time=2.251..40554.473 rows=4936061 loops=3)\n",
      "                                                        Filter: (l_returnflag = 'R'::bpchar)\n",
      "                                                        Rows Removed by Filter: 15059290\n",
      "                                            ->  Sort  (cost=548382.24..549811.16 rows=571566 width=8) (actual time=3605.659..3634.960 rows=573157 loops=3)\n",
      "                                                  Sort Key: orders.o_orderkey\n",
      "                                                  Sort Method: external merge  Disk: 10128kB\n",
      "                                                  Worker 0:  Sort Method: external merge  Disk: 10128kB\n",
      "                                                  Worker 1:  Sort Method: external merge  Disk: 10128kB\n",
      "                                                  ->  Seq Scan on orders  (cost=0.00..485912.00 rows=571566 width=8) (actual time=0.801..3389.869 rows=573157 loops=3)\n",
      "                                                        Filter: ((o_orderdate >= '1993-10-01'::date) AND (o_orderdate < '1994-01-01 00:00:00'::timestamp without time zone))\n",
      "                                                        Rows Removed by Filter: 14426843\n",
      "                          ->  Index Scan using customer_pkey on customer  (cost=0.43..74794.43 rows=1500000 width=147) (actual time=0.334..424.399 rows=1499998 loops=1)\n",
      "                    ->  Memoize  (cost=0.15..2.17 rows=1 width=108) (actual time=0.000..0.000 rows=1 loops=1147084)\n",
      "                          Cache Key: customer.c_nationkey\n",
      "                          Cache Mode: logical\n",
      "                          Hits: 1147059  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                          ->  Index Scan using nation_pkey on nation  (cost=0.14..2.16 rows=1 width=108) (actual time=0.028..0.028 rows=1 loops=25)\n",
      "                                Index Cond: (n_nationkey = customer.c_nationkey)\n",
      "Planning Time: 12.527 ms\n",
      "Execution Time: 50692.733 ms\n"
     ]
    }
   ],
   "source": [
    "explain_analyze(query_10, analyze = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate  (cost=1800922.34..1800922.35 rows=1 width=32) (actual time=38352.426..38352.462 rows=1 loops=1)\n",
      "  ->  Merge Join  (cost=1676444.04..1786617.50 rows=817419 width=33) (actual time=37591.652..38222.425 rows=749223 loops=1)\n",
      "        Merge Cond: (part.p_partkey = lineitem.l_partkey)\n",
      "        ->  Index Scan using part_pkey on part  (cost=0.43..92913.43 rows=2000000 width=25) (actual time=0.879..422.172 rows=1999994 loops=1)\n",
      "        ->  Sort  (cost=1676443.20..1678486.75 rows=817419 width=16) (actual time=37590.732..37626.491 rows=749223 loops=1)\n",
      "              Sort Key: lineitem.l_partkey\n",
      "              Sort Method: external sort  Disk: 24288kB\n",
      "              ->  Gather  (cost=1000.00..1582197.72 rows=817419 width=16) (actual time=1.168..36369.465 rows=749223 loops=1)\n",
      "                    Workers Planned: 2\n",
      "                    Workers Launched: 2\n",
      "                    ->  Parallel Seq Scan on lineitem  (cost=0.00..1499455.82 rows=340591 width=16) (actual time=1.262..36981.023 rows=249741 loops=3)\n",
      "                          Filter: ((l_shipdate >= '1995-09-01'::date) AND (l_shipdate < '1995-10-01 00:00:00'::timestamp without time zone))\n",
      "                          Rows Removed by Filter: 19745610\n",
      "Planning Time: 29.799 ms\n",
      "Execution Time: 38389.912 ms\n"
     ]
    }
   ],
   "source": [
    "explain_analyze(query_14, analyze = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set hashjoin and hashaggregate off, we only analyze the situation with indexes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to put an index on (l_returnflag, l_linestatus). since they do not have many distinct values: (3,2) respectively, we could use a bitmap index, but in postgre it is not implemented.\n",
    "\n",
    "Let's use btree, hash index cannot be done on a pair\n",
    "\n",
    "Maybe we can leverage bitmap scan.\n",
    "\n",
    "I tried to create an index on the pair (l_returnflag, l_linestatus) but it was not used by the optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if with an index on shipdate we get better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create index on lineitem: 49.96327495574951 seconds\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_l_shipdate ON lineitem (l_shipdate);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create index on lineitem: {end_time - start_time} seconds\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of idx_l_shipdate ON lineitem (l_shipdate): 397.546875 MB\n",
      "Size of idx_l_shipdate ON lineitem (l_shipdate): 0.3882293701171875 GB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "\n",
    "    cur.execute(\"SELECT pg_relation_size('idx_l_shipdate');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of idx_l_shipdate ON lineitem (l_shipdate): {index_size/(1024**2)} MB\")\n",
    "    print(f\"Size of idx_l_shipdate ON lineitem (l_shipdate): {index_size/(1024**3)} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalize GroupAggregate  (cost=2958736.61..2958738.57 rows=6 width=236) (actual time=35196.474..35199.506 rows=4 loops=1)\n",
      "  Group Key: l_returnflag, l_linestatus\n",
      "  ->  Gather Merge  (cost=2958736.61..2958738.01 rows=12 width=236) (actual time=35196.439..35199.444 rows=12 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Sort  (cost=2957736.59..2957736.60 rows=6 width=236) (actual time=35192.556..35192.557 rows=4 loops=3)\n",
      "              Sort Key: l_returnflag, l_linestatus\n",
      "              Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 0:  Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 1:  Sort Method: quicksort  Memory: 27kB\n",
      "              ->  Partial HashAggregate  (cost=2957736.37..2957736.51 rows=6 width=236) (actual time=35192.515..35192.523 rows=4 loops=3)\n",
      "                    Group Key: l_returnflag, l_linestatus\n",
      "                    Batches: 1  Memory Usage: 24kB\n",
      "                    Worker 0:  Batches: 1  Memory Usage: 24kB\n",
      "                    Worker 1:  Batches: 1  Memory Usage: 24kB\n",
      "                    ->  Parallel Bitmap Heap Scan on lineitem  (cost=658763.41..2095601.99 rows=24632411 width=25) (actual time=1104.605..11538.072 rows=19714203 loops=3)\n",
      "                          Recheck Cond: (l_shipdate <= '1998-09-02 00:00:00'::timestamp without time zone)\n",
      "                          Rows Removed by Index Recheck: 270333\n",
      "                          Heap Blocks: exact=11632 lossy=364768\n",
      "                          ->  Bitmap Index Scan on idx_l_shipdate  (cost=0.00..643983.96 rows=59117786 width=0) (actual time=1099.644..1099.644 rows=59142609 loops=1)\n",
      "                                Index Cond: (l_shipdate <= '1998-09-02 00:00:00'::timestamp without time zone)\n",
      "Planning Time: 12.236 ms\n",
      "Execution Time: 35200.202 ms\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = off;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_tidscan = off;\")\n",
    "    cur.execute(\"SET enable_material = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = off;\")\n",
    "    cur.execute(\"SET enable_mergejoin = off;\")\n",
    "    cur.execute(\"SET enable_hashjoin = on;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of the day, the index on (l_returnflag, l_linestatus) is not used for sorting nor grouping, so I would not use it. \n",
    "\n",
    "On the contrary we can see an improvement using an index on l_shipdate with a bitmapscan. if we used indexonlyscan we get worse results.\n",
    "\n",
    "What I would suggest is to keep the index on l_shipdate since it may help us also in query 14, even if it has low selectivity and probably it won't help much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate and record the size of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: \n",
      " ('A', 'F', Decimal('377518399'), Decimal('566065727797.25'), Decimal('537759104278.0656'), Decimal('559276670892.116819'), Decimal('25.5009751030070973'), Decimal('38237.151008958546'), Decimal('0.05000657454024320463'), 14804077)\n",
      "Size of query_1 result table: 0.015625 MB\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = off;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_tidscan = off;\")\n",
    "    cur.execute(\"SET enable_material = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = off;\")\n",
    "    cur.execute(\"SET enable_mergejoin = off;\")\n",
    "    cur.execute(\"SET enable_hashjoin = on;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    conn.commit()\n",
    "    \n",
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(f\"CREATE TEMP TABLE temp_result AS {query_1};\")\n",
    "    cur.execute(\"SELECT * FROM temp_result;\")\n",
    "    result = cur.fetchone()\n",
    "    print(f\"First row: \\n {result}\")\n",
    "    cur.execute(\"SELECT pg_total_relation_size('temp_result');\")\n",
    "    size = cur.fetchall()\n",
    "    print(f\"Size of query_1 result table: {size[0][0]/(1024**2)} MB\")\n",
    "    cur.execute(\"DROP TABLE temp_result;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SELECT pg_total_relation_size('lineitem');\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create gin index on lineitem (l_shipdate): 70.45620393753052 seconds\n"
     ]
    }
   ],
   "source": [
    "# l_shipdate has selectivity of 90/(6*12*365) = 0,003424657534 , so an index may be useful, \n",
    "# but since we have <=, an hash index can't be used. \n",
    "# we may use an inverted list\n",
    "\n",
    "# tried with btree_gin extension, but it gave worse results\n",
    "\n",
    "\"\"\"\n",
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"CREATE EXTENSION IF NOT EXISTS btree_gin;\")\n",
    "    cur.execute(\"CREATE INDEX idx_lineitem_shipdate ON lineitem USING gin (l_shipdate);\")\n",
    "\n",
    "\"\"\"\n",
    "# we may try to put an index also on (l_returnflag, l_linestatus) since they are used in the GROUP BY and ORDER BY clauses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Order_Date is quite selective 3 months / 7*12 months, so probably an index can be beneficial.\n",
    "\n",
    "ordering by revenue, which is computed in the query, can't be optimised.\n",
    "what can be optimised is the join.\n",
    "\n",
    "l_return flag is not selective, so we don't put an index on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create idx_o_orderdate ON orders (o_orderdate): 10.395975828170776 seconds\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_o_orderdate ON orders (o_orderdate);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create idx_o_orderdate ON orders (o_orderdate): {end_time - start_time} seconds\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort  (cost=10003291048.47..10003292443.34 rows=557947 width=279) (actual time=38244.429..38295.235 rows=381105 loops=1)\n",
      "  Sort Key: (sum((lineitem.l_extendedprice * ('1'::numeric - lineitem.l_discount)))) DESC\n",
      "  Sort Method: external merge  Disk: 71032kB\n",
      "  ->  Finalize GroupAggregate  (cost=10002923518.50..10003092851.07 rows=557947 width=279) (actual time=36721.926..37842.118 rows=381105 loops=1)\n",
      "        Group Key: customer.c_custkey, nation.n_name\n",
      "        ->  Gather Merge  (cost=10002923518.50..10003081227.18 rows=464956 width=279) (actual time=36721.920..37559.885 rows=450558 loops=1)\n",
      "              Workers Planned: 2\n",
      "              Workers Launched: 2\n",
      "              ->  Partial GroupAggregate  (cost=10002922518.47..10003026559.69 rows=232478 width=279) (actual time=36698.604..37499.219 rows=150186 loops=3)\n",
      "                    Group Key: customer.c_custkey, nation.n_name\n",
      "                    ->  Incremental Sort  (cost=10002922518.47..10003020747.74 rows=232478 width=259) (actual time=36698.590..37294.358 rows=382361 loops=3)\n",
      "                          Sort Key: customer.c_custkey, nation.n_name\n",
      "                          Presorted Key: customer.c_custkey\n",
      "                          Full-sort Groups: 11703  Sort Method: quicksort  Average Memory: 32kB  Peak Memory: 32kB\n",
      "                          Worker 0:  Full-sort Groups: 11506  Sort Method: quicksort  Average Memory: 32kB  Peak Memory: 32kB\n",
      "                          Worker 1:  Full-sort Groups: 11334  Sort Method: quicksort  Average Memory: 32kB  Peak Memory: 32kB\n",
      "                          ->  Nested Loop  (cost=10002922518.08..10003010286.23 rows=232478 width=259) (actual time=36698.379..37184.644 rows=382361 loops=3)\n",
      "                                ->  Merge Join  (cost=10002922517.94..10003004548.88 rows=232478 width=159) (actual time=36698.168..37085.031 rows=382361 loops=3)\n",
      "                                      Merge Cond: (orders.o_custkey = customer.c_custkey)\n",
      "                                      ->  Sort  (cost=10002922517.39..10002923098.59 rows=232478 width=16) (actual time=36697.349..36724.004 rows=382361 loops=3)\n",
      "                                            Sort Key: orders.o_custkey\n",
      "                                            Sort Method: external merge  Disk: 10480kB\n",
      "                                            Worker 0:  Sort Method: external merge  Disk: 10312kB\n",
      "                                            Worker 1:  Sort Method: external merge  Disk: 10152kB\n",
      "                                            ->  Merge Join  (cost=10002862137.86..10002897819.78 rows=232478 width=16) (actual time=35772.784..36572.511 rows=382361 loops=3)\n",
      "                                                  Merge Cond: (lineitem.l_orderkey = orders.o_orderkey)\n",
      "                                                  ->  Sort  (cost=10002333118.63..10002348371.33 rows=6101082 width=16) (actual time=28490.306..28921.857 rows=4936061 loops=3)\n",
      "                                                        Sort Key: lineitem.l_orderkey\n",
      "                                                        Sort Method: external merge  Disk: 142488kB\n",
      "                                                        Worker 0:  Sort Method: external merge  Disk: 139856kB\n",
      "                                                        Worker 1:  Sort Method: external merge  Disk: 138232kB\n",
      "                                                        ->  Parallel Seq Scan on lineitem  (cost=10000000000.00..10001436970.35 rows=6101082 width=16) (actual time=0.094..26341.979 rows=4936061 loops=3)\n",
      "                                                              Filter: (l_returnflag = 'R'::bpchar)\n",
      "                                                              Rows Removed by Filter: 15059290\n",
      "                                                  ->  Sort  (cost=529016.18..530445.09 rows=571566 width=8) (actual time=7282.401..7330.507 rows=573109 loops=3)\n",
      "                                                        Sort Key: orders.o_orderkey\n",
      "                                                        Sort Method: external merge  Disk: 10128kB\n",
      "                                                        Worker 0:  Sort Method: external merge  Disk: 10128kB\n",
      "                                                        Worker 1:  Sort Method: external merge  Disk: 10128kB\n",
      "                                                        ->  Bitmap Heap Scan on orders  (cost=7814.99..466545.94 rows=571566 width=8) (actual time=60.098..7095.973 rows=573157 loops=3)\n",
      "                                                              Recheck Cond: ((o_orderdate >= '1993-10-01'::date) AND (o_orderdate < '1994-01-01 00:00:00'::timestamp without time zone))\n",
      "                                                              Rows Removed by Index Recheck: 10885890\n",
      "                                                              Heap Blocks: exact=34987 lossy=198319\n",
      "                                                              ->  Bitmap Index Scan on idx_o_orderdate  (cost=0.00..7672.10 rows=571566 width=0) (actual time=53.583..53.583 rows=573157 loops=3)\n",
      "                                                                    Index Cond: ((o_orderdate >= '1993-10-01'::date) AND (o_orderdate < '1994-01-01 00:00:00'::timestamp without time zone))\n",
      "                                      ->  Index Scan using customer_pkey on customer  (cost=0.43..74794.43 rows=1500000 width=147) (actual time=0.799..229.340 rows=1499989 loops=3)\n",
      "                                ->  Memoize  (cost=0.15..2.17 rows=1 width=108) (actual time=0.000..0.000 rows=1 loops=1147084)\n",
      "                                      Cache Key: customer.c_nationkey\n",
      "                                      Cache Mode: logical\n",
      "                                      Hits: 388565  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                                      Worker 0:  Hits: 382208  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                                      Worker 1:  Hits: 376236  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                                      ->  Index Scan using nation_pkey on nation  (cost=0.14..2.16 rows=1 width=108) (actual time=0.008..0.008 rows=1 loops=75)\n",
      "                                            Index Cond: (n_nationkey = customer.c_nationkey)\n",
      "Planning Time: 6.962 ms\n",
      "Execution Time: 38337.595 ms\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = off;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_tidscan = off;\")\n",
    "    cur.execute(\"SET enable_material = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = on;\")\n",
    "    cur.execute(\"SET enable_mergejoin = on;\")\n",
    "    cur.execute(\"SET enable_hashjoin = off;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting to note that it leverages an index on l_returnflag because we have an index on (l_returnflag, l_linestatus). but it may be dropped, sooo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate and record the size of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: \n",
      " (1237537, 'Customer#001237537', Decimal('884989.6657'), Decimal('7840.17'), 'RUSSIA                   ', 'FNG6WgB1mopyyY,ajQTU qUPW5o', '32-367-120-4327', 'nag carefully about the regular packages. carefully reg')\n",
      "Size of query_10 result table: 78.5078125 MB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(f\"CREATE TEMP TABLE temp_result AS {query_10};\")\n",
    "    cur.execute(\"SELECT * FROM temp_result;\")\n",
    "    result = cur.fetchone()\n",
    "    print(f\"First row: \\n {result}\")\n",
    "    cur.execute(\"SELECT pg_total_relation_size('temp_result');\")\n",
    "    size = cur.fetchall()\n",
    "    print(f\"Size of query_10 result table: {size[0][0]/(1024**2)} MB\")\n",
    "    cur.execute(\"DROP TABLE temp_result;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shipdate is selective and we know that we have already an index on it, so we can leverage it \n",
    "\n",
    "we know we have a btree index in both l_partkey, p_partkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate  (cost=1752182.01..1752182.03 rows=1 width=32) (actual time=17888.858..17889.252 rows=1 loops=1)\n",
      "  ->  Merge Join  (cost=1627703.71..1737877.17 rows=817419 width=33) (actual time=17072.889..17683.330 rows=749223 loops=1)\n",
      "        Merge Cond: (part.p_partkey = lineitem.l_partkey)\n",
      "        ->  Index Scan using part_pkey on part  (cost=0.43..92913.43 rows=2000000 width=25) (actual time=0.154..317.587 rows=1999994 loops=1)\n",
      "        ->  Sort  (cost=1627702.87..1629746.42 rows=817419 width=16) (actual time=17072.726..17133.166 rows=749223 loops=1)\n",
      "              Sort Key: lineitem.l_partkey\n",
      "              Sort Method: external sort  Disk: 24288kB\n",
      "              ->  Gather  (cost=12155.11..1533457.40 rows=817419 width=16) (actual time=69.304..16334.072 rows=749223 loops=1)\n",
      "                    Workers Planned: 2\n",
      "                    Workers Launched: 2\n",
      "                    ->  Parallel Bitmap Heap Scan on lineitem  (cost=11155.11..1450715.50 rows=340591 width=16) (actual time=61.670..16657.261 rows=249741 loops=3)\n",
      "                          Recheck Cond: ((l_shipdate >= '1995-09-01'::date) AND (l_shipdate < '1995-10-01 00:00:00'::timestamp without time zone))\n",
      "                          Rows Removed by Index Recheck: 6279649\n",
      "                          Heap Blocks: exact=14401 lossy=118387\n",
      "                          ->  Bitmap Index Scan on idx_l_shipdate  (cost=0.00..10950.76 rows=817419 width=0) (actual time=60.057..60.057 rows=749223 loops=1)\n",
      "                                Index Cond: ((l_shipdate >= '1995-09-01'::date) AND (l_shipdate < '1995-10-01 00:00:00'::timestamp without time zone))\n",
      "Planning Time: 3.966 ms\n",
      "Execution Time: 17895.219 ms\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = on;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = on;\")\n",
    "    cur.execute(\"SET enable_mergejoin = on;\")\n",
    "    cur.execute(\"SET enable_hashjoin = off;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    cur.execute(\"SET enable_hashagg = on;\")\n",
    "    \n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using sort seems to improve the result of 5 seconds.\n",
    "\n",
    "bitmap scan improves of 9 seconds the time.\n",
    "\n",
    "as it is clear, the index on lineitem is not used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate and record size result table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: \n",
      " (Decimal('16.6475949416150953'),)\n",
      "Size of query_14 result table: 0.015625 MB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(f\"CREATE TEMP TABLE temp_result AS {query_14};\")\n",
    "    cur.execute(\"SELECT * FROM temp_result;\")\n",
    "    result = cur.fetchone()\n",
    "    print(f\"First row: \\n {result}\")\n",
    "    cur.execute(\"SELECT pg_total_relation_size('temp_result');\")\n",
    "    size = cur.fetchall()\n",
    "    print(f\"Size of query_14 result table: {size[0][0]/(1024**2)} MB\")\n",
    "    cur.execute(\"DROP TABLE temp_result;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This query takes a lot of time if we don't use indexes.\n",
    "\n",
    "we tried hash indexes on p_brand and p_container but they are not used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create idx_l_partkey ON lineitem (l_partkey): 53.212462186813354 seconds\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_l_partkey ON lineitem (l_partkey);\")    \n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create idx_l_partkey ON lineitem (l_partkey): {end_time - start_time} seconds\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of idx_l_partkey: 429.5078125 MB\n",
      "Size of idx_l_partkey: 0.41944122314453125 GB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "\n",
    "    cur.execute(\"SELECT pg_relation_size('idx_l_partkey');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of idx_l_partkey: {index_size/(1024**2)} MB\")\n",
    "    print(f\"Size of idx_l_partkey: {index_size/(1024**3)} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index Name: idx_l_shipdate\n",
      "Index Definition: CREATE INDEX idx_l_shipdate ON public.lineitem USING btree (l_shipdate)\n",
      "\n",
      "Index Name: idx_l_partkey\n",
      "Index Definition: CREATE INDEX idx_l_partkey ON public.lineitem USING btree (l_partkey)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_indexes('lineitem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate  (cost=9428617.44..9428617.45 rows=1 width=32) (actual time=11691.185..11691.187 rows=1 loops=1)\n",
      "  ->  Nested Loop  (cost=0.87..9428567.40 rows=20015 width=8) (actual time=11.018..11690.154 rows=5526 loops=1)\n",
      "        ->  Index Scan using part_pkey on part  (cost=0.43..102913.43 rows=2002 width=4) (actual time=3.143..473.433 rows=2044 loops=1)\n",
      "              Filter: ((p_brand = 'Brand#23'::bpchar) AND (p_container = 'MED BOX'::bpchar))\n",
      "              Rows Removed by Filter: 1997956\n",
      "        ->  Index Scan using idx_l_partkey on lineitem  (cost=0.44..4658.06 rows=11 width=17) (actual time=5.273..5.487 rows=3 loops=2044)\n",
      "              Index Cond: (l_partkey = part.p_partkey)\n",
      "              Filter: (l_quantity < (SubPlan 1))\n",
      "              Rows Removed by Filter: 27\n",
      "              SubPlan 1\n",
      "                ->  Aggregate  (cost=137.10..137.11 rows=1 width=32) (actual time=0.166..0.166 rows=1 loops=61385)\n",
      "                      ->  Index Scan using idx_l_partkey on lineitem lineitem_1  (cost=0.44..137.02 rows=33 width=5) (actual time=0.001..0.163 rows=31 loops=61385)\n",
      "                            Index Cond: (l_partkey = part.p_partkey)\n",
      "Planning Time: 8.700 ms\n",
      "Execution Time: 11692.246 ms\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = off;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = on;\")\n",
    "    cur.execute(\"SET enable_nestloop = on;\")\n",
    "    cur.execute(\"SET enable_mergejoin = on;\")\n",
    "    cur.execute(\"SET enable_hashjoin = off;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    cur.execute(\"SET enable_hashagg = on;\")\n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_17, analyze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Decimal('3295493.512857142857'),)\n",
      "Size of query_17 result table: 0.015625 MB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(f\"CREATE TEMP TABLE temp_result AS {query_17};\")\n",
    "    cur.execute(\"SELECT * FROM temp_result;\")\n",
    "    result = cur.fetchall()\n",
    "    for row in result:\n",
    "        print(row)\n",
    "\n",
    "    cur.execute(\"SELECT pg_total_relation_size('temp_result');\")\n",
    "    size = cur.fetchall()\n",
    "    print(f\"Size of query_17 result table: {size[0][0]/(1024**2)} MB\")\n",
    "    cur.execute(\"DROP TABLE temp_result;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final db size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database size: 39400.84 MB\n",
      "Database size: 38.48 GB \n",
      "\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    cur.execute(\"SELECT pg_database_size('dw_cs');\")\n",
    "    all_rows = cur.fetchall()\n",
    "    print(f\"Database size: {all_rows[0][0] / (1024**2):.2f} MB\")\n",
    "    print(f\"Database size: {all_rows[0][0] / (1024**3):.2f} GB \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
