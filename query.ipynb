{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish a connection to the PostgreSQL database\n",
    "conn = psycopg2.connect(\n",
    "    dbname = \"dw_cs\", \n",
    "    user = \"postgres\", \n",
    "    host= 'localhost',\n",
    "    password = \"Mu34zi72\",\n",
    "    port = 5432\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check the indexes on a table\n",
    "\n",
    "def check_indexes(table_name):\n",
    "\n",
    "    with conn.cursor() as cur:\n",
    "        query = f\"\"\"\n",
    "        SELECT\n",
    "            indexname,\n",
    "            indexdef\n",
    "        FROM\n",
    "            pg_indexes\n",
    "        WHERE\n",
    "            tablename = '{table_name}';\n",
    "        \"\"\"\n",
    "\n",
    "        cur.execute(query)      \n",
    "        \n",
    "        indexes = cur.fetchall()\n",
    "        \n",
    "        for index in indexes:\n",
    "            print(f\"Index Name: {index[0]}\")\n",
    "            print(f\"Index Definition: {index[1]}\\n\")\n",
    "\n",
    "\n",
    "# function to explain-analyze a query\n",
    "\n",
    "def explain_analyze(query, analyze = True):\n",
    "    conn.rollback()\n",
    "    with conn.cursor() as cur:\n",
    "        if analyze:\n",
    "            cur.execute(f\"EXPLAIN ANALYZE {query}\")\n",
    "        else:\n",
    "            cur.execute(f\"EXPLAIN {query}\")\n",
    "        explain = cur.fetchall()\n",
    "\n",
    "        for line in explain:\n",
    "            print(line[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First step\n",
    "Compute size and time for executing the queries without additional structure support. Record the size of the result set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the first value is the startup cost, the second the total cost.\n",
    "\n",
    "Startup Cost: This represents the amount of work the query planner estimates is required before the first row can be returned. For a sequential scan (Seq Scan), this value is typically very low or zero because the first row can be returned almost immediately.\n",
    "\n",
    "Total Cost: This represents the total estimated cost to execute the entire query. It is the sum of the startup cost and the cost to process all rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## how to compute the size needed to execute the query?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_1 = \"\"\"\n",
    "SELECT\n",
    "    l_returnflag,\n",
    "    l_linestatus,\n",
    "    SUM(l_quantity) AS sum_qty,\n",
    "    SUM(l_extendedprice) AS sum_base_price,\n",
    "    SUM(l_extendedprice * (1 - l_discount)) AS sum_disc_price,\n",
    "    SUM(l_extendedprice * (1 - l_discount) * (1 + l_tax)) AS sum_charge,\n",
    "    AVG(l_quantity) AS avg_qty,\n",
    "    AVG(l_extendedprice) AS avg_price,\n",
    "    AVG(l_discount) AS avg_disc,\n",
    "    COUNT(*) AS count_order\n",
    "FROM\n",
    "    lineitem\n",
    "WHERE\n",
    "    l_shipdate <= DATE '1998-12-01' - INTERVAL '90' DAY\n",
    "GROUP BY\n",
    "    l_returnflag,\n",
    "    l_linestatus\n",
    "ORDER BY\n",
    "    l_returnflag,\n",
    "    l_linestatus;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index Name: idx_lineitem_partkey\n",
      "Index Definition: CREATE INDEX idx_lineitem_partkey ON public.lineitem USING hash (l_partkey)\n",
      "\n",
      "Index Name: idx_l_returnflag_linestatus\n",
      "Index Definition: CREATE INDEX idx_l_returnflag_linestatus ON public.lineitem USING btree (l_returnflag, l_linestatus)\n",
      "\n",
      "Index Name: idx_l_shipdate\n",
      "Index Definition: CREATE INDEX idx_l_shipdate ON public.lineitem USING btree (l_shipdate)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_indexes(\"lineitem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroupAggregate  (cost=10013741365.72..10015956918.99 rows=6 width=236) (actual time=171347.799..250921.466 rows=4 loops=1)\n",
      "  Group Key: l_returnflag, l_linestatus\n",
      "  ->  Sort  (cost=10013741365.72..10013889069.26 rows=59081416 width=25) (actual time=140959.472..199267.461 rows=59142609 loops=1)\n",
      "        Sort Key: l_returnflag, l_linestatus\n",
      "        Sort Method: external merge  Disk: 2155328kB\n",
      "        ->  Seq Scan on lineitem  (cost=0.00..1874368.65 rows=59081416 width=25) (actual time=0.012..19020.892 rows=59142609 loops=1)\n",
      "              Filter: (l_shipdate <= '1998-09-02 00:00:00'::timestamp without time zone)\n",
      "              Rows Removed by Filter: 843443\n",
      "Planning Time: 41.538 ms\n",
      "Execution Time: 251002.274 ms\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = on;\")\n",
    "    cur.execute(\"SET enable_indexscan = off;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = off;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_tidscan = off;\")\n",
    "    cur.execute(\"SET enable_material = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = off;\")\n",
    "    cur.execute(\"SET enable_mergejoin = off;\")\n",
    "    cur.execute(\"SET enable_hashjoin = off;\")\n",
    "    cur.execute(\"SET enable_sort = off;\")\n",
    "    cur.execute(\"SET enable_partition_pruning = off;\")\n",
    "    cur.execute(\"SET enable_partitionwise_join = off;\")\n",
    "    cur.execute(\"SET enable_partitionwise_aggregate = off;\")\n",
    "    conn.commit()\n",
    "    \n",
    "explain_analyze(query_1, analyze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to put an index on (l_returnflag, l_linestatus). since they do not have many distinct values: (3,2) respectively, we could use a bitmap index, but in postgre it is not implemented.\n",
    "\n",
    "Let's use btree, hash index cannot be done on a pair\n",
    "\n",
    "Maybe we can leverage bitmap scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create index on lineitem: 92.10641407966614 seconds\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_l_returnflag_linestatus ON lineitem (l_returnflag, l_linestatus);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create index on lineitem (l_returnflag, l_linestatus): {end_time - start_time} seconds\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of gin index on lineitem (l_returnflag, l_linestatus): 396.4609375 MB\n",
      "Size of gin index on lineitem (l_returnflag, l_linestatus): 0.38716888427734375 GB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "\n",
    "    cur.execute(\"SELECT pg_relation_size('idx_l_returnflag_linestatus');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of btree index on lineitem (l_returnflag, l_linestatus): {index_size/(1024**2)} MB\")\n",
    "    print(f\"Size of btree index on lineitem (l_returnflag, l_linestatus): {index_size/(1024**3)} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to use sorting to see if something changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalize GroupAggregate  (cost=2299574.59..2299576.54 rows=6 width=236) (actual time=52812.051..52816.631 rows=4 loops=1)\n",
      "  Group Key: l_returnflag, l_linestatus\n",
      "  ->  Gather Merge  (cost=2299574.59..2299575.99 rows=12 width=236) (actual time=52812.004..52816.569 rows=12 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Sort  (cost=2298574.56..2298574.58 rows=6 width=236) (actual time=52787.017..52787.023 rows=4 loops=3)\n",
      "              Sort Key: l_returnflag, l_linestatus\n",
      "              Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 0:  Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 1:  Sort Method: quicksort  Memory: 27kB\n",
      "              ->  Partial HashAggregate  (cost=2298574.35..2298574.48 rows=6 width=236) (actual time=52786.945..52786.963 rows=4 loops=3)\n",
      "                    Group Key: l_returnflag, l_linestatus\n",
      "                    Batches: 1  Memory Usage: 24kB\n",
      "                    Worker 0:  Batches: 1  Memory Usage: 24kB\n",
      "                    Worker 1:  Batches: 1  Memory Usage: 24kB\n",
      "                    ->  Parallel Seq Scan on lineitem  (cost=0.00..1436970.35 rows=24617257 width=25) (actual time=0.404..17640.963 rows=19714203 loops=3)\n",
      "                          Filter: (l_shipdate <= '1998-09-02 00:00:00'::timestamp without time zone)\n",
      "                          Rows Removed by Filter: 281148\n",
      "Planning Time: 6.329 ms\n",
      "Execution Time: 52816.848 ms\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = on;\")\n",
    "    cur.execute(\"SET enable_indexscan = off;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = off;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_tidscan = off;\")\n",
    "    cur.execute(\"SET enable_material = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = off;\")\n",
    "    cur.execute(\"SET enable_mergejoin = off;\")\n",
    "    cur.execute(\"SET enable_hashjoin = off;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the optimizer chooses as best solution between indexes and sorting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalize GroupAggregate  (cost=2299574.59..2299576.54 rows=6 width=236) (actual time=51115.257..51120.039 rows=4 loops=1)\n",
      "  Group Key: l_returnflag, l_linestatus\n",
      "  ->  Gather Merge  (cost=2299574.59..2299575.99 rows=12 width=236) (actual time=51115.213..51119.986 rows=12 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Sort  (cost=2298574.56..2298574.58 rows=6 width=236) (actual time=51089.590..51089.595 rows=4 loops=3)\n",
      "              Sort Key: l_returnflag, l_linestatus\n",
      "              Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 0:  Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 1:  Sort Method: quicksort  Memory: 27kB\n",
      "              ->  Partial HashAggregate  (cost=2298574.35..2298574.48 rows=6 width=236) (actual time=51088.484..51088.493 rows=4 loops=3)\n",
      "                    Group Key: l_returnflag, l_linestatus\n",
      "                    Batches: 1  Memory Usage: 24kB\n",
      "                    Worker 0:  Batches: 1  Memory Usage: 24kB\n",
      "                    Worker 1:  Batches: 1  Memory Usage: 24kB\n",
      "                    ->  Parallel Seq Scan on lineitem  (cost=0.00..1436970.35 rows=24617257 width=25) (actual time=0.235..18607.306 rows=19714203 loops=3)\n",
      "                          Filter: (l_shipdate <= '1998-09-02 00:00:00'::timestamp without time zone)\n",
      "                          Rows Removed by Filter: 281148\n",
      "Planning Time: 3.924 ms\n",
      "Execution Time: 51132.621 ms\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = on;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_tidscan = off;\")\n",
    "    cur.execute(\"SET enable_material = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = off;\")\n",
    "    cur.execute(\"SET enable_mergejoin = off;\")\n",
    "    cur.execute(\"SET enable_hashjoin = off;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried to put an gin index, but it didn't work, so we use a btree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create index on lineitem: 50.624717712402344 seconds\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_l_shipdate ON lineitem (l_shipdate);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create index on lineitem: {end_time - start_time} seconds\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of btree index on lineitem (l_shipdate): 397.546875 MB\n",
      "Size of btree index on lineitem (l_shipdate): 0.3882293701171875 GB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "\n",
    "    cur.execute(\"SELECT pg_relation_size('idx_l_shipdate');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of btree index on lineitem (l_shipdate): {index_size/(1024**2)} MB\")\n",
    "    print(f\"Size of btree index on lineitem (l_shipdate): {index_size/(1024**3)} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index Name: idx_lineitem_partkey\n",
      "Index Definition: CREATE INDEX idx_lineitem_partkey ON public.lineitem USING hash (l_partkey)\n",
      "\n",
      "Index Name: idx_l_returnflag_linestatus\n",
      "Index Definition: CREATE INDEX idx_l_returnflag_linestatus ON public.lineitem USING btree (l_returnflag, l_linestatus)\n",
      "\n",
      "Index Name: idx_l_shipdate\n",
      "Index Definition: CREATE INDEX idx_l_shipdate ON public.lineitem USING btree (l_shipdate)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_indexes(\"lineitem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalize GroupAggregate  (cost=1000.59..124567743.23 rows=6 width=236) (actual time=152792.253..152792.768 rows=4 loops=1)\n",
      "  Group Key: l_returnflag, l_linestatus\n",
      "  ->  Gather Merge  (cost=1000.59..124567742.68 rows=12 width=236) (actual time=152695.591..152792.691 rows=10 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Partial GroupAggregate  (cost=0.56..124566741.27 rows=6 width=236) (actual time=34083.839..113101.988 rows=3 loops=3)\n",
      "              Group Key: l_returnflag, l_linestatus\n",
      "              ->  Parallel Index Scan using idx_l_returnflag_linestatus on lineitem  (cost=0.56..123705137.14 rows=24617257 width=25) (actual time=1.595..79126.510 rows=19714203 loops=3)\n",
      "                    Filter: (l_shipdate <= '1998-09-02 00:00:00'::timestamp without time zone)\n",
      "                    Rows Removed by Filter: 281148\n",
      "Planning Time: 40.747 ms\n",
      "Execution Time: 152813.249 ms\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = off;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_tidscan = off;\")\n",
    "    cur.execute(\"SET enable_material = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = off;\")\n",
    "    cur.execute(\"SET enable_mergejoin = off;\")\n",
    "    cur.execute(\"SET enable_hashjoin = off;\")\n",
    "    cur.execute(\"SET enable_sort = off;\")\n",
    "    conn.commit()\n",
    "\n",
    "    explain_analyze(query_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalize GroupAggregate  (cost=2957794.83..2957796.79 rows=6 width=236) (actual time=55547.882..55554.947 rows=4 loops=1)\n",
      "  Group Key: l_returnflag, l_linestatus\n",
      "  ->  Gather Merge  (cost=2957794.83..2957796.23 rows=12 width=236) (actual time=55547.840..55554.892 rows=12 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Sort  (cost=2956794.81..2956794.82 rows=6 width=236) (actual time=55522.050..55522.055 rows=4 loops=3)\n",
      "              Sort Key: l_returnflag, l_linestatus\n",
      "              Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 0:  Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 1:  Sort Method: quicksort  Memory: 27kB\n",
      "              ->  Partial HashAggregate  (cost=2956794.60..2956794.73 rows=6 width=236) (actual time=55521.108..55521.117 rows=4 loops=3)\n",
      "                    Group Key: l_returnflag, l_linestatus\n",
      "                    Batches: 1  Memory Usage: 24kB\n",
      "                    Worker 0:  Batches: 1  Memory Usage: 24kB\n",
      "                    Worker 1:  Batches: 1  Memory Usage: 24kB\n",
      "                    ->  Parallel Bitmap Heap Scan on lineitem  (cost=658357.54..2095190.60 rows=24617257 width=25) (actual time=2953.801..22561.959 rows=19714203 loops=3)\n",
      "                          Recheck Cond: (l_shipdate <= '1998-09-02 00:00:00'::timestamp without time zone)\n",
      "                          Rows Removed by Index Recheck: 270331\n",
      "                          Heap Blocks: exact=11626 lossy=365740\n",
      "                          ->  Bitmap Index Scan on idx_l_shipdate  (cost=0.00..643587.18 rows=59081416 width=0) (actual time=2950.022..2950.028 rows=59142609 loops=1)\n",
      "                                Index Cond: (l_shipdate <= '1998-09-02 00:00:00'::timestamp without time zone)\n",
      "Planning Time: 15.100 ms\n",
      "Execution Time: 55555.889 ms\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = off;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = on;\")\n",
    "    cur.execute(\"SET enable_tidscan = off;\")\n",
    "    cur.execute(\"SET enable_material = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = off;\")\n",
    "    cur.execute(\"SET enable_mergejoin = off;\")\n",
    "    cur.execute(\"SET enable_hashjoin = off;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    cur.execute(\"SET enable_hashagg = off;\")\n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of the day, the index on (l_returnflag, l_linestatus) is not used for sorting nor grouping, so I would not use it. \n",
    "\n",
    "On the contrary we can see an improvement using an index on l_shipdate with a bitmapscan. if we used indexonlyscan we get worse results.\n",
    "\n",
    "What I would suggest is to keep the index on l_shipdate since it may help us also in query 14, even if it has low selectivity and probably it won't help much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate and record the size of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: \n",
      " ('A', 'F', Decimal('377518399'), Decimal('566065727797.25'), Decimal('537759104278.0656'), Decimal('559276670892.116819'), Decimal('25.5009751030070973'), Decimal('38237.151008958546'), Decimal('0.05000657454024320463'), 14804077)\n",
      "Size of query_1 result table: 0.015625 MB\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = on;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_tidscan = off;\")\n",
    "    cur.execute(\"SET enable_material = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = off;\")\n",
    "    cur.execute(\"SET enable_mergejoin = off;\")\n",
    "    cur.execute(\"SET enable_hashjoin = off;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    cur.execute(\"SET enable_hashagg = off;\")\n",
    "    conn.commit()\n",
    "    \n",
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(f\"CREATE TEMP TABLE temp_result AS {query_1};\")\n",
    "    cur.execute(\"SELECT * FROM temp_result;\")\n",
    "    result = cur.fetchone()\n",
    "    print(f\"First row: \\n {result}\")\n",
    "    cur.execute(\"SELECT pg_total_relation_size('temp_result');\")\n",
    "    size = cur.fetchall()\n",
    "    print(f\"Size of query_1 result table: {size[0][0]/(1024**2)} MB\")\n",
    "    cur.execute(\"DROP TABLE temp_result;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize\n",
    "\n",
    "the condition on l_shipdate is not selective, infact it is not used.\n",
    "\n",
    "We can divide the optimisation strategy in 2 groups: one using hashaggregate and one using an index on (returnstatus, linestatus).\n",
    "\n",
    "in the first case the index on (returnstatus, linestatus) is not used, we saw this is the best strategy. \n",
    "\n",
    "we also tried to put an index on shipdate but the condition is not selective and the sequantial scan performs even better.\n",
    "\n",
    "if we want to work with indexes, we can see that the time is reduced by 2, and an index is used for the group by."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_10 = \"\"\"\n",
    "SELECT\n",
    "    c_custkey,\n",
    "    c_name,\n",
    "    SUM(l_extendedprice * (1 - l_discount)) AS revenue,\n",
    "    c_acctbal,\n",
    "    n_name,\n",
    "    c_address,\n",
    "    c_phone,\n",
    "    c_comment\n",
    "FROM\n",
    "    customer,\n",
    "    orders,\n",
    "    lineitem,\n",
    "    nation\n",
    "WHERE\n",
    "    c_custkey = o_custkey\n",
    "    AND l_orderkey = o_orderkey\n",
    "    AND o_orderdate >= DATE '1993-10-01'\n",
    "    AND o_orderdate < DATE '1993-10-01' + INTERVAL '3' MONTH\n",
    "    AND l_returnflag = 'R'\n",
    "    AND c_nationkey = n_nationkey\n",
    "GROUP BY\n",
    "    c_custkey,\n",
    "    c_name,\n",
    "    c_acctbal,\n",
    "    c_phone,\n",
    "    n_name,\n",
    "    c_address,\n",
    "    c_comment\n",
    "ORDER BY\n",
    "    revenue DESC;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_indexes(\"customer\")\n",
    "check_indexes(\"lineitem\")\n",
    "check_indexes(\"orders\")\n",
    "check_indexes(\"nation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Order_Date is quite selective, so probably an index may be beneficial.\n",
    "ordering by revenue, which is computed in the query, can't be optimised.\n",
    "what can be optimised is the join.\n",
    "we have an index on c_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = on;\")\n",
    "    cur.execute(\"SET enable_indexscan = off;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = off;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_tidscan = off;\")\n",
    "    cur.execute(\"SET enable_material = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = off;\")\n",
    "    cur.execute(\"SET enable_mergejoin = on;\")\n",
    "    cur.execute(\"SET enable_hashjoin = off;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort  (cost=3775904.16..3777256.44 rows=540913 width=279) (actual time=77150.017..78300.537 rows=381105 loops=1)\n",
      "  Sort Key: (sum((lineitem.l_extendedprice * ('1'::numeric - lineitem.l_discount)))) DESC\n",
      "  Sort Method: external merge  Disk: 71032kB\n",
      "  ->  Finalize GroupAggregate  (cost=3514388.77..3583884.62 rows=540913 width=279) (actual time=71456.506..75623.581 rows=381105 loops=1)\n",
      "        Group Key: customer.c_custkey, nation.n_name\n",
      "        ->  Gather Merge  (cost=3514388.77..3572615.61 rows=450760 width=279) (actual time=71456.489..75323.124 rows=450437 loops=1)\n",
      "              Workers Planned: 2\n",
      "              Workers Launched: 2\n",
      "              ->  Partial GroupAggregate  (cost=3513388.75..3519586.70 rows=225380 width=279) (actual time=70271.250..71925.440 rows=150146 loops=3)\n",
      "                    Group Key: customer.c_custkey, nation.n_name\n",
      "                    ->  Sort  (cost=3513388.75..3513952.20 rows=225380 width=259) (actual time=70271.207..71696.587 rows=382361 loops=3)\n",
      "                          Sort Key: customer.c_custkey, nation.n_name\n",
      "                          Sort Method: external merge  Disk: 73256kB\n",
      "                          Worker 0:  Sort Method: external merge  Disk: 72632kB\n",
      "                          Worker 1:  Sort Method: external merge  Disk: 73128kB\n",
      "                          ->  Merge Join  (cost=3434500.66..3437882.21 rows=225380 width=259) (actual time=67916.405..69101.291 rows=382361 loops=3)\n",
      "                                Merge Cond: (customer.c_nationkey = nation.n_nationkey)\n",
      "                                ->  Sort  (cost=3434482.66..3435046.11 rows=225380 width=159) (actual time=67911.815..69036.633 rows=382361 loops=3)\n",
      "                                      Sort Key: customer.c_nationkey\n",
      "                                      Sort Method: external merge  Disk: 65512kB\n",
      "                                      Worker 0:  Sort Method: external merge  Disk: 64968kB\n",
      "                                      Worker 1:  Sort Method: external merge  Disk: 65424kB\n",
      "                                      ->  Merge Join  (cost=3385842.94..3396723.63 rows=225380 width=159) (actual time=65223.876..66679.592 rows=382361 loops=3)\n",
      "                                            Merge Cond: (orders.o_custkey = customer.c_custkey)\n",
      "                                            ->  Sort  (cost=2955540.57..2956104.02 rows=225380 width=16) (actual time=58743.801..59076.106 rows=382361 loops=3)\n",
      "                                                  Sort Key: orders.o_custkey\n",
      "                                                  Sort Method: external merge  Disk: 10344kB\n",
      "                                                  Worker 0:  Sort Method: external merge  Disk: 10264kB\n",
      "                                                  Worker 1:  Sort Method: external merge  Disk: 10336kB\n",
      "                                                  ->  Merge Join  (cost=2895610.27..2931648.53 rows=225380 width=16) (actual time=56504.648..58347.112 rows=382361 loops=3)\n",
      "                                                        Merge Cond: (lineitem.l_orderkey = orders.o_orderkey)\n",
      "                                                        ->  Sort  (cost=2350456.44..2365990.33 rows=6213555 width=16) (actual time=45748.205..46747.279 rows=4936061 loops=3)\n",
      "                                                              Sort Key: lineitem.l_orderkey\n",
      "                                                              Sort Method: external merge  Disk: 140256kB\n",
      "                                                              Worker 0:  Sort Method: external merge  Disk: 139984kB\n",
      "                                                              Worker 1:  Sort Method: external merge  Disk: 140296kB\n",
      "                                                              ->  Parallel Seq Scan on lineitem  (cost=0.00..1436970.35 rows=6213555 width=16) (actual time=0.505..40072.177 rows=4936061 loops=3)\n",
      "                                                                    Filter: (l_returnflag = 'R'::bpchar)\n",
      "                                                                    Rows Removed by Filter: 15059290\n",
      "                                                        ->  Sort  (cost=545150.72..546510.76 rows=544016 width=8) (actual time=10756.344..10924.081 rows=573105 loops=3)\n",
      "                                                              Sort Key: orders.o_orderkey\n",
      "                                                              Sort Method: external merge  Disk: 10128kB\n",
      "                                                              Worker 0:  Sort Method: external merge  Disk: 10128kB\n",
      "                                                              Worker 1:  Sort Method: external merge  Disk: 10128kB\n",
      "                                                              ->  Seq Scan on orders  (cost=0.00..485883.24 rows=544016 width=8) (actual time=1.424..10193.516 rows=573157 loops=3)\n",
      "                                                                    Filter: ((o_orderdate >= '1993-10-01'::date) AND (o_orderdate < '1994-01-01 00:00:00'::timestamp without time zone))\n",
      "                                                                    Rows Removed by Filter: 14426843\n",
      "                                            ->  Sort  (cost=430302.25..434052.36 rows=1500044 width=147) (actual time=6480.031..7472.874 rows=1499986 loops=3)\n",
      "                                                  Sort Key: customer.c_custkey\n",
      "                                                  Sort Method: external merge  Disk: 236328kB\n",
      "                                                  Worker 0:  Sort Method: external merge  Disk: 236328kB\n",
      "                                                  Worker 1:  Sort Method: external merge  Disk: 236312kB\n",
      "                                                  ->  Seq Scan on customer  (cost=0.00..50827.44 rows=1500044 width=147) (actual time=0.953..2317.136 rows=1500000 loops=3)\n",
      "                                ->  Sort  (cost=18.00..18.42 rows=170 width=108) (actual time=1.114..1.122 rows=25 loops=3)\n",
      "                                      Sort Key: nation.n_nationkey\n",
      "                                      Sort Method: quicksort  Memory: 26kB\n",
      "                                      Worker 0:  Sort Method: quicksort  Memory: 26kB\n",
      "                                      Worker 1:  Sort Method: quicksort  Memory: 26kB\n",
      "                                      ->  Seq Scan on nation  (cost=0.00..11.70 rows=170 width=108) (actual time=1.085..1.087 rows=25 loops=3)\n",
      "Planning Time: 116.130 ms\n",
      "Execution Time: 78346.890 ms\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = on;\")\n",
    "    cur.execute(\"SET enable_indexscan = off;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = off;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_tidscan = off;\")\n",
    "    cur.execute(\"SET enable_material = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = off;\")\n",
    "    cur.execute(\"SET enable_mergejoin = on;\")\n",
    "    cur.execute(\"SET enable_hashjoin = off;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort  (cost=3775904.16..3777256.44 rows=540913 width=279) (actual time=47746.573..47825.689 rows=381105 loops=1)\n",
      "  Sort Key: (sum((lineitem.l_extendedprice * ('1'::numeric - lineitem.l_discount)))) DESC\n",
      "  Sort Method: external merge  Disk: 71032kB\n",
      "  ->  Finalize GroupAggregate  (cost=3514388.77..3583884.62 rows=540913 width=279) (actual time=46125.765..47087.550 rows=381105 loops=1)\n",
      "        Group Key: customer.c_custkey, nation.n_name\n",
      "        ->  Gather Merge  (cost=3514388.77..3572615.61 rows=450760 width=279) (actual time=46125.688..46642.507 rows=450378 loops=1)\n",
      "              Workers Planned: 2\n",
      "              Workers Launched: 2\n",
      "              ->  Partial GroupAggregate  (cost=3513388.75..3519586.70 rows=225380 width=279) (actual time=46096.908..46474.597 rows=150126 loops=3)\n",
      "                    Group Key: customer.c_custkey, nation.n_name\n",
      "                    ->  Sort  (cost=3513388.75..3513952.20 rows=225380 width=259) (actual time=46096.865..46163.459 rows=382361 loops=3)\n",
      "                          Sort Key: customer.c_custkey, nation.n_name\n",
      "                          Sort Method: external merge  Disk: 72864kB\n",
      "                          Worker 0:  Sort Method: external merge  Disk: 72800kB\n",
      "                          Worker 1:  Sort Method: external merge  Disk: 73336kB\n",
      "                          ->  Merge Join  (cost=3434500.66..3437882.21 rows=225380 width=259) (actual time=45124.755..45312.974 rows=382361 loops=3)\n",
      "                                Merge Cond: (customer.c_nationkey = nation.n_nationkey)\n",
      "                                ->  Sort  (cost=3434482.66..3435046.11 rows=225380 width=159) (actual time=45124.643..45212.630 rows=382361 loops=3)\n",
      "                                      Sort Key: customer.c_nationkey\n",
      "                                      Sort Method: external merge  Disk: 65176kB\n",
      "                                      Worker 0:  Sort Method: external merge  Disk: 65120kB\n",
      "                                      Worker 1:  Sort Method: external merge  Disk: 65592kB\n",
      "                                      ->  Merge Join  (cost=3385842.94..3396723.63 rows=225380 width=159) (actual time=43897.345..44477.213 rows=382361 loops=3)\n",
      "                                            Merge Cond: (orders.o_custkey = customer.c_custkey)\n",
      "                                            ->  Sort  (cost=2955540.57..2956104.02 rows=225380 width=16) (actual time=41225.484..41306.679 rows=382361 loops=3)\n",
      "                                                  Sort Key: orders.o_custkey\n",
      "                                                  Sort Method: external merge  Disk: 10296kB\n",
      "                                                  Worker 0:  Sort Method: external merge  Disk: 10288kB\n",
      "                                                  Worker 1:  Sort Method: external merge  Disk: 10360kB\n",
      "                                                  ->  Merge Join  (cost=2895610.27..2931648.53 rows=225380 width=16) (actual time=39651.656..41029.021 rows=382361 loops=3)\n",
      "                                                        Merge Cond: (lineitem.l_orderkey = orders.o_orderkey)\n",
      "                                                        ->  Sort  (cost=2350456.44..2365990.33 rows=6213555 width=16) (actual time=34172.569..34913.630 rows=4936061 loops=3)\n",
      "                                                              Sort Key: lineitem.l_orderkey\n",
      "                                                              Sort Method: external merge  Disk: 140072kB\n",
      "                                                              Worker 0:  Sort Method: external merge  Disk: 140096kB\n",
      "                                                              Worker 1:  Sort Method: external merge  Disk: 140376kB\n",
      "                                                              ->  Parallel Seq Scan on lineitem  (cost=0.00..1436970.35 rows=6213555 width=16) (actual time=0.142..30359.163 rows=4936061 loops=3)\n",
      "                                                                    Filter: (l_returnflag = 'R'::bpchar)\n",
      "                                                                    Rows Removed by Filter: 15059290\n",
      "                                                        ->  Sort  (cost=545150.72..546510.76 rows=544016 width=8) (actual time=5478.988..5542.659 rows=572907 loops=3)\n",
      "                                                              Sort Key: orders.o_orderkey\n",
      "                                                              Sort Method: external merge  Disk: 10128kB\n",
      "                                                              Worker 0:  Sort Method: external merge  Disk: 10128kB\n",
      "                                                              Worker 1:  Sort Method: external merge  Disk: 10128kB\n",
      "                                                              ->  Seq Scan on orders  (cost=0.00..485883.24 rows=544016 width=8) (actual time=0.524..5155.811 rows=573157 loops=3)\n",
      "                                                                    Filter: ((o_orderdate >= '1993-10-01'::date) AND (o_orderdate < '1994-01-01 00:00:00'::timestamp without time zone))\n",
      "                                                                    Rows Removed by Filter: 14426843\n",
      "                                            ->  Sort  (cost=430302.25..434052.36 rows=1500044 width=147) (actual time=2671.831..2931.559 rows=1499992 loops=3)\n",
      "                                                  Sort Key: customer.c_custkey\n",
      "                                                  Sort Method: external merge  Disk: 236328kB\n",
      "                                                  Worker 0:  Sort Method: external merge  Disk: 236312kB\n",
      "                                                  Worker 1:  Sort Method: external merge  Disk: 236328kB\n",
      "                                                  ->  Seq Scan on customer  (cost=0.00..50827.44 rows=1500044 width=147) (actual time=0.279..767.011 rows=1500000 loops=3)\n",
      "                                ->  Sort  (cost=18.00..18.42 rows=170 width=108) (actual time=0.101..0.113 rows=25 loops=3)\n",
      "                                      Sort Key: nation.n_nationkey\n",
      "                                      Sort Method: quicksort  Memory: 26kB\n",
      "                                      Worker 0:  Sort Method: quicksort  Memory: 26kB\n",
      "                                      Worker 1:  Sort Method: quicksort  Memory: 26kB\n",
      "                                      ->  Seq Scan on nation  (cost=0.00..11.70 rows=170 width=108) (actual time=0.083..0.086 rows=25 loops=3)\n",
      "Planning Time: 10.622 ms\n",
      "Execution Time: 48368.217 ms\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = off;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_tidscan = off;\")\n",
    "    cur.execute(\"SET enable_material = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = on;\")\n",
    "    cur.execute(\"SET enable_mergejoin = on;\")\n",
    "    cur.execute(\"SET enable_hashjoin = on;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort  (cost=2655567.02..2656919.30 rows=540913 width=279) (actual time=41879.185..42004.789 rows=381105 loops=1)\n",
      "  Sort Key: (sum((lineitem.l_extendedprice * ('1'::numeric - lineitem.l_discount)))) DESC\n",
      "  Sort Method: external merge  Disk: 71032kB\n",
      "  ->  Finalize GroupAggregate  (cost=2296819.47..2463547.48 rows=540913 width=279) (actual time=39346.447..41312.665 rows=381105 loops=1)\n",
      "        Group Key: customer.c_custkey, nation.n_name\n",
      "        ->  Gather Merge  (cost=2296819.47..2452278.46 rows=450760 width=279) (actual time=39346.397..40837.657 rows=453770 loops=1)\n",
      "              Workers Planned: 2\n",
      "              Workers Launched: 2\n",
      "              ->  Partial GroupAggregate  (cost=2295819.45..2399249.55 rows=225380 width=279) (actual time=39336.334..40734.674 rows=151257 loops=3)\n",
      "                    Group Key: customer.c_custkey, nation.n_name\n",
      "                    ->  Incremental Sort  (cost=2295819.45..2393615.05 rows=225380 width=259) (actual time=39336.290..40402.003 rows=382361 loops=3)\n",
      "                          Sort Key: customer.c_custkey, nation.n_name\n",
      "                          Presorted Key: customer.c_custkey\n",
      "                          Full-sort Groups: 11509  Sort Method: quicksort  Average Memory: 32kB  Peak Memory: 32kB\n",
      "                          Worker 0:  Full-sort Groups: 11572  Sort Method: quicksort  Average Memory: 32kB  Peak Memory: 32kB\n",
      "                          Worker 1:  Full-sort Groups: 11466  Sort Method: quicksort  Average Memory: 31kB  Peak Memory: 31kB\n",
      "                          ->  Nested Loop  (cost=2295819.05..2383472.95 rows=225380 width=259) (actual time=39335.673..40225.451 rows=382361 loops=3)\n",
      "                                ->  Merge Join  (cost=2295818.89..2377740.13 rows=225380 width=159) (actual time=39335.243..40036.535 rows=382361 loops=3)\n",
      "                                      Merge Cond: (orders.o_custkey = customer.c_custkey)\n",
      "                                      ->  Sort  (cost=2295818.35..2296381.80 rows=225380 width=16) (actual time=39334.217..39391.539 rows=382361 loops=3)\n",
      "                                            Sort Key: orders.o_custkey\n",
      "                                            Sort Method: external merge  Disk: 10312kB\n",
      "                                            Worker 0:  Sort Method: external merge  Disk: 10368kB\n",
      "                                            Worker 1:  Sort Method: external merge  Disk: 10272kB\n",
      "                                            ->  Parallel Hash Join  (cost=763919.98..2271926.31 rows=225380 width=16) (actual time=38027.909..39091.313 rows=382361 loops=3)\n",
      "                                                  Hash Cond: (lineitem.l_orderkey = orders.o_orderkey)\n",
      "                                                  ->  Parallel Bitmap Heap Scan on lineitem  (cost=166036.70..1596166.45 rows=6213555 width=16) (actual time=826.391..28961.737 rows=4936061 loops=3)\n",
      "                                                        Recheck Cond: (l_returnflag = 'R'::bpchar)\n",
      "                                                        Rows Removed by Index Recheck: 14537774\n",
      "                                                        Heap Blocks: exact=12767 lossy=362250\n",
      "                                                        ->  Bitmap Index Scan on idx_l_returnflag_linestatus  (cost=0.00..162308.56 rows=14912533 width=0) (actual time=814.170..814.183 rows=14808183 loops=1)\n",
      "                                                              Index Cond: (l_returnflag = 'R'::bpchar)\n",
      "                                                  ->  Parallel Hash  (cost=594163.87..594163.87 rows=226673 width=8) (actual time=7511.955..7511.959 rows=191052 loops=3)\n",
      "                                                        Buckets: 262144  Batches: 4  Memory Usage: 7712kB\n",
      "                                                        ->  Parallel Index Scan using orders_pkey on orders  (cost=0.43..594163.87 rows=226673 width=8) (actual time=0.405..7214.554 rows=191052 loops=3)\n",
      "                                                              Filter: ((o_orderdate >= '1993-10-01'::date) AND (o_orderdate < '1994-01-01 00:00:00'::timestamp without time zone))\n",
      "                                                              Rows Removed by Filter: 4808948\n",
      "                                      ->  Index Scan using customer_pkey on customer  (cost=0.43..74791.09 rows=1500044 width=147) (actual time=0.985..409.724 rows=1499986 loops=3)\n",
      "                                ->  Memoize  (cost=0.15..4.57 rows=1 width=108) (actual time=0.000..0.000 rows=1 loops=1147084)\n",
      "                                      Cache Key: customer.c_nationkey\n",
      "                                      Cache Mode: logical\n",
      "                                      Hits: 382161  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                                      Worker 0:  Hits: 384189  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                                      Worker 1:  Hits: 380659  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                                      ->  Index Scan using nation_pkey on nation  (cost=0.14..4.56 rows=1 width=108) (actual time=0.017..0.017 rows=1 loops=75)\n",
      "                                            Index Cond: (n_nationkey = customer.c_nationkey)\n",
      "Planning Time: 0.907 ms\n",
      "Execution Time: 42040.602 ms\n"
     ]
    }
   ],
   "source": [
    "explain_analyze(query_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting to note that it leverages an index on l_returnflag because we have an index on (l_returnflag, l_linestatus). but it may be dropped, sooo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate and record the size of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: \n",
      " (1237537, 'Customer#001237537', Decimal('884989.6657'), Decimal('7840.17'), 'RUSSIA                   ', 'FNG6WgB1mopyyY,ajQTU qUPW5o', '32-367-120-4327', 'nag carefully about the regular packages. carefully reg')\n",
      "Size of query_10 result table: 78.5078125 MB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(f\"CREATE TEMP TABLE temp_result AS {query_10};\")\n",
    "    cur.execute(\"SELECT * FROM temp_result;\")\n",
    "    result = cur.fetchone()\n",
    "    print(f\"First row: \\n {result}\")\n",
    "    cur.execute(\"SELECT pg_total_relation_size('temp_result');\")\n",
    "    size = cur.fetchall()\n",
    "    print(f\"Size of query_10 result table: {size[0][0]/(1024**2)} MB\")\n",
    "    cur.execute(\"DROP TABLE temp_result;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_14 = \"\"\"\n",
    "SELECT\n",
    "    100.00 * SUM(CASE\n",
    "        WHEN p_type LIKE 'PROMO%'\n",
    "        THEN l_extendedprice * (1 - l_discount)\n",
    "        ELSE 0\n",
    "    END) / SUM(l_extendedprice * (1 - l_discount)) AS promo_revenue\n",
    "FROM\n",
    "    lineitem,\n",
    "    part\n",
    "WHERE\n",
    "    l_partkey = p_partkey\n",
    "    AND l_shipdate >= DATE '1995-09-01'\n",
    "    AND l_shipdate < DATE '1995-09-01' + INTERVAL '1' MONTH;\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shipdate is quite selective, so we can use the index.\n",
    "we can optimise the join with the indexes. we know we have a btree index in both l_partkey, p_partkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = on;\")\n",
    "    cur.execute(\"SET enable_indexscan = off;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = off;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = on;\")\n",
    "    cur.execute(\"SET enable_mergejoin = off;\")\n",
    "    cur.execute(\"SET enable_hashjoin = off;\")\n",
    "    cur.execute(\"SET enable_sort = off;\")\n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_14, analyze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes a lot of time. after 45 minutes i quit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to not use the indexes but only hash join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalize Aggregate  (cost=1580790.06..1580790.08 rows=1 width=32) (actual time=58609.493..58916.956 rows=1 loops=1)\n",
      "  ->  Gather  (cost=1580789.83..1580790.04 rows=2 width=64) (actual time=58609.035..58916.937 rows=2 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 1\n",
      "        ->  Partial Aggregate  (cost=1579789.83..1579789.84 rows=1 width=64) (actual time=58509.653..58509.657 rows=1 loops=2)\n",
      "              ->  Parallel Hash Join  (cost=65409.00..1574388.08 rows=308671 width=33) (actual time=57421.307..58403.070 rows=374612 loops=2)\n",
      "                    Hash Cond: (lineitem.l_partkey = part.p_partkey)\n",
      "                    ->  Parallel Seq Scan on lineitem  (cost=0.00..1499455.82 rows=308671 width=16) (actual time=0.860..46013.326 rows=374612 loops=2)\n",
      "                          Filter: ((l_shipdate >= '1995-09-01'::date) AND (l_shipdate < '1995-10-01 00:00:00'::timestamp without time zone))\n",
      "                          Rows Removed by Filter: 29618414\n",
      "                    ->  Parallel Hash  (cost=49295.33..49295.33 rows=833333 width=25) (actual time=10796.029..10796.029 rows=1000000 loops=2)\n",
      "                          Buckets: 131072  Batches: 32  Memory Usage: 4832kB\n",
      "                          ->  Parallel Seq Scan on part  (cost=0.00..49295.33 rows=833333 width=25) (actual time=2.059..10225.856 rows=1000000 loops=2)\n",
      "Planning Time: 23.293 ms\n",
      "Execution Time: 58917.236 ms\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = on;\")\n",
    "    cur.execute(\"SET enable_indexscan = off;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = off;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = on;\")\n",
    "    cur.execute(\"SET enable_mergejoin = on;\")\n",
    "    cur.execute(\"SET enable_hashjoin = on;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    cur.execute(\"SET enable_hashagg = on;\")\n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that the optimizer doesn't use the index on p_partkey, it prefers to use hash join.\n",
    "the bitmap scan is used for the shipdate condition, and seems to speed up the time of 9 sec."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's use also the indexes, the bitmap scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate  (cost=1698913.50..1698913.52 rows=1 width=32) (actual time=48347.152..48348.560 rows=1 loops=1)\n",
      "  ->  Merge Join  (cost=1575410.50..1685949.32 rows=740810 width=33) (actual time=45010.907..47808.837 rows=749223 loops=1)\n",
      "        Merge Cond: (part.p_partkey = lineitem.l_partkey)\n",
      "        ->  Index Scan using part_pkey on part  (cost=0.43..92909.43 rows=2000000 width=25) (actual time=0.005..1540.118 rows=1999994 loops=1)\n",
      "        ->  Materialize  (cost=1575409.70..1579113.75 rows=740810 width=16) (actual time=45010.865..45520.394 rows=749223 loops=1)\n",
      "              ->  Sort  (cost=1575409.70..1577261.73 rows=740810 width=16) (actual time=45010.841..45329.736 rows=749223 loops=1)\n",
      "                    Sort Key: lineitem.l_partkey\n",
      "                    Sort Method: external merge  Disk: 21360kB\n",
      "                    ->  Gather  (cost=11109.87..1490522.38 rows=740810 width=16) (actual time=157.220..43484.164 rows=749223 loops=1)\n",
      "                          Workers Planned: 2\n",
      "                          Workers Launched: 1\n",
      "                          ->  Parallel Bitmap Heap Scan on lineitem  (cost=10109.87..1415441.38 rows=308671 width=16) (actual time=113.376..43890.664 rows=374612 loops=2)\n",
      "                                Recheck Cond: ((l_shipdate >= '1995-09-01'::date) AND (l_shipdate < '1995-10-01 00:00:00'::timestamp without time zone))\n",
      "                                Rows Removed by Index Recheck: 9419050\n",
      "                                Heap Blocks: exact=21477 lossy=178538\n",
      "                                ->  Bitmap Index Scan on idx_l_shipdate  (cost=0.00..9924.67 rows=740810 width=0) (actual time=146.778..146.778 rows=749223 loops=1)\n",
      "                                      Index Cond: ((l_shipdate >= '1995-09-01'::date) AND (l_shipdate < '1995-10-01 00:00:00'::timestamp without time zone))\n",
      "Planning Time: 14.326 ms\n",
      "Execution Time: 48355.805 ms\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = on;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = on;\")\n",
    "    cur.execute(\"SET enable_mergejoin = on;\")\n",
    "    cur.execute(\"SET enable_hashjoin = off;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    cur.execute(\"SET enable_hashagg = off;\")\n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_14, analyze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using sort seems to improve the result of 5 seconds.\n",
    "\n",
    "bitmap scan improves of 9 seconds the time.\n",
    "\n",
    "as it is clear, the index on lineitem is not used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's try with index nested loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalize Aggregate  (cost=2932787.70..2932787.71 rows=1 width=32) (actual time=52230.643..52235.760 rows=1 loops=1)\n",
      "  ->  Gather  (cost=2932787.46..2932787.67 rows=2 width=64) (actual time=52230.212..52235.664 rows=2 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 1\n",
      "        ->  Partial Aggregate  (cost=2931787.46..2931787.47 rows=1 width=64) (actual time=52188.231..52188.233 rows=1 loops=2)\n",
      "              ->  Nested Loop  (cost=10110.30..2926385.72 rows=308671 width=33) (actual time=283.281..51583.723 rows=374612 loops=2)\n",
      "                    ->  Parallel Bitmap Heap Scan on lineitem  (cost=10109.87..1415441.38 rows=308671 width=16) (actual time=282.869..35916.723 rows=374612 loops=2)\n",
      "                          Recheck Cond: ((l_shipdate >= '1995-09-01'::date) AND (l_shipdate < '1995-10-01 00:00:00'::timestamp without time zone))\n",
      "                          Rows Removed by Index Recheck: 9419050\n",
      "                          Heap Blocks: exact=22042 lossy=183693\n",
      "                          ->  Bitmap Index Scan on idx_l_shipdate  (cost=0.00..9924.67 rows=740810 width=0) (actual time=308.591..308.592 rows=749223 loops=1)\n",
      "                                Index Cond: ((l_shipdate >= '1995-09-01'::date) AND (l_shipdate < '1995-10-01 00:00:00'::timestamp without time zone))\n",
      "                    ->  Index Scan using part_pkey on part  (cost=0.43..4.89 rows=1 width=25) (actual time=0.041..0.041 rows=1 loops=749223)\n",
      "                          Index Cond: (p_partkey = lineitem.l_partkey)\n",
      "Planning Time: 0.301 ms\n",
      "Execution Time: 52235.866 ms\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = on;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = on;\")\n",
    "    cur.execute(\"SET enable_mergejoin = off;\")\n",
    "    cur.execute(\"SET enable_hashjoin = off;\")\n",
    "    cur.execute(\"SET enable_sort = off;\")\n",
    "    cur.execute(\"SET enable_hashagg = off;\")\n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_14, analyze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's try with merge join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate and record size result table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: \n",
      " (Decimal('16.6475949416150953'),)\n",
      "Size of query_14 result table: 0.015625 MB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(f\"CREATE TEMP TABLE temp_result AS {query_14};\")\n",
    "    cur.execute(\"SELECT * FROM temp_result;\")\n",
    "    result = cur.fetchone()\n",
    "    print(f\"First row: \\n {result}\")\n",
    "    cur.execute(\"SELECT pg_total_relation_size('temp_result');\")\n",
    "    size = cur.fetchall()\n",
    "    print(f\"Size of query_14 result table: {size[0][0]/(1024**2)} MB\")\n",
    "    cur.execute(\"DROP TABLE temp_result;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_17 = \"\"\"\n",
    "SELECT\n",
    "    SUM(l_extendedprice) / 7.0 AS avg_yearly\n",
    "FROM\n",
    "    lineitem,\n",
    "    part\n",
    "WHERE\n",
    "    p_partkey = l_partkey\n",
    "    AND p_brand = 'Brand#23'\n",
    "    AND p_container = 'MED BOX'\n",
    "    AND l_quantity < (\n",
    "        SELECT\n",
    "            0.2 * AVG(l_quantity)\n",
    "        FROM\n",
    "            lineitem\n",
    "        WHERE\n",
    "            l_partkey = p_partkey\n",
    "    );\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = on;\")\n",
    "    cur.execute(\"SET enable_indexscan = off;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = on;\")\n",
    "    cur.execute(\"SET enable_mergejoin = on;\")\n",
    "    cur.execute(\"SET enable_hashjoin = on;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_17, analyze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This query takes a lot of time if we don't use indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate  (cost=7192655.19..7192655.20 rows=1 width=32) (actual time=22812.586..22812.588 rows=1 loops=1)\n",
      "  ->  Nested Loop  (cost=0.00..7192605.95 rows=19695 width=8) (actual time=110.553..22810.144 rows=5526 loops=1)\n",
      "        ->  Seq Scan on part  (cost=0.00..70962.00 rows=1970 width=4) (actual time=0.949..437.183 rows=2044 loops=1)\n",
      "              Filter: ((p_brand = 'Brand#23'::bpchar) AND (p_container = 'MED BOX'::bpchar))\n",
      "              Rows Removed by Filter: 1997956\n",
      "        ->  Index Scan using idx_lineitem_partkey on lineitem  (cost=0.00..3614.95 rows=10 width=17) (actual time=10.610..10.944 rows=3 loops=2044)\n",
      "              Index Cond: (l_partkey = part.p_partkey)\n",
      "              Filter: (l_quantity < (SubPlan 1))\n",
      "              Rows Removed by Filter: 27\n",
      "              SubPlan 1\n",
      "                ->  Aggregate  (cost=120.58..120.60 rows=1 width=32) (actual time=0.334..0.334 rows=1 loops=61385)\n",
      "                      ->  Index Scan using idx_lineitem_partkey on lineitem lineitem_1  (cost=0.00..120.51 rows=29 width=5) (actual time=0.001..0.329 rows=31 loops=61385)\n",
      "                            Index Cond: (l_partkey = part.p_partkey)\n",
      "Planning Time: 12.479 ms\n",
      "Execution Time: 22812.696 ms\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = on;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = off;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = on;\")\n",
    "    cur.execute(\"SET enable_mergejoin = on;\")\n",
    "    cur.execute(\"SET enable_hashjoin = off;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_17, analyze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that it is already a fast query, but we can try to put an index also on containier and brand to see if it speeds up the query. they have respectively 40 and 25 distinc values, so they are not that selective, but we can try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create index on lineitem: 55.932111978530884 seconds\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_p_brand ON part USING hash (p_brand);\")    \n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create index on part: {end_time - start_time} seconds\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create index on lineitem: 36.967782974243164 seconds\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_p_container ON part USING hash (p_container);\")    \n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create index on part: {end_time - start_time} seconds\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index Name: part_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX part_pkey ON public.part USING btree (p_partkey)\n",
      "\n",
      "Index Name: idx_p_brand\n",
      "Index Definition: CREATE INDEX idx_p_brand ON public.part USING hash (p_brand)\n",
      "\n",
      "Index Name: idx_p_container\n",
      "Index Definition: CREATE INDEX idx_p_container ON public.part USING hash (p_container)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_indexes(\"part\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate  (cost=7132257.53..7132257.55 rows=1 width=32) (actual time=19185.859..19185.862 rows=1 loops=1)\n",
      "  ->  Nested Loop  (cost=4089.74..7132208.29 rows=19695 width=8) (actual time=53.152..19183.788 rows=5526 loops=1)\n",
      "        ->  Bitmap Heap Scan on part  (cost=4089.74..10564.34 rows=1970 width=4) (actual time=28.314..249.393 rows=2044 loops=1)\n",
      "              Recheck Cond: ((p_container = 'MED BOX'::bpchar) AND (p_brand = 'Brand#23'::bpchar))\n",
      "              Heap Blocks: exact=1998\n",
      "              ->  BitmapAnd  (cost=4089.74..4089.74 rows=1970 width=0) (actual time=27.397..27.398 rows=0 loops=1)\n",
      "                    ->  Bitmap Index Scan on idx_p_container  (cost=0.00..1567.00 rows=49467 width=0) (actual time=18.831..18.831 rows=50186 loops=1)\n",
      "                          Index Cond: (p_container = 'MED BOX'::bpchar)\n",
      "                    ->  Bitmap Index Scan on idx_p_brand  (cost=0.00..2521.50 rows=79667 width=0) (actual time=7.327..7.327 rows=79826 loops=1)\n",
      "                          Index Cond: (p_brand = 'Brand#23'::bpchar)\n",
      "        ->  Index Scan using idx_lineitem_partkey on lineitem  (cost=0.00..3614.95 rows=10 width=17) (actual time=8.926..9.262 rows=3 loops=2044)\n",
      "              Index Cond: (l_partkey = part.p_partkey)\n",
      "              Filter: (l_quantity < (SubPlan 1))\n",
      "              Rows Removed by Filter: 27\n",
      "              SubPlan 1\n",
      "                ->  Aggregate  (cost=120.58..120.60 rows=1 width=32) (actual time=0.281..0.281 rows=1 loops=61385)\n",
      "                      ->  Index Scan using idx_lineitem_partkey on lineitem lineitem_1  (cost=0.00..120.51 rows=29 width=5) (actual time=0.001..0.276 rows=31 loops=61385)\n",
      "                            Index Cond: (l_partkey = part.p_partkey)\n",
      "Planning Time: 3.733 ms\n",
      "Execution Time: 19197.023 ms\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = off;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = on;\")\n",
    "    cur.execute(\"SET enable_mergejoin = on;\")\n",
    "    cur.execute(\"SET enable_hashjoin = off;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_17, analyze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we get a small improvemtn, i don't think it is worth keeping those indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(f\"CREATE TEMP TABLE temp_result AS {query_17};\")\n",
    "    cur.execute(\"SELECT pg_total_relation_size('temp_result');\")\n",
    "    size = cur.fetchall()\n",
    "    print(f\"Size of query_17 result table: {size[0][0]/(1024**2)} MB\")\n",
    "    cur.execute(\"DROP TABLE temp_result;\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Part 2: Indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some useful commands:\n",
    "\n",
    "To create and index:\n",
    "\n",
    "default is b+tree\n",
    "CREATE INDEX idx_customer_name ON customer (c_name);\n",
    "\n",
    "available indexes:\n",
    "\n",
    "B-tree: The default and most common type of index.\n",
    "\n",
    "Hash: Used for equality comparisons.\n",
    "\n",
    "GIN (Generalized Inverted Index): Useful for indexing array values and full-text search.\n",
    "\n",
    "GiST (Generalized Search Tree): Supports many types of queries, including full-text search.\n",
    "\n",
    "SP-GiST (Space-Partitioned Generalized Search Tree): Useful for partitioning data.\n",
    "\n",
    "BRIN (Block Range INdexes): Efficient for large tables where the column values are correlated with their physical location.\n",
    "\n",
    "other possibilities:\n",
    "\n",
    "Partial Indexes\n",
    "Description: Indexes only a portion of a table, based on a condition.\n",
    "Use Case: When you frequently query a subset of rows.\n",
    "\n",
    "CREATE INDEX idx_active_customers ON customer (c_name) WHERE active = true;\n",
    "\n",
    "Expression Indexes\n",
    "Description: Indexes the result of an expression or function rather than a raw column.\n",
    "Use Case: When queries involve expressions or function calls.\n",
    "\n",
    "CREATE INDEX idx_lower_customer_name ON customer ((lower(c_name)));\n",
    "\n",
    "\n",
    "To disable the indexscan\n",
    "\n",
    "SET enable_seqscan = on;\n",
    "SET enable_indexscan = off;\n",
    "SET enable_bitmapscan = off;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create index on lineitem: 146.5280566215515 seconds\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_lineitem_partkey ON lineitem USING hash (l_partkey);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create index on lineitem: {end_time - start_time} seconds\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of index on lineitem: 1896.65625 MB\n",
      "Size of index on lineitem: 1.852203369140625 GB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "\n",
    "    cur.execute(\"SELECT pg_relation_size('idx_lineitem_partkey');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of index on lineitem: {index_size/(1024**2)} MB\")\n",
    "    print(f\"Size of index on lineitem: {index_size/(1024**3)} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPLAIN ANALYZE result:\n",
      "Aggregate  (cost=1937805.96..1937805.97 rows=1 width=32) (actual time=240896.545..240896.670 rows=1 loops=1)\n",
      "  ->  Hash Join  (cost=54683.72..1937756.72 rows=19695 width=8) (actual time=1156.271..240892.848 rows=5526 loops=1)\n",
      "        Hash Cond: (lineitem.l_partkey = part.p_partkey)\n",
      "        Join Filter: (lineitem.l_quantity < (SubPlan 1))\n",
      "        Rows Removed by Join Filter: 55859\n",
      "        ->  Seq Scan on lineitem  (cost=0.00..1724403.52 rows=59986052 width=17) (actual time=0.335..23018.323 rows=59986052 loops=1)\n",
      "        ->  Hash  (cost=54659.10..54659.10 rows=1970 width=4) (actual time=989.198..989.319 rows=2044 loops=1)\n",
      "              Buckets: 2048  Batches: 1  Memory Usage: 88kB\n",
      "              ->  Gather  (cost=1000.00..54659.10 rows=1970 width=4) (actual time=3.643..975.057 rows=2044 loops=1)\n",
      "                    Workers Planned: 2\n",
      "                    Workers Launched: 2\n",
      "                    ->  Parallel Seq Scan on part  (cost=0.00..53462.10 rows=821 width=4) (actual time=1.157..911.640 rows=681 loops=3)\n",
      "                          Filter: ((p_brand = 'Brand#23'::bpchar) AND (p_container = 'MED BOX'::bpchar))\n",
      "                          Rows Removed by Filter: 665985\n",
      "        SubPlan 1\n",
      "          ->  Aggregate  (cost=120.58..120.60 rows=1 width=32) (actual time=3.453..3.453 rows=1 loops=61385)\n",
      "                ->  Index Scan using idx_lineitem_partkey on lineitem lineitem_1  (cost=0.00..120.51 rows=29 width=5) (actual time=0.259..3.447 rows=31 loops=61385)\n",
      "                      Index Cond: (l_partkey = part.p_partkey)\n",
      "Planning Time: 13.348 ms\n",
      "Execution Time: 240897.794 ms\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(f\"EXPLAIN ANALYZE {query_17}\")\n",
    "    explain_result = cur.fetchall()\n",
    "    print(\"EXPLAIN ANALYZE result:\")\n",
    "    for row in explain_result:\n",
    "        print(row[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very good! A query that almost can't be executed now is completed in 4 minutes! But the cost is huge 1.85 GB ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: \n",
      " (Decimal('3295493.512857142857'),)\n",
      "Size of query_17 result table: 0.015625 MB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(f\"CREATE TEMP TABLE temp_result AS {query_17};\")\n",
    "    cur.execute(\"SELECT * FROM temp_result;\")\n",
    "    result = cur.fetchall()\n",
    "    for row in result:\n",
    "        print(row)\n",
    "\n",
    "    cur.execute(\"SELECT pg_total_relation_size('temp_result');\")\n",
    "    size = cur.fetchall()\n",
    "    print(f\"Size of query_17 result table: {size[0][0]/(1024**2)} MB\")\n",
    "    cur.execute(\"DROP TABLE temp_result;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Materialised view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_materialized = \"\"\"\n",
    "CREATE MATERIALIZED VIEW part_lineitem AS\n",
    "SELECT part.p_partkey, part.p_brand, part.p_container, lineitem.l_quantity, lineitem.l_extendedprice\n",
    "FROM part JOIN lineitem ON p_partkey = l_partkey;\n",
    "\"\"\"\n",
    "\n",
    "with conn.cursor() as cur:\n",
    "        cur.execute(f\"EXPLAIN ANALYZE {query_materialized}\")\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of materialised view: 3906.609375 MB\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(\"SELECT pg_total_relation_size('part_lineitem');\")\n",
    "    size = cur.fetchall()\n",
    "    print(f\"Size of materialised view: {size[0][0]/(1024**2)} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_17_1 = \"\"\"\n",
    "\n",
    "CREATE VIEW average_quantity AS\n",
    "SELECT\n",
    "    p_partkey,\n",
    "    AVG(l_quantity) AS avg_quantity\n",
    "FROM\n",
    "    part_lineitem\n",
    "GROUP BY\n",
    "    p_partkey;\n",
    "\n",
    "SELECT\n",
    "    p_partkey,\n",
    "    SUM(l_extendedprice) / 7.0 AS avg_yearly\n",
    "FROM\n",
    "    part_lineitem\n",
    "WHERE\n",
    "    p_brand = 'Brand#23'\n",
    "    AND p_container = 'MED BOX'\n",
    "    AND l_quantity < (\n",
    "        SELECT\n",
    "            0.2 * avg_quantity\n",
    "        FROM\n",
    "            average_quantity\n",
    "        WHERE \n",
    "            average_quantity.p_partkey = part_lineitem.p_partkey\n",
    "    )\n",
    "GROUP BY\n",
    "    p_partkey;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "        cur.execute(f\"{query_17_1}\")\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "takes more time than the index, there is something wrong? maybe there is no index in p_partkey and thats the problem??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
