{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish a connection to the PostgreSQL database\n",
    "conn = psycopg2.connect(\n",
    "    dbname = \"dw_cs\", \n",
    "    user = \"postgres\", \n",
    "    host= 'localhost',      # change this to your host\n",
    "    password = \"postgres\",  # change this to your password\n",
    "    port = 5432\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check the indexes on a table\n",
    "\n",
    "def check_indexes(table_name):\n",
    "\n",
    "    with conn.cursor() as cur:\n",
    "        query = f\"\"\"\n",
    "        SELECT\n",
    "            indexname,\n",
    "            indexdef\n",
    "        FROM\n",
    "            pg_indexes\n",
    "        WHERE\n",
    "            tablename = '{table_name}';\n",
    "        \"\"\"\n",
    "\n",
    "        cur.execute(query)      \n",
    "        \n",
    "        indexes = cur.fetchall()\n",
    "        \n",
    "        for index in indexes:\n",
    "            print(f\"Index Name: {index[0]}\")\n",
    "            print(f\"Index Definition: {index[1]}\\n\")\n",
    "\n",
    "\n",
    "# function to explain-analyze a query\n",
    "\n",
    "def explain_analyze(query, analyze = True):\n",
    "    conn.rollback()\n",
    "    with conn.cursor() as cur:\n",
    "        if analyze:\n",
    "            cur.execute(f\"EXPLAIN ANALYZE {query}\")\n",
    "        else:\n",
    "            cur.execute(f\"EXPLAIN {query}\")\n",
    "        explain = cur.fetchall()\n",
    "\n",
    "        for line in explain:\n",
    "            print(line[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial database size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database size: 19715.57 MB\n",
      "Database size: 19.25 GB \n",
      "\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    cur.execute(\"SELECT pg_database_size('dw_cs');\")\n",
    "    all_rows = cur.fetchall()\n",
    "    print(f\"Database size: {all_rows[0][0] / (1024**2):.2f} MB\")\n",
    "    print(f\"Database size: {all_rows[0][0] / (1024**3):.2f} GB \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index Name: nation_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX nation_pkey ON public.nation USING btree (n_nationkey)\n",
      "\n",
      "Index Name: part_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX part_pkey ON public.part USING btree (p_partkey)\n",
      "\n",
      "Index Name: supplier_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX supplier_pkey ON public.supplier USING btree (s_suppkey)\n",
      "\n",
      "Index Name: customer_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX customer_pkey ON public.customer USING btree (c_custkey)\n",
      "\n",
      "Index Name: region_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX region_pkey ON public.region USING btree (r_regionkey)\n",
      "\n",
      "Index Name: partsupp_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX partsupp_pkey ON public.partsupp USING btree (ps_partkey, ps_suppkey)\n",
      "\n",
      "Index Name: orders_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX orders_pkey ON public.orders USING btree (o_orderkey)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = ['nation', 'part', 'supplier', 'customer', 'lineitem', 'region', 'partsupp', 'orders']\n",
    "\n",
    "conn.rollback()\n",
    "for table in a:\n",
    "    check_indexes(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = on;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = off;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_tidscan = off;\")\n",
    "    cur.execute(\"SET enable_material = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = on;\")\n",
    "    cur.execute(\"SET enable_mergejoin = on;\")\n",
    "    cur.execute(\"SET enable_hashjoin = off;\")\n",
    "    cur.execute(\"SET enable_hashagg = on;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    cur.execute(\"SET enable_partition_pruning = off;\")\n",
    "    cur.execute(\"SET enable_partitionwise_join = off;\")\n",
    "    cur.execute(\"SET enable_partitionwise_aggregate = off;\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_1 = \"\"\"\n",
    "SELECT\n",
    "    l_returnflag,\n",
    "    l_linestatus,\n",
    "    SUM(l_quantity) AS sum_qty,\n",
    "    SUM(l_extendedprice) AS sum_base_price,\n",
    "    SUM(l_extendedprice * (1 - l_discount)) AS sum_disc_price,\n",
    "    SUM(l_extendedprice * (1 - l_discount) * (1 + l_tax)) AS sum_charge,\n",
    "    AVG(l_quantity) AS avg_qty,\n",
    "    AVG(l_extendedprice) AS avg_price,\n",
    "    AVG(l_discount) AS avg_disc,\n",
    "    COUNT(*) AS count_order\n",
    "FROM\n",
    "    lineitem\n",
    "WHERE\n",
    "    l_shipdate <= DATE '1998-12-01' - INTERVAL '90' DAY\n",
    "GROUP BY\n",
    "    l_returnflag,\n",
    "    l_linestatus\n",
    "ORDER BY\n",
    "    l_returnflag,\n",
    "    l_linestatus;\n",
    "\"\"\"\n",
    "\n",
    "query_10 = \"\"\"\n",
    "SELECT\n",
    "    c_custkey,\n",
    "    c_name,\n",
    "    SUM(l_extendedprice * (1 - l_discount)) AS revenue,\n",
    "    c_acctbal,\n",
    "    n_name,\n",
    "    c_address,\n",
    "    c_phone,\n",
    "    c_comment\n",
    "FROM\n",
    "    customer,\n",
    "    orders,\n",
    "    lineitem,\n",
    "    nation\n",
    "WHERE\n",
    "    c_custkey = o_custkey\n",
    "    AND l_orderkey = o_orderkey\n",
    "    AND o_orderdate >= DATE '1993-10-01'\n",
    "    AND o_orderdate < DATE '1993-10-01' + INTERVAL '3' MONTH\n",
    "    AND l_returnflag = 'R'\n",
    "    AND c_nationkey = n_nationkey\n",
    "GROUP BY\n",
    "    c_custkey,\n",
    "    c_name,\n",
    "    c_acctbal,\n",
    "    c_phone,\n",
    "    n_name,\n",
    "    c_address,\n",
    "    c_comment\n",
    "ORDER BY\n",
    "    revenue DESC;\n",
    "\"\"\"\n",
    "\n",
    "query_14 = \"\"\"\n",
    "SELECT\n",
    "    100.00 * SUM(CASE\n",
    "        WHEN p_type LIKE 'PROMO%'\n",
    "        THEN l_extendedprice * (1 - l_discount)\n",
    "        ELSE 0\n",
    "    END) / SUM(l_extendedprice * (1 - l_discount)) AS promo_revenue\n",
    "FROM\n",
    "    lineitem,\n",
    "    part\n",
    "WHERE\n",
    "    l_partkey = p_partkey\n",
    "    AND l_shipdate >= DATE '1995-09-01'\n",
    "    AND l_shipdate < DATE '1995-09-01' + INTERVAL '1' MONTH;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "query_17 = \"\"\"\n",
    "SELECT\n",
    "    SUM(l_extendedprice) / 7.0 AS avg_yearly\n",
    "FROM\n",
    "    lineitem,\n",
    "    part\n",
    "WHERE\n",
    "    l_partkey = p_partkey\n",
    "    AND p_brand = 'Brand#23'\n",
    "    AND p_container = 'MED BOX'\n",
    "    AND l_quantity < (\n",
    "        SELECT\n",
    "            0.2 * AVG(l_quantity)\n",
    "        FROM\n",
    "            lineitem\n",
    "        WHERE\n",
    "            p_partkey = l_partkey\n",
    "    );\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalize GroupAggregate  (cost=2300104.98..2300106.93 rows=6 width=236) (actual time=41971.743..41972.816 rows=4 loops=1)\n",
      "  Group Key: l_returnflag, l_linestatus\n",
      "  ->  Gather Merge  (cost=2300104.98..2300106.38 rows=12 width=236) (actual time=41971.694..41972.759 rows=12 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Sort  (cost=2299104.95..2299104.97 rows=6 width=236) (actual time=41958.535..41958.536 rows=4 loops=3)\n",
      "              Sort Key: l_returnflag, l_linestatus\n",
      "              Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 0:  Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 1:  Sort Method: quicksort  Memory: 27kB\n",
      "              ->  Partial HashAggregate  (cost=2299104.74..2299104.87 rows=6 width=236) (actual time=41954.829..41954.833 rows=4 loops=3)\n",
      "                    Group Key: l_returnflag, l_linestatus\n",
      "                    Batches: 1  Memory Usage: 24kB\n",
      "                    Worker 0:  Batches: 1  Memory Usage: 24kB\n",
      "                    Worker 1:  Batches: 1  Memory Usage: 24kB\n",
      "                    ->  Parallel Seq Scan on lineitem  (cost=0.00..1436970.35 rows=24632411 width=25) (actual time=0.283..26108.701 rows=19714203 loops=3)\n",
      "                          Filter: (l_shipdate <= '1998-09-02 00:00:00'::timestamp without time zone)\n",
      "                          Rows Removed by Filter: 281148\n",
      "Planning Time: 5.888 ms\n",
      "Execution Time: 41973.138 ms\n"
     ]
    }
   ],
   "source": [
    "explain_analyze(query_1, analyze = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort  (cost=3344325.21..3345720.08 rows=557947 width=279) (actual time=31990.264..32040.663 rows=381105 loops=1)\n",
      "  Sort Key: (sum((lineitem.l_extendedprice * ('1'::numeric - lineitem.l_discount)))) DESC\n",
      "  Sort Method: external merge  Disk: 71032kB\n",
      "  ->  GroupAggregate  (cost=2942891.02..3146127.82 rows=557947 width=279) (actual time=29727.038..31635.053 rows=381105 loops=1)\n",
      "        Group Key: customer.c_custkey, nation.n_name\n",
      "        ->  Incremental Sort  (cost=2942891.02..3132179.14 rows=557947 width=259) (actual time=29727.025..31081.010 rows=1147084 loops=1)\n",
      "              Sort Key: customer.c_custkey, nation.n_name\n",
      "              Presorted Key: customer.c_custkey\n",
      "              Full-sort Groups: 34124  Sort Method: quicksort  Average Memory: 31kB  Peak Memory: 31kB\n",
      "              ->  Nested Loop  (cost=2942890.72..3107071.53 rows=557947 width=259) (actual time=29726.951..30755.197 rows=1147084 loops=1)\n",
      "                    ->  Merge Join  (cost=2942890.57..3093377.71 rows=557947 width=159) (actual time=29726.580..30467.129 rows=1147084 loops=1)\n",
      "                          Merge Cond: (orders.o_custkey = customer.c_custkey)\n",
      "                          ->  Gather Merge  (cost=2942883.48..3007865.60 rows=557947 width=16) (actual time=29726.302..29870.820 rows=1147084 loops=1)\n",
      "                                Workers Planned: 2\n",
      "                                Workers Launched: 2\n",
      "                                ->  Sort  (cost=2941883.46..2942464.65 rows=232478 width=16) (actual time=29710.674..29739.102 rows=382361 loops=3)\n",
      "                                      Sort Key: orders.o_custkey\n",
      "                                      Sort Method: external merge  Disk: 10256kB\n",
      "                                      Worker 0:  Sort Method: external merge  Disk: 10368kB\n",
      "                                      Worker 1:  Sort Method: external merge  Disk: 10320kB\n",
      "                                      ->  Merge Join  (cost=2881503.92..2917185.84 rows=232478 width=16) (actual time=28752.206..29574.733 rows=382361 loops=3)\n",
      "                                            Merge Cond: (lineitem.l_orderkey = orders.o_orderkey)\n",
      "                                            ->  Sort  (cost=2333118.63..2348371.33 rows=6101082 width=16) (actual time=25885.403..26330.228 rows=4936061 loops=3)\n",
      "                                                  Sort Key: lineitem.l_orderkey\n",
      "                                                  Sort Method: external merge  Disk: 139504kB\n",
      "                                                  Worker 0:  Sort Method: external merge  Disk: 140672kB\n",
      "                                                  Worker 1:  Sort Method: external merge  Disk: 140400kB\n",
      "                                                  ->  Parallel Seq Scan on lineitem  (cost=0.00..1436970.35 rows=6101082 width=16) (actual time=0.207..23779.338 rows=4936061 loops=3)\n",
      "                                                        Filter: (l_returnflag = 'R'::bpchar)\n",
      "                                                        Rows Removed by Filter: 15059290\n",
      "                                            ->  Sort  (cost=548382.24..549811.16 rows=571566 width=8) (actual time=2866.739..2904.649 rows=573157 loops=3)\n",
      "                                                  Sort Key: orders.o_orderkey\n",
      "                                                  Sort Method: external merge  Disk: 10128kB\n",
      "                                                  Worker 0:  Sort Method: external merge  Disk: 10128kB\n",
      "                                                  Worker 1:  Sort Method: external merge  Disk: 10128kB\n",
      "                                                  ->  Seq Scan on orders  (cost=0.00..485912.00 rows=571566 width=8) (actual time=0.184..2628.624 rows=573157 loops=3)\n",
      "                                                        Filter: ((o_orderdate >= '1993-10-01'::date) AND (o_orderdate < '1994-01-01 00:00:00'::timestamp without time zone))\n",
      "                                                        Rows Removed by Filter: 14426843\n",
      "                          ->  Index Scan using customer_pkey on customer  (cost=0.43..74794.43 rows=1500000 width=147) (actual time=0.274..355.784 rows=1499998 loops=1)\n",
      "                    ->  Memoize  (cost=0.15..2.17 rows=1 width=108) (actual time=0.000..0.000 rows=1 loops=1147084)\n",
      "                          Cache Key: customer.c_nationkey\n",
      "                          Cache Mode: logical\n",
      "                          Hits: 1147059  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                          ->  Index Scan using nation_pkey on nation  (cost=0.14..2.16 rows=1 width=108) (actual time=0.014..0.014 rows=1 loops=25)\n",
      "                                Index Cond: (n_nationkey = customer.c_nationkey)\n",
      "Planning Time: 11.170 ms\n",
      "Execution Time: 32076.221 ms\n"
     ]
    }
   ],
   "source": [
    "explain_analyze(query_10, analyze = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate  (cost=1800922.34..1800922.35 rows=1 width=32) (actual time=28778.747..28778.848 rows=1 loops=1)\n",
      "  ->  Merge Join  (cost=1676444.04..1786617.50 rows=817419 width=33) (actual time=27950.390..28572.123 rows=749223 loops=1)\n",
      "        Merge Cond: (part.p_partkey = lineitem.l_partkey)\n",
      "        ->  Index Scan using part_pkey on part  (cost=0.43..92913.43 rows=2000000 width=25) (actual time=0.131..330.069 rows=1999994 loops=1)\n",
      "        ->  Sort  (cost=1676443.20..1678486.75 rows=817419 width=16) (actual time=27950.251..28009.924 rows=749223 loops=1)\n",
      "              Sort Key: lineitem.l_partkey\n",
      "              Sort Method: external sort  Disk: 24288kB\n",
      "              ->  Gather  (cost=1000.00..1582197.72 rows=817419 width=16) (actual time=0.452..27458.587 rows=749223 loops=1)\n",
      "                    Workers Planned: 2\n",
      "                    Workers Launched: 2\n",
      "                    ->  Parallel Seq Scan on lineitem  (cost=0.00..1499455.82 rows=340591 width=16) (actual time=0.537..27610.615 rows=249741 loops=3)\n",
      "                          Filter: ((l_shipdate >= '1995-09-01'::date) AND (l_shipdate < '1995-10-01 00:00:00'::timestamp without time zone))\n",
      "                          Rows Removed by Filter: 19745610\n",
      "Planning Time: 3.724 ms\n",
      "Execution Time: 28784.718 ms\n"
     ]
    }
   ],
   "source": [
    "explain_analyze(query_14, analyze = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set hashjoin and hashaggregate off, we only analyze the situation with indexes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried to put two indexes on l_returnflag and l_linestatus but we saw that they were not used. We have to note that they do not have many distinct values: (3,2) respectively, we could use a bitmap index, but in postgre it is not implemented.\n",
    "\n",
    "Let's see if with an index on shipdate we get better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create index on lineitem: 54.73046016693115 seconds\n",
      "Size of idx_l_shipdate ON lineitem (l_shipdate): 397.546875 MB\n",
      "Size of idx_l_shipdate ON lineitem (l_shipdate): 0.3882293701171875 GB\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    # tried also this index, but it is not helpful\n",
    "    # cur.execute(\"CREATE EXTENSION IF NOT EXISTS btree_gin;\")\n",
    "    # cur.execute(\"CREATE INDEX idx_l_shipdate_gin ON lineitem USING gin (l_shipdate);\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_l_shipdate ON lineitem (l_shipdate);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create index on lineitem: {end_time - start_time} seconds\")\n",
    "\n",
    "    cur.execute(\"SELECT pg_relation_size('idx_l_shipdate');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of idx_l_shipdate ON lineitem (l_shipdate): {index_size/(1024**2)} MB\")\n",
    "    print(f\"Size of idx_l_shipdate ON lineitem (l_shipdate): {index_size/(1024**3)} GB\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create index on lineitem: 61.83437705039978 seconds\n",
      "Size of idx_l_returnflag ON lineitem (l_returnflag): 396.4609375 MB\n",
      "Size of idx_l_returnflag ON lineitem (l_returnflag): 0.38716888427734375 GB\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    # tried also hash index but it doesn't work, after 5 minutes it was still running\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_l_returnflag ON lineitem (l_returnflag);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create index on lineitem: {end_time - start_time} seconds\")\n",
    "\n",
    "    cur.execute(\"SELECT pg_relation_size('idx_l_returnflag');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of idx_l_returnflag ON lineitem (l_returnflag): {index_size/(1024**2)} MB\")\n",
    "    print(f\"Size of idx_l_returnflag ON lineitem (l_returnflag): {index_size/(1024**3)} GB\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an index also on return flag to see if it helps both in query 1 and 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalize GroupAggregate  (cost=2958736.61..2958738.57 rows=6 width=236) (actual time=32916.266..32919.690 rows=4 loops=1)\n",
      "  Group Key: l_returnflag, l_linestatus\n",
      "  ->  Gather Merge  (cost=2958736.61..2958738.01 rows=12 width=236) (actual time=32916.244..32919.654 rows=12 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Sort  (cost=2957736.59..2957736.60 rows=6 width=236) (actual time=32910.412..32910.414 rows=4 loops=3)\n",
      "              Sort Key: l_returnflag, l_linestatus\n",
      "              Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 0:  Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 1:  Sort Method: quicksort  Memory: 27kB\n",
      "              ->  Partial HashAggregate  (cost=2957736.37..2957736.51 rows=6 width=236) (actual time=32910.371..32910.376 rows=4 loops=3)\n",
      "                    Group Key: l_returnflag, l_linestatus\n",
      "                    Batches: 1  Memory Usage: 24kB\n",
      "                    Worker 0:  Batches: 1  Memory Usage: 24kB\n",
      "                    Worker 1:  Batches: 1  Memory Usage: 24kB\n",
      "                    ->  Parallel Bitmap Heap Scan on lineitem  (cost=658763.41..2095601.99 rows=24632411 width=25) (actual time=1411.923..14732.905 rows=19714203 loops=3)\n",
      "                          Recheck Cond: (l_shipdate <= '1998-09-02 00:00:00'::timestamp without time zone)\n",
      "                          Rows Removed by Index Recheck: 270333\n",
      "                          Heap Blocks: exact=11474 lossy=365278\n",
      "                          ->  Bitmap Index Scan on idx_l_shipdate  (cost=0.00..643983.96 rows=59117786 width=0) (actual time=1409.816..1409.816 rows=59142609 loops=1)\n",
      "                                Index Cond: (l_shipdate <= '1998-09-02 00:00:00'::timestamp without time zone)\n",
      "Planning Time: 3.248 ms\n",
      "Execution Time: 32919.832 ms\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = off;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = on;\")\n",
    "    cur.execute(\"SET enable_tidscan = off;\")\n",
    "    cur.execute(\"SET enable_material = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = off;\")\n",
    "    cur.execute(\"SET enable_mergejoin = off;\")\n",
    "    cur.execute(\"SET enable_hashjoin = off;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see an improvement using an index on l_shipdate with a bitmapscan. \n",
    "\n",
    "What I would suggest is to keep the index on l_shipdate since it may help us also in query 14, where shipdate has high selectivity and probably will help more.\n",
    "\n",
    "The index on l_returnflag is not used, I also tried to use an index on (l_returnflag, l_linestatus), but it was not used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate and record the size of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: \n",
      " ('A', 'F', Decimal('377518399'), Decimal('566065727797.25'), Decimal('537759104278.0656'), Decimal('559276670892.116819'), Decimal('25.5009751030070973'), Decimal('38237.151008958546'), Decimal('0.05000657454024320463'), 14804077)\n",
      "Size of query_1 result table: 0.015625 MB\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = off;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_tidscan = off;\")\n",
    "    cur.execute(\"SET enable_material = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = off;\")\n",
    "    cur.execute(\"SET enable_mergejoin = off;\")\n",
    "    cur.execute(\"SET enable_hashjoin = on;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    conn.commit()\n",
    "    \n",
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(f\"CREATE TEMP TABLE temp_result AS {query_1};\")\n",
    "    cur.execute(\"SELECT * FROM temp_result;\")\n",
    "    result = cur.fetchone()\n",
    "    print(f\"First row: \\n {result}\")\n",
    "    cur.execute(\"SELECT pg_total_relation_size('temp_result');\")\n",
    "    size = cur.fetchall()\n",
    "    print(f\"Size of query_1 result table: {size[0][0]/(1024**2)} MB\")\n",
    "    cur.execute(\"DROP TABLE temp_result;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "o_orderdate is quite selective 3 months / 7*12 months, so probably an index can be beneficial.\n",
    "\n",
    "ordering by revenue, which is computed in the query, can't be optimised.\n",
    "\n",
    "what can be optimised is the join, where there are already indexes on the pks.\n",
    "\n",
    "l_return flag is not selective, but we saw it helps in speeding up the query.\n",
    "\n",
    "i put an index on o_custkey and l_orderkey but the first was never used and the second brings worse results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create idx_o_orderdate ON orders (o_orderdate): 11.052881002426147 seconds\n",
      "Size of idx_o_orderdate: 100.1796875 MB\n",
      "Size of idx_o_orderdate: 0.09783172607421875 GB\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_o_orderdate ON orders (o_orderdate);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create idx_o_orderdate ON orders (o_orderdate): {end_time - start_time} seconds\")\n",
    "    cur.execute(\"SELECT pg_relation_size('idx_o_orderdate');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of idx_o_orderdate: {index_size/(1024**2)} MB\")\n",
    "    print(f\"Size of idx_o_orderdate: {index_size/(1024**3)} GB\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index Name: idx_l_shipdate\n",
      "Index Definition: CREATE INDEX idx_l_shipdate ON public.lineitem USING btree (l_shipdate)\n",
      "\n",
      "Index Name: idx_l_returnflag\n",
      "Index Definition: CREATE INDEX idx_l_returnflag ON public.lineitem USING btree (l_returnflag)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_indexes('lineitem')\n",
    "check_indexes('orders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort  (cost=34913159.69..34914554.56 rows=557947 width=279) (actual time=30247.351..30297.432 rows=381105 loops=1)\n",
      "  Sort Key: (sum((lineitem.l_extendedprice * ('1'::numeric - lineitem.l_discount)))) DESC\n",
      "  Sort Method: external merge  Disk: 71032kB\n",
      "  ->  Finalize GroupAggregate  (cost=34545629.72..34714962.30 rows=557947 width=279) (actual time=28776.713..29877.905 rows=381105 loops=1)\n",
      "        Group Key: customer.c_custkey, nation.n_name\n",
      "        ->  Gather Merge  (cost=34545629.72..34703338.40 rows=464956 width=279) (actual time=28776.685..29587.500 rows=451109 loops=1)\n",
      "              Workers Planned: 2\n",
      "              Workers Launched: 2\n",
      "              ->  Partial GroupAggregate  (cost=34544629.70..34648670.92 rows=232478 width=279) (actual time=28761.180..29549.346 rows=150370 loops=3)\n",
      "                    Group Key: customer.c_custkey, nation.n_name\n",
      "                    ->  Incremental Sort  (cost=34544629.70..34642858.97 rows=232478 width=259) (actual time=28761.163..29338.986 rows=382361 loops=3)\n",
      "                          Sort Key: customer.c_custkey, nation.n_name\n",
      "                          Presorted Key: customer.c_custkey\n",
      "                          Full-sort Groups: 11613  Sort Method: quicksort  Average Memory: 32kB  Peak Memory: 32kB\n",
      "                          Worker 0:  Full-sort Groups: 11424  Sort Method: quicksort  Average Memory: 32kB  Peak Memory: 32kB\n",
      "                          Worker 1:  Full-sort Groups: 11502  Sort Method: quicksort  Average Memory: 31kB  Peak Memory: 31kB\n",
      "                          ->  Nested Loop  (cost=34544629.31..34632397.46 rows=232478 width=259) (actual time=28760.833..29226.407 rows=382361 loops=3)\n",
      "                                ->  Merge Join  (cost=34544629.16..34626660.10 rows=232478 width=159) (actual time=28760.665..29124.634 rows=382361 loops=3)\n",
      "                                      Merge Cond: (orders.o_custkey = customer.c_custkey)\n",
      "                                      ->  Sort  (cost=34544628.62..34545209.81 rows=232478 width=16) (actual time=28759.878..28787.251 rows=382361 loops=3)\n",
      "                                            Sort Key: orders.o_custkey\n",
      "                                            Sort Method: external merge  Disk: 10408kB\n",
      "                                            Worker 0:  Sort Method: external merge  Disk: 10232kB\n",
      "                                            Worker 1:  Sort Method: external merge  Disk: 10304kB\n",
      "                                            ->  Merge Join  (cost=33760239.00..34519931.00 rows=232478 width=16) (actual time=24514.568..28512.933 rows=382361 loops=3)\n",
      "                                                  Merge Cond: (lineitem.l_orderkey = orders.o_orderkey)\n",
      "                                                  ->  Sort  (cost=33760235.51..33775488.22 rows=6101082 width=16) (actual time=24511.233..25033.542 rows=4936061 loops=3)\n",
      "                                                        Sort Key: lineitem.l_orderkey\n",
      "                                                        Sort Method: external merge  Disk: 141888kB\n",
      "                                                        Worker 0:  Sort Method: external merge  Disk: 138912kB\n",
      "                                                        Worker 1:  Sort Method: external merge  Disk: 139768kB\n",
      "                                                        ->  Parallel Index Scan using idx_l_returnflag on lineitem  (cost=0.56..32864087.24 rows=6101082 width=16) (actual time=0.451..22524.982 rows=4936061 loops=3)\n",
      "                                                              Index Cond: (l_returnflag = 'R'::bpchar)\n",
      "                                                  ->  Index Scan using orders_pkey on orders  (cost=0.43..725439.44 rows=571566 width=8) (actual time=0.508..3078.443 rows=573130 loops=3)\n",
      "                                                        Filter: ((o_orderdate >= '1993-10-01'::date) AND (o_orderdate < '1994-01-01 00:00:00'::timestamp without time zone))\n",
      "                                                        Rows Removed by Filter: 14426125\n",
      "                                      ->  Index Scan using customer_pkey on customer  (cost=0.43..74794.43 rows=1500000 width=147) (actual time=0.769..202.723 rows=1499992 loops=3)\n",
      "                                ->  Memoize  (cost=0.15..2.17 rows=1 width=108) (actual time=0.000..0.000 rows=1 loops=1147084)\n",
      "                                      Cache Key: customer.c_nationkey\n",
      "                                      Cache Mode: logical\n",
      "                                      Hits: 385706  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                                      Worker 0:  Hits: 379402  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                                      Worker 1:  Hits: 381901  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                                      ->  Index Scan using nation_pkey on nation  (cost=0.14..2.16 rows=1 width=108) (actual time=0.007..0.007 rows=1 loops=75)\n",
      "                                            Index Cond: (n_nationkey = customer.c_nationkey)\n",
      "Planning Time: 2.326 ms\n",
      "Execution Time: 30337.440 ms\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = off;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = off;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_tidscan = off;\")\n",
    "    cur.execute(\"SET enable_material = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = on;\")\n",
    "    cur.execute(\"SET enable_mergejoin = on;\")\n",
    "    cur.execute(\"SET enable_hashjoin = off;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we note that here we get better results using index scan and not bitmapscan.\n",
    "\n",
    "We can see that we get a small improvement using the index on l_returnflag, but the index on orderdate is not used because of the query definition, so we drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(\"DROP INDEX idx_o_orderdate;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate and record the size of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: \n",
      " (1237537, 'Customer#001237537', Decimal('884989.6657'), Decimal('7840.17'), 'RUSSIA                   ', 'FNG6WgB1mopyyY,ajQTU qUPW5o', '32-367-120-4327', 'nag carefully about the regular packages. carefully reg')\n",
      "Size of query_10 result table: 78.5078125 MB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(f\"CREATE TEMP TABLE temp_result AS {query_10};\")\n",
    "    cur.execute(\"SELECT * FROM temp_result;\")\n",
    "    result = cur.fetchone()\n",
    "    print(f\"First row: \\n {result}\")\n",
    "    cur.execute(\"SELECT pg_total_relation_size('temp_result');\")\n",
    "    size = cur.fetchall()\n",
    "    print(f\"Size of query_10 result table: {size[0][0]/(1024**2)} MB\")\n",
    "    cur.execute(\"DROP TABLE temp_result;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shipdate is selective and we know that we have already an index on it, so we can leverage it \n",
    "\n",
    "we know we have a btree index in p_partkey\n",
    "\n",
    "since l_partkey will be fundamental for the next query, we can create now the index and check if it helps/is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create idx_l_partkey ON lineitem (l_partkey): 46.996431827545166 seconds\n",
      "Size of idx_l_partkey: 429.5078125 MB\n",
      "Size of idx_l_partkey: 0.41944122314453125 GB\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_l_partkey ON lineitem (l_partkey);\")    \n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create idx_l_partkey ON lineitem (l_partkey): {end_time - start_time} seconds\")\n",
    "    cur.execute(\"SELECT pg_relation_size('idx_l_partkey');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of idx_l_partkey: {index_size/(1024**2)} MB\")\n",
    "    print(f\"Size of idx_l_partkey: {index_size/(1024**3)} GB\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate  (cost=1752182.24..1752182.26 rows=1 width=32) (actual time=22055.189..22055.719 rows=1 loops=1)\n",
      "  ->  Merge Join  (cost=1627703.30..1737877.40 rows=817419 width=33) (actual time=21220.749..21849.587 rows=749223 loops=1)\n",
      "        Merge Cond: (part.p_partkey = lineitem.l_partkey)\n",
      "        ->  Index Scan using part_pkey on part  (cost=0.43..92913.43 rows=2000000 width=25) (actual time=0.181..333.497 rows=1999994 loops=1)\n",
      "        ->  Sort  (cost=1627702.87..1629746.42 rows=817419 width=16) (actual time=21220.556..21284.103 rows=749223 loops=1)\n",
      "              Sort Key: lineitem.l_partkey\n",
      "              Sort Method: external sort  Disk: 24288kB\n",
      "              ->  Gather  (cost=12155.11..1533457.40 rows=817419 width=16) (actual time=76.699..20330.170 rows=749223 loops=1)\n",
      "                    Workers Planned: 2\n",
      "                    Workers Launched: 2\n",
      "                    ->  Parallel Bitmap Heap Scan on lineitem  (cost=11155.11..1450715.50 rows=340591 width=16) (actual time=71.580..20643.821 rows=249741 loops=3)\n",
      "                          Recheck Cond: ((l_shipdate >= '1995-09-01'::date) AND (l_shipdate < '1995-10-01 00:00:00'::timestamp without time zone))\n",
      "                          Rows Removed by Index Recheck: 6279649\n",
      "                          Heap Blocks: exact=14221 lossy=117469\n",
      "                          ->  Bitmap Index Scan on idx_l_shipdate  (cost=0.00..10950.76 rows=817419 width=0) (actual time=67.802..67.802 rows=749223 loops=1)\n",
      "                                Index Cond: ((l_shipdate >= '1995-09-01'::date) AND (l_shipdate < '1995-10-01 00:00:00'::timestamp without time zone))\n",
      "Planning Time: 9.202 ms\n",
      "Execution Time: 22056.852 ms\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = on;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = on;\")\n",
    "    cur.execute(\"SET enable_mergejoin = on;\")\n",
    "    cur.execute(\"SET enable_hashjoin = off;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    cur.execute(\"SET enable_hashagg = on;\")\n",
    "    \n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the index on l_partkey is not used, but this is in line with the definition of the query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate and record size result table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: \n",
      " (Decimal('16.6475949416150953'),)\n",
      "Size of query_14 result table: 0.015625 MB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(f\"CREATE TEMP TABLE temp_result AS {query_14};\")\n",
    "    cur.execute(\"SELECT * FROM temp_result;\")\n",
    "    result = cur.fetchone()\n",
    "    print(f\"First row: \\n {result}\")\n",
    "    cur.execute(\"SELECT pg_total_relation_size('temp_result');\")\n",
    "    size = cur.fetchall()\n",
    "    print(f\"Size of query_14 result table: {size[0][0]/(1024**2)} MB\")\n",
    "    cur.execute(\"DROP TABLE temp_result;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This query takes a lot of time if we don't use indexes.\n",
    "\n",
    "The index on l_partkey is fundamental.\n",
    "\n",
    "We tried hash indexes on p_brand and p_container but they are not used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index Name: idx_l_shipdate\n",
      "Index Definition: CREATE INDEX idx_l_shipdate ON public.lineitem USING btree (l_shipdate)\n",
      "\n",
      "Index Name: idx_l_returnflag\n",
      "Index Definition: CREATE INDEX idx_l_returnflag ON public.lineitem USING btree (l_returnflag)\n",
      "\n",
      "Index Name: idx_l_partkey\n",
      "Index Definition: CREATE INDEX idx_l_partkey ON public.lineitem USING btree (l_partkey)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_indexes('lineitem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate  (cost=9428617.44..9428617.45 rows=1 width=32) (actual time=10340.977..10340.979 rows=1 loops=1)\n",
      "  ->  Nested Loop  (cost=0.87..9428567.40 rows=20015 width=8) (actual time=4.552..10340.009 rows=5526 loops=1)\n",
      "        ->  Index Scan using part_pkey on part  (cost=0.43..102913.43 rows=2002 width=4) (actual time=0.418..400.213 rows=2044 loops=1)\n",
      "              Filter: ((p_brand = 'Brand#23'::bpchar) AND (p_container = 'MED BOX'::bpchar))\n",
      "              Rows Removed by Filter: 1997956\n",
      "        ->  Index Scan using idx_l_partkey on lineitem  (cost=0.44..4658.06 rows=11 width=17) (actual time=4.653..4.862 rows=3 loops=2044)\n",
      "              Index Cond: (l_partkey = part.p_partkey)\n",
      "              Filter: (l_quantity < (SubPlan 1))\n",
      "              Rows Removed by Filter: 27\n",
      "              SubPlan 1\n",
      "                ->  Aggregate  (cost=137.10..137.11 rows=1 width=32) (actual time=0.149..0.149 rows=1 loops=61385)\n",
      "                      ->  Index Scan using idx_l_partkey on lineitem lineitem_1  (cost=0.44..137.02 rows=33 width=5) (actual time=0.001..0.146 rows=31 loops=61385)\n",
      "                            Index Cond: (l_partkey = part.p_partkey)\n",
      "Planning Time: 0.634 ms\n",
      "Execution Time: 10341.011 ms\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = off;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = on;\")\n",
    "    cur.execute(\"SET enable_nestloop = on;\")\n",
    "    cur.execute(\"SET enable_mergejoin = on;\")\n",
    "    cur.execute(\"SET enable_hashjoin = off;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    cur.execute(\"SET enable_hashagg = on;\")\n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_17, analyze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Decimal('3295493.512857142857'),)\n",
      "Size of query_17 result table: 0.015625 MB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(f\"CREATE TEMP TABLE temp_result AS {query_17};\")\n",
    "    cur.execute(\"SELECT * FROM temp_result;\")\n",
    "    result = cur.fetchall()\n",
    "    for row in result:\n",
    "        print(row)\n",
    "\n",
    "    cur.execute(\"SELECT pg_total_relation_size('temp_result');\")\n",
    "    size = cur.fetchall()\n",
    "    print(f\"Size of query_17 result table: {size[0][0]/(1024**2)} MB\")\n",
    "    cur.execute(\"DROP TABLE temp_result;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexes used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index Name: nation_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX nation_pkey ON public.nation USING btree (n_nationkey)\n",
      "\n",
      "Index Name: part_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX part_pkey ON public.part USING btree (p_partkey)\n",
      "\n",
      "Index Name: supplier_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX supplier_pkey ON public.supplier USING btree (s_suppkey)\n",
      "\n",
      "Index Name: customer_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX customer_pkey ON public.customer USING btree (c_custkey)\n",
      "\n",
      "Index Name: idx_l_shipdate\n",
      "Index Definition: CREATE INDEX idx_l_shipdate ON public.lineitem USING btree (l_shipdate)\n",
      "\n",
      "Index Name: idx_l_returnflag\n",
      "Index Definition: CREATE INDEX idx_l_returnflag ON public.lineitem USING btree (l_returnflag)\n",
      "\n",
      "Index Name: idx_l_partkey\n",
      "Index Definition: CREATE INDEX idx_l_partkey ON public.lineitem USING btree (l_partkey)\n",
      "\n",
      "Index Name: region_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX region_pkey ON public.region USING btree (r_regionkey)\n",
      "\n",
      "Index Name: partsupp_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX partsupp_pkey ON public.partsupp USING btree (ps_partkey, ps_suppkey)\n",
      "\n",
      "Index Name: orders_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX orders_pkey ON public.orders USING btree (o_orderkey)\n",
      "\n",
      "Index Name: idx_o_orderdate\n",
      "Index Definition: CREATE INDEX idx_o_orderdate ON public.orders USING btree (o_orderdate)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = ['nation', 'part', 'supplier', 'customer', 'lineitem', 'region', 'partsupp', 'orders']\n",
    "\n",
    "conn.rollback()\n",
    "for table in a:\n",
    "    check_indexes(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final db size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database size: 21039.29 MB\n",
      "Database size: 20.55 GB \n",
      "\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    cur.execute(\"SELECT pg_database_size('dw_cs');\")\n",
    "    all_rows = cur.fetchall()\n",
    "    print(f\"Database size: {all_rows[0][0] / (1024**2):.2f} MB\")\n",
    "    print(f\"Database size: {all_rows[0][0] / (1024**3):.2f} GB \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.close()\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
