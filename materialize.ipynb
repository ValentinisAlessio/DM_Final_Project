{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import time\n",
    "\n",
    "# establish a connection to the PostgreSQL database\n",
    "conn = psycopg2.connect(\n",
    "    dbname = \"dw_cs\", \n",
    "    user = \"postgres\", \n",
    "    host= 'localhost',\n",
    "    #host = '172.30.160.1',\n",
    "    password = \"postgres\",\n",
    "    port = 5432\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_indexes(table_name):\n",
    "\n",
    "    with conn.cursor() as cur:\n",
    "        query = f\"\"\"\n",
    "        SELECT\n",
    "            indexname,\n",
    "            indexdef\n",
    "        FROM\n",
    "            pg_indexes\n",
    "        WHERE\n",
    "            tablename = '{table_name}';\n",
    "        \"\"\"\n",
    "\n",
    "        cur.execute(query)      \n",
    "        \n",
    "        indexes = cur.fetchall()\n",
    "        \n",
    "        for index in indexes:\n",
    "            print(f\"Index Name: {index[0]}\")\n",
    "            print(f\"Index Definition: {index[1]}\\n\")\n",
    "\n",
    "# function to explain-analyze a query\n",
    "\n",
    "def explain_analyze(query, analyze = True):\n",
    "    conn.rollback()\n",
    "    with conn.cursor() as cur:\n",
    "        if analyze:\n",
    "            cur.execute(f\"EXPLAIN ANALYZE {query}\")\n",
    "        else:\n",
    "            cur.execute(f\"EXPLAIN {query}\")\n",
    "        explain = cur.fetchall()\n",
    "\n",
    "        for line in explain:\n",
    "            print(line[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index Name: nation_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX nation_pkey ON public.nation USING btree (n_nationkey)\n",
      "\n",
      "Index Name: part_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX part_pkey ON public.part USING btree (p_partkey)\n",
      "\n",
      "Index Name: supplier_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX supplier_pkey ON public.supplier USING btree (s_suppkey)\n",
      "\n",
      "Index Name: customer_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX customer_pkey ON public.customer USING btree (c_custkey)\n",
      "\n",
      "Index Name: region_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX region_pkey ON public.region USING btree (r_regionkey)\n",
      "\n",
      "Index Name: partsupp_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX partsupp_pkey ON public.partsupp USING btree (ps_partkey, ps_suppkey)\n",
      "\n",
      "Index Name: orders_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX orders_pkey ON public.orders USING btree (o_orderkey)\n",
      "\n",
      "Index Name: idx_o_orderdate\n",
      "Index Definition: CREATE INDEX idx_o_orderdate ON public.orders USING btree (o_orderdate)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = ['nation', 'part', 'supplier', 'customer', 'lineitem', 'region', 'partsupp', 'orders']\n",
    "\n",
    "conn.rollback()\n",
    "for table in a:\n",
    "    check_indexes(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    query = \"\"\"\n",
    "    drop index if exists idx_l_returnflag;\n",
    "    \"\"\"\n",
    "    cur.execute(query)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 1\n",
    "\n",
    "is it necessary to create a mv for this query? we don't expect so much gain because of the sequential scan on shipdate. we could perform a group by, but in this way we can't add shipdate and adding this information to\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Materialized on part lineitem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to create materialized view: 299.80979585647583 seconds\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = on;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = on;\")\n",
    "    cur.execute(\"SET enable_mergejoin = on;\")\n",
    "    cur.execute(\"SET enable_hashjoin = on;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    cur.execute(\"SET enable_hashagg = on;\")\n",
    "    conn.commit()\n",
    "\n",
    "query_materialized = \"\"\"\n",
    "\n",
    "CREATE MATERIALIZED VIEW part_lineitem AS\n",
    "SELECT\n",
    "    l_returnflag,\n",
    "    l_linestatus,\n",
    "    l_quantity,\n",
    "    l_extendedprice,\n",
    "    l_discount,\n",
    "    l_tax,\n",
    "    l_shipdate,\n",
    "    l_partkey,\n",
    "    p_partkey,\n",
    "    p_brand,\n",
    "    p_container,\n",
    "    SUBSTRING(p_type FROM 1 FOR 5) AS p_type_prefix,\n",
    "    0.2 * AVG(l_quantity) OVER (PARTITION BY l_partkey) AS avg_quantity\n",
    "FROM\n",
    "    lineitem l\n",
    "JOIN\n",
    "    part p ON l.l_partkey = p.p_partkey;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "with conn.cursor() as cur:\n",
    "    start_time = time.time()\n",
    "    cur.execute(query_materialized)\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken to create materialized view: {end_time - start_time} seconds\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we allowed to use hash join since we are not interested in indexes performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of materialised view: 6582.0078125 MB\n",
      "Size of materialised view: 6.427742004394531 GB\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(\"SELECT pg_total_relation_size('part_lineitem');\")\n",
    "    size = cur.fetchall()\n",
    "    print(f\"Size of materialised view: {size[0][0]/(1024**2)} MB\")\n",
    "    print(f\"Size of materialised view: {size[0][0]/(1024**3)} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.rollback()\n",
    "check_indexes('part_lineitem')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = on;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = on;\")\n",
    "    cur.execute(\"SET enable_mergejoin = on;\")\n",
    "    cur.execute(\"SET enable_hashjoin = on;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    cur.execute(\"SET enable_hashagg = on;\")\n",
    "    cur.execute(\"SET enable_material = on;\")\n",
    "    conn.commit()\n",
    "\n",
    "query_14 = \"\"\"\n",
    "SELECT\n",
    "    100.00 * SUM(CASE\n",
    "        WHEN p_type_prefix LIKE 'PROMO'\n",
    "        THEN l_extendedprice * (1 - l_discount)\n",
    "        ELSE 0\n",
    "    END) / SUM(l_extendedprice * (1 - l_discount)) AS promo_revenue\n",
    "FROM\n",
    "    part_lineitem\n",
    "WHERE\n",
    "    l_shipdate >= DATE '1995-09-01'\n",
    "    AND l_shipdate < DATE '1995-09-01' + INTERVAL '1' MONTH;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalize Aggregate  (cost=970607.83..970607.84 rows=1 width=32) (actual time=27278.221..27281.427 rows=1 loops=1)\n",
      "  ->  Gather  (cost=970607.59..970607.80 rows=2 width=64) (actual time=27277.773..27281.379 rows=3 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Partial Aggregate  (cost=969607.59..969607.60 rows=1 width=64) (actual time=27265.298..27265.302 rows=1 loops=3)\n",
      "              ->  Parallel Seq Scan on part_lineitem  (cost=0.00..968870.40 rows=42125 width=96) (actual time=0.432..27126.996 rows=249741 loops=3)\n",
      "                    Filter: ((l_shipdate >= '1995-09-01'::date) AND (l_shipdate < '1995-10-01 00:00:00'::timestamp without time zone))\n",
      "                    Rows Removed by Filter: 19745610\n",
      "Planning Time: 1.226 ms\n",
      "Execution Time: 27281.538 ms\n"
     ]
    }
   ],
   "source": [
    "explain_analyze(query_14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the problem is that it does a seq scan because there is no index on shipdate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size of the result table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: \n",
      " (Decimal('16.6475949416150953'),)\n",
      "Size of query_14 result table: 0.015625 MB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(f\"CREATE TEMP TABLE temp_result AS {query_14};\")\n",
    "    cur.execute(\"SELECT * FROM temp_result;\")\n",
    "    result = cur.fetchone()\n",
    "    print(f\"First row: \\n {result}\")\n",
    "    cur.execute(\"SELECT pg_total_relation_size('temp_result');\")\n",
    "    size = cur.fetchall()\n",
    "    print(f\"Size of query_14 result table: {size[0][0]/(1024**2)} MB\")\n",
    "    cur.execute(\"DROP TABLE temp_result;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we expect to get the most gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_17 = \"\"\"\n",
    "SELECT\n",
    "    SUM(l_extendedprice) / 7.0 AS avg_yearly\n",
    "FROM\n",
    "    part_lineitem\n",
    "WHERE\n",
    "    p_brand = 'Brand#23'\n",
    "    AND p_container = 'MED BOX'\n",
    "    AND l_quantity < avg_quantity;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalize Aggregate  (cost=990933.20..990933.21 rows=1 width=32) (actual time=16940.366..16941.821 rows=1 loops=1)\n",
      "  ->  Gather  (cost=990932.98..990933.19 rows=2 width=32) (actual time=16940.296..16941.812 rows=3 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Partial Aggregate  (cost=989932.98..989932.99 rows=1 width=32) (actual time=16935.286..16935.287 rows=1 loops=3)\n",
      "              ->  Parallel Seq Scan on part_lineitem  (cost=0.00..989932.80 rows=70 width=32) (actual time=50.863..16934.722 rows=1842 loops=3)\n",
      "                    Filter: ((l_quantity < avg_quantity) AND (p_brand = 'Brand#23'::bpchar) AND (p_container = 'MED BOX'::bpchar))\n",
      "                    Rows Removed by Filter: 19993509\n",
      "Planning Time: 2.369 ms\n",
      "Execution Time: 16941.847 ms\n"
     ]
    }
   ],
   "source": [
    "explain_analyze(query_17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size of result table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: \n",
      " (Decimal('3295493.512857142857'),)\n",
      "Size of query_1 result table: 0.015625 MB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(f\"CREATE TEMP TABLE temp_result AS {query_17_1};\")\n",
    "    cur.execute(\"SELECT * FROM temp_result;\")\n",
    "    result = cur.fetchone()\n",
    "    print(f\"First row: \\n {result}\")\n",
    "    cur.execute(\"SELECT pg_total_relation_size('temp_result');\")\n",
    "    size = cur.fetchall()\n",
    "    print(f\"Size of query_1 result table: {size[0][0]/(1024**2)} MB\")\n",
    "    cur.execute(\"DROP TABLE temp_result;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Materialized customer_order_lineitem_nation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hash Join  (cost=773460.56..4508342.52 rows=59986052 width=265)\n",
      "  Hash Cond: (c.c_nationkey = n.n_nationkey)\n",
      "  ->  Hash Join  (cost=773459.00..4324183.78 rows=59986052 width=165)\n",
      "        Hash Cond: (o.o_custkey = c.c_custkey)\n",
      "        ->  Hash Join  (cost=671655.00..3329726.95 rows=59986052 width=22)\n",
      "              Hash Cond: (l.l_orderkey = o.o_orderkey)\n",
      "              ->  Seq Scan on lineitem l  (cost=0.00..1724403.52 rows=59986052 width=18)\n",
      "              ->  Hash  (cost=410912.00..410912.00 rows=15000000 width=12)\n",
      "                    ->  Seq Scan on orders o  (cost=0.00..410912.00 rows=15000000 width=12)\n",
      "        ->  Hash  (cost=50827.00..50827.00 rows=1500000 width=147)\n",
      "              ->  Seq Scan on customer c  (cost=0.00..50827.00 rows=1500000 width=147)\n",
      "  ->  Hash  (cost=1.25..1.25 rows=25 width=108)\n",
      "        ->  Seq Scan on nation n  (cost=0.00..1.25 rows=25 width=108)\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = on;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = on;\")\n",
    "    cur.execute(\"SET enable_mergejoin = on;\")\n",
    "    cur.execute(\"SET enable_hashjoin = on;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    cur.execute(\"SET enable_hashagg = on;\")\n",
    "    conn.commit()\n",
    "\n",
    "query_materialized = \"\"\"\n",
    "\n",
    "CREATE MATERIALIZED VIEW customer_order_lineitem_nation AS\n",
    "SELECT\n",
    "    c.c_custkey,\n",
    "    c.c_name,\n",
    "    c.c_acctbal,\n",
    "    n.n_name,\n",
    "    c.c_address,\n",
    "    c.c_phone,\n",
    "    c.c_comment,\n",
    "    -- c.c_nationkey, not needed in the query, so not included\n",
    "    l.l_returnflag,\n",
    "    -- l.l_orderkey, not needed in the query, so not included\n",
    "    l.l_discount,\n",
    "    l.l_extendedprice,\n",
    "    o.o_orderdate\n",
    "\n",
    "FROM\n",
    "    customer c\n",
    "JOIN\n",
    "    orders o ON c.c_custkey = o.o_custkey\n",
    "JOIN\n",
    "    lineitem l ON l.l_orderkey = o.o_orderkey\n",
    "JOIN\n",
    "    nation n ON c.c_nationkey = n.n_nationkey;\n",
    "\"\"\"\n",
    "\n",
    "explain_analyze(query_materialized, analyze = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"drop materialized view customer_order_lineitem_nation;\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to create materialized view: 551.8813228607178 seconds\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    start_time = time.time()\n",
    "    cur.execute(query_materialized)\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken to create materialized view: {end_time - start_time} seconds\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of materialised view: 12939.0859375 MB\n",
      "Size of materialised view: 12.635826110839844 GB\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(\"SELECT pg_total_relation_size('customer_order_lineitem_nation');\")\n",
    "    size = cur.fetchall()\n",
    "    print(f\"Size of materialised view: {size[0][0]/(1024**2)} MB\")\n",
    "    print(f\"Size of materialised view: {size[0][0]/(1024**3)} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index Name: idx_coln_orderdate\n",
      "Index Definition: CREATE INDEX idx_coln_orderdate ON public.customer_order_lineitem_nation USING btree (o_orderdate)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_indexes('customer_order_lineitem_nation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_10 = \"\"\"\n",
    "SELECT\n",
    "    c_custkey,\n",
    "    c_name,\n",
    "    SUM(l_extendedprice * (1 - l_discount)) AS revenue,\n",
    "    c_acctbal,\n",
    "    n_name,\n",
    "    c_address,\n",
    "    c_phone,\n",
    "    c_comment\n",
    "FROM\n",
    "    customer_order_lineitem_nation\n",
    "WHERE\n",
    "    o_orderdate >= DATE '1993-10-01'\n",
    "    AND o_orderdate < DATE '1993-10-01' + INTERVAL '3' MONTH\n",
    "    AND l_returnflag = 'R'\n",
    "GROUP BY\n",
    "    c_custkey,\n",
    "    c_name,\n",
    "    c_acctbal,\n",
    "    c_phone,\n",
    "    n_name,\n",
    "    c_address,\n",
    "    c_comment\n",
    "ORDER BY\n",
    "    revenue DESC;\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort  (cost=1790056.27..1790057.41 rows=455 width=654) (actual time=62449.084..62499.962 rows=381105 loops=1)\n",
      "  Sort Key: (sum((l_extendedprice * ('1'::numeric - l_discount)))) DESC\n",
      "  Sort Method: external merge  Disk: 71032kB\n",
      "  ->  Finalize GroupAggregate  (cost=1789970.48..1790036.18 rows=455 width=654) (actual time=61336.128..61992.943 rows=381105 loops=1)\n",
      "        Group Key: c_custkey, c_name, c_acctbal, c_phone, n_name, c_address, c_comment\n",
      "        ->  Gather Merge  (cost=1789970.48..1790021.94 rows=380 width=654) (actual time=61329.519..61709.788 rows=449735 loops=1)\n",
      "              Workers Planned: 2\n",
      "              Workers Launched: 2\n",
      "              ->  Partial GroupAggregate  (cost=1788970.46..1788978.06 rows=190 width=654) (actual time=61310.738..61596.312 rows=149912 loops=3)\n",
      "                    Group Key: c_custkey, c_name, c_acctbal, c_phone, n_name, c_address, c_comment\n",
      "                    ->  Sort  (cost=1788970.46..1788970.93 rows=190 width=686) (actual time=61308.963..61351.050 rows=382361 loops=3)\n",
      "                          Sort Key: c_custkey, c_name, c_acctbal, c_phone, n_name, c_address, c_comment\n",
      "                          Sort Method: external merge  Disk: 72920kB\n",
      "                          Worker 0:  Sort Method: external merge  Disk: 72848kB\n",
      "                          Worker 1:  Sort Method: external merge  Disk: 73224kB\n",
      "                          ->  Parallel Seq Scan on customer_order_lineitem_nation  (cost=0.00..1788963.27 rows=190 width=686) (actual time=0.206..58175.996 rows=382361 loops=3)\n",
      "                                Filter: ((o_orderdate >= '1993-10-01'::date) AND (o_orderdate < '1994-01-01 00:00:00'::timestamp without time zone) AND (l_returnflag = 'R'::bpchar))\n",
      "                                Rows Removed by Filter: 19612989\n",
      "Planning Time: 4.648 ms\n",
      "Execution Time: 62608.401 ms\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = on;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = on;\")\n",
    "    cur.execute(\"SET enable_mergejoin = on;\")\n",
    "    cur.execute(\"SET enable_hashjoin = on;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    cur.execute(\"SET enable_hashagg = on;\")\n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: \n",
      " (1237537, 'Customer#001237537', Decimal('884989.6657'), Decimal('7840.17'), 'RUSSIA                   ', 'FNG6WgB1mopyyY,ajQTU qUPW5o', '32-367-120-4327', 'nag carefully about the regular packages. carefully reg')\n",
      "Size of query_10 result table: 78.5078125 MB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(f\"CREATE TEMP TABLE temp_result AS {query_10};\")\n",
    "    cur.execute(\"SELECT * FROM temp_result;\")\n",
    "    result = cur.fetchone()\n",
    "    print(f\"First row: \\n {result}\")\n",
    "    cur.execute(\"SELECT pg_total_relation_size('temp_result');\")\n",
    "    size = cur.fetchall()\n",
    "    print(f\"Size of query_10 result table: {size[0][0]/(1024**2)} MB\")\n",
    "    cur.execute(\"DROP TABLE temp_result;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mixed approach order lineitem part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_10_1 = \"\"\"\n",
    "SELECT\n",
    "    c_custkey,\n",
    "    c_name,\n",
    "    SUM(l_extendedprice * (1 - l_discount)) AS revenue,\n",
    "    c_acctbal,\n",
    "    n_name,\n",
    "    c_address,\n",
    "    c_phone,\n",
    "    c_comment\n",
    "FROM\n",
    "    part_lineitem_order\n",
    "    JOIN customer c ON c.c_custkey = o_custkey\n",
    "    JOIN nation n ON c.c_nationkey = n.n_nationkey\n",
    "WHERE\n",
    "    o_orderdate >= DATE '1993-10-01'\n",
    "    AND o_orderdate < DATE '1993-10-01' + INTERVAL '3' MONTH\n",
    "    AND l_returnflag = 'R'\n",
    "GROUP BY\n",
    "    c_custkey,\n",
    "    c_name,\n",
    "    c_acctbal,\n",
    "    c_phone,\n",
    "    n_name,\n",
    "    c_address,\n",
    "    c_comment\n",
    "ORDER BY\n",
    "    revenue DESC;\n",
    "\"\"\"\n",
    "\n",
    "query_14_1 = \"\"\"\n",
    "SELECT\n",
    "    100.00 * SUM(CASE\n",
    "        WHEN p_type_prefix LIKE 'PROMO'\n",
    "        THEN l_extendedprice * (1 - l_discount)\n",
    "        ELSE 0\n",
    "    END) / SUM(l_extendedprice * (1 - l_discount)) AS promo_revenue\n",
    "FROM\n",
    "    part_lineitem_order\n",
    "WHERE\n",
    "    l_shipdate >= DATE '1995-09-01'\n",
    "    AND l_shipdate < DATE '1995-09-01' + INTERVAL '1' MONTH;\n",
    "\"\"\"\n",
    "\n",
    "query_17_1 = \"\"\"\n",
    "SELECT\n",
    "    SUM(l_extendedprice) / 7.0 AS avg_yearly\n",
    "FROM\n",
    "    part_lineitem_order\n",
    "WHERE\n",
    "    p_brand = 'Brand#23'\n",
    "    AND p_container = 'MED BOX'\n",
    "    AND l_quantity < avg_quantity;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_materialized = \"\"\"\n",
    "\n",
    "CREATE MATERIALIZED VIEW part_lineitem_order AS\n",
    "SELECT\n",
    "    l_returnflag,\n",
    "    l_linestatus,\n",
    "    l_quantity,\n",
    "    l_extendedprice,\n",
    "    l_discount,\n",
    "    l_tax,\n",
    "    l_shipdate,\n",
    "    l_partkey,\n",
    "    p_partkey,\n",
    "    p_brand,\n",
    "    p_container,\n",
    "    SUBSTRING(p_type FROM 1 FOR 5) AS p_type_prefix,\n",
    "    0.2 * AVG(l_quantity) OVER (PARTITION BY l_partkey) AS avg_quantity,\n",
    "    o_orderkey,\n",
    "    o.o_custkey,\n",
    "    o.o_orderdate\n",
    "FROM\n",
    "    lineitem l\n",
    "JOIN\n",
    "    part p ON l.l_partkey = p.p_partkey\n",
    "JOIN\n",
    "    orders o ON l.l_orderkey = o.o_orderkey;\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    start_time = time.time()\n",
    "    cur.execute(query_materialized)\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken to create materialized view: {end_time - start_time} seconds\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index Name: idx_plo_shipdate\n",
      "Index Definition: CREATE INDEX idx_plo_shipdate ON public.part_lineitem_order USING btree (l_shipdate)\n",
      "\n",
      "Index Name: idx_plo_o_orderdate\n",
      "Index Definition: CREATE INDEX idx_plo_o_orderdate ON public.part_lineitem_order USING btree (o_orderdate)\n",
      "\n",
      "Index Name: idx_plo_brand\n",
      "Index Definition: CREATE INDEX idx_plo_brand ON public.part_lineitem_order USING btree (p_brand)\n",
      "\n",
      "Index Name: idx_plo_container\n",
      "Index Definition: CREATE INDEX idx_plo_container ON public.part_lineitem_order USING btree (p_container)\n",
      "\n",
      "Index Name: idx_plo_custkey\n",
      "Index Definition: CREATE INDEX idx_plo_custkey ON public.part_lineitem_order USING btree (o_custkey)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_indexes('part_lineitem_order')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort  (cost=1776499.22..1777907.79 rows=563430 width=279) (actual time=25666.602..25716.922 rows=381105 loops=1)\n",
      "  Sort Key: (sum((part_lineitem_order.l_extendedprice * ('1'::numeric - part_lineitem_order.l_discount)))) DESC\n",
      "  Sort Method: external merge  Disk: 71032kB\n",
      "  ->  GroupAggregate  (cost=1371906.12..1576317.73 rows=563430 width=279) (actual time=23400.287..25290.271 rows=381105 loops=1)\n",
      "        Group Key: c.c_custkey, n.n_name\n",
      "        ->  Incremental Sort  (cost=1371906.12..1562231.98 rows=563430 width=259) (actual time=23400.272..24731.624 rows=1147084 loops=1)\n",
      "              Sort Key: c.c_custkey, n.n_name\n",
      "              Presorted Key: c.c_custkey\n",
      "              Full-sort Groups: 34124  Sort Method: quicksort  Average Memory: 31kB  Peak Memory: 31kB\n",
      "              ->  Nested Loop  (cost=1371905.81..1536877.63 rows=563430 width=259) (actual time=23400.199..24404.519 rows=1147084 loops=1)\n",
      "                    ->  Merge Join  (cost=1371905.66..1523099.92 rows=563430 width=159) (actual time=23399.779..24115.487 rows=1147084 loops=1)\n",
      "                          Merge Cond: (part_lineitem_order.o_custkey = c.c_custkey)\n",
      "                          ->  Gather Merge  (cost=1371898.58..1437519.28 rows=563430 width=16) (actual time=23399.273..23592.362 rows=1147084 loops=1)\n",
      "                                Workers Planned: 2\n",
      "                                Workers Launched: 2\n",
      "                                ->  Sort  (cost=1370898.55..1371485.46 rows=234762 width=16) (actual time=23377.722..23428.443 rows=382361 loops=3)\n",
      "                                      Sort Key: part_lineitem_order.o_custkey\n",
      "                                      Sort Method: external merge  Disk: 10888kB\n",
      "                                      Worker 0:  Sort Method: external merge  Disk: 10912kB\n",
      "                                      Worker 1:  Sort Method: external merge  Disk: 10888kB\n",
      "                                      ->  Parallel Seq Scan on part_lineitem_order  (cost=0.00..1345942.30 rows=234762 width=16) (actual time=0.397..22980.568 rows=382361 loops=3)\n",
      "                                            Filter: ((o_orderdate >= '1993-10-01'::date) AND (o_orderdate < '1994-01-01 00:00:00'::timestamp without time zone) AND (l_returnflag = 'R'::bpchar))\n",
      "                                            Rows Removed by Filter: 19612989\n",
      "                          ->  Index Scan using customer_pkey on customer c  (cost=0.43..74794.43 rows=1500000 width=147) (actual time=0.486..301.297 rows=1499998 loops=1)\n",
      "                    ->  Memoize  (cost=0.15..0.17 rows=1 width=108) (actual time=0.000..0.000 rows=1 loops=1147084)\n",
      "                          Cache Key: c.c_nationkey\n",
      "                          Cache Mode: logical\n",
      "                          Hits: 1147059  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                          ->  Index Scan using nation_pkey on nation n  (cost=0.14..0.16 rows=1 width=108) (actual time=0.017..0.017 rows=1 loops=25)\n",
      "                                Index Cond: (n_nationkey = c.c_nationkey)\n",
      "Planning Time: 5.175 ms\n",
      "Execution Time: 25747.872 ms\n"
     ]
    }
   ],
   "source": [
    "explain_analyze(query_10_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(\"drop index if exists idx_plo_shipdate;\")\n",
    "    cur.execute(\"drop index if exists idx_plo_o_orderdate;\")\n",
    "    cur.execute(\"drop index if exists idx_plo_brand;\")\n",
    "    cur.execute(\"drop index if exists idx_plo_container;\")\n",
    "    cur.execute(\"drop index if exists idx_plo_custkey;\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalize Aggregate  (cost=1289948.88..1289948.89 rows=1 width=32) (actual time=22442.989..22445.220 rows=1 loops=1)\n",
      "  ->  Gather  (cost=1289948.64..1289948.85 rows=2 width=64) (actual time=22442.756..22445.209 rows=3 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Partial Aggregate  (cost=1288948.64..1288948.65 rows=1 width=64) (actual time=22422.299..22422.300 rows=1 loops=3)\n",
      "              ->  Parallel Seq Scan on part_lineitem_order  (cost=0.00..1283456.82 rows=313818 width=18) (actual time=1.258..22276.169 rows=249741 loops=3)\n",
      "                    Filter: ((l_shipdate >= '1995-09-01'::date) AND (l_shipdate < '1995-10-01 00:00:00'::timestamp without time zone))\n",
      "                    Rows Removed by Filter: 19745610\n",
      "Planning Time: 0.095 ms\n",
      "Execution Time: 22445.263 ms\n"
     ]
    }
   ],
   "source": [
    "explain_analyze(query_14_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalize Aggregate  (cost=1346964.43..1346964.44 rows=1 width=32) (actual time=22503.711..22505.520 rows=1 loops=1)\n",
      "  ->  Gather  (cost=1346964.20..1346964.41 rows=2 width=32) (actual time=22503.504..22505.489 rows=3 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Partial Aggregate  (cost=1345964.20..1345964.21 rows=1 width=32) (actual time=22498.851..22498.852 rows=1 loops=3)\n",
      "              ->  Parallel Seq Scan on part_lineitem_order  (cost=0.00..1345942.30 rows=8762 width=8) (actual time=20.351..22498.051 rows=1842 loops=3)\n",
      "                    Filter: ((l_quantity < avg_quantity) AND (p_brand = 'Brand#23'::bpchar) AND (p_container = 'MED BOX'::bpchar))\n",
      "                    Rows Removed by Filter: 19993509\n",
      "Planning Time: 0.161 ms\n",
      "Execution Time: 22505.596 ms\n"
     ]
    }
   ],
   "source": [
    "explain_analyze(query_17_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## indexes on order_lineitem_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(\"drop index if exists idx_plo_shipdate;\")\n",
    "    cur.execute(\"drop index if exists idx_plo_o_orderdate;\")\n",
    "    cur.execute(\"drop index if exists idx_plo_brand;\")\n",
    "    cur.execute(\"drop index if exists idx_plo_container;\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create idx_plo_shipdate ON part_lineitem_order (l_shipdate): 42.57509398460388 seconds\n",
      "Size of idx_plo_shipdate: 397.546875 MB\n",
      "Size of idx_plo_shipdate: 0.3882293701171875 GB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_plo_shipdate ON part_lineitem_order (l_shipdate);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create idx_plo_shipdate ON part_lineitem_order (l_shipdate): {end_time - start_time} seconds\")\n",
    "\n",
    "    cur.execute(\"SELECT pg_relation_size('idx_plo_shipdate');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of idx_plo_shipdate: {index_size/(1024**2)} MB\")\n",
    "    print(f\"Size of idx_plo_shipdate: {index_size/(1024**3)} GB\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create idx_plo_o_orderdate ON part_lineitem_order (o_orderdate): 44.36399292945862 seconds\n",
      "Size of idx_plo_o_orderdate: 397.5078125 MB\n",
      "Size of idx_plo_o_orderdate: 0.38819122314453125 GB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_plo_o_orderdate ON part_lineitem_order (o_orderdate);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create idx_plo_o_orderdate ON part_lineitem_order (o_orderdate): {end_time - start_time} seconds\")\n",
    "\n",
    "    cur.execute(\"SELECT pg_relation_size('idx_plo_o_orderdate');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of idx_plo_o_orderdate: {index_size/(1024**2)} MB\")\n",
    "    print(f\"Size of idx_plo_o_orderdate: {index_size/(1024**3)} GB\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create idx_plo_brand ON part_lineitem_order (p_brand): 58.09077000617981 seconds\n",
      "Size of idx_plo_brand: 403.140625 MB\n",
      "Size of idx_plo_brand: 0.3936920166015625 GB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_plo_brand ON part_lineitem_order (p_brand);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create idx_plo_brand ON part_lineitem_order (p_brand): {end_time - start_time} seconds\")\n",
    "\n",
    "    cur.execute(\"SELECT pg_relation_size('idx_plo_brand');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of idx_plo_brand: {index_size/(1024**2)} MB\")\n",
    "    print(f\"Size of idx_plo_brand: {index_size/(1024**3)} GB\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create idx_plo_container ON part_lineitem_order (p_container): 64.20518612861633 seconds\n",
      "Size of idx_plo_container: 403.1484375 MB\n",
      "Size of idx_plo_container: 0.39369964599609375 GB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_plo_container ON part_lineitem_order (p_container);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create idx_plo_container ON part_lineitem_order (p_container): {end_time - start_time} seconds\")\n",
    "\n",
    "    cur.execute(\"SELECT pg_relation_size('idx_plo_container');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of idx_plo_container: {index_size/(1024**2)} MB\")\n",
    "    print(f\"Size of idx_plo_container: {index_size/(1024**3)} GB\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort  (cost=1758138.74..1759547.31 rows=563430 width=279) (actual time=31916.069..31967.507 rows=381105 loops=1)\n",
      "  Sort Key: (sum((part_lineitem_order.l_extendedprice * ('1'::numeric - part_lineitem_order.l_discount)))) DESC\n",
      "  Sort Method: external merge  Disk: 71032kB\n",
      "  ->  Finalize GroupAggregate  (cost=1387783.36..1557957.25 rows=563430 width=279) (actual time=30158.032..31479.786 rows=381105 loops=1)\n",
      "        Group Key: c.c_custkey, n.n_name\n",
      "        ->  Gather Merge  (cost=1387783.36..1546219.13 rows=469524 width=279) (actual time=30158.012..31098.325 rows=719453 loops=1)\n",
      "              Workers Planned: 2\n",
      "              Workers Launched: 2\n",
      "              ->  Partial GroupAggregate  (cost=1386783.34..1491024.39 rows=234762 width=279) (actual time=30143.852..31001.176 rows=239818 loops=3)\n",
      "                    Group Key: c.c_custkey, n.n_name\n",
      "                    ->  Incremental Sort  (cost=1386783.34..1485155.34 rows=234762 width=259) (actual time=30143.343..30741.911 rows=382361 loops=3)\n",
      "                          Sort Key: c.c_custkey, n.n_name\n",
      "                          Presorted Key: c.c_custkey\n",
      "                          Full-sort Groups: 11722  Sort Method: quicksort  Average Memory: 32kB  Peak Memory: 32kB\n",
      "                          Worker 0:  Full-sort Groups: 11720  Sort Method: quicksort  Average Memory: 31kB  Peak Memory: 31kB\n",
      "                          Worker 1:  Full-sort Groups: 11805  Sort Method: quicksort  Average Memory: 32kB  Peak Memory: 32kB\n",
      "                          ->  Nested Loop  (cost=1386782.95..1474591.05 rows=234762 width=259) (actual time=30142.625..30634.072 rows=382361 loops=3)\n",
      "                                ->  Merge Join  (cost=1386782.81..1468848.01 rows=234762 width=159) (actual time=30141.586..30529.706 rows=382361 loops=3)\n",
      "                                      Merge Cond: (part_lineitem_order.o_custkey = c.c_custkey)\n",
      "                                      ->  Sort  (cost=1386782.26..1387369.17 rows=234762 width=16) (actual time=30140.667..30188.796 rows=382361 loops=3)\n",
      "                                            Sort Key: part_lineitem_order.o_custkey\n",
      "                                            Sort Method: external merge  Disk: 10832kB\n",
      "                                            Worker 0:  Sort Method: external merge  Disk: 10872kB\n",
      "                                            Worker 1:  Sort Method: external merge  Disk: 10952kB\n",
      "                                            ->  Parallel Bitmap Heap Scan on part_lineitem_order  (cost=31052.20..1361826.01 rows=234762 width=16) (actual time=143.025..29332.519 rows=382361 loops=3)\n",
      "                                                  Recheck Cond: ((o_orderdate >= '1993-10-01'::date) AND (o_orderdate < '1994-01-01 00:00:00'::timestamp without time zone))\n",
      "                                                  Rows Removed by Index Recheck: 16710235\n",
      "                                                  Filter: (l_returnflag = 'R'::bpchar)\n",
      "                                                  Rows Removed by Filter: 381947\n",
      "                                                  Heap Blocks: exact=15285 lossy=263933\n",
      "                                                  ->  Bitmap Index Scan on idx_plo_o_orderdate  (cost=0.00..30911.34 rows=2307878 width=0) (actual time=147.046..147.047 rows=2292924 loops=1)\n",
      "                                                        Index Cond: ((o_orderdate >= '1993-10-01'::date) AND (o_orderdate < '1994-01-01 00:00:00'::timestamp without time zone))\n",
      "                                      ->  Index Scan using customer_pkey on customer c  (cost=0.43..74794.43 rows=1500000 width=147) (actual time=0.900..201.462 rows=1499996 loops=3)\n",
      "                                ->  Memoize  (cost=0.15..0.17 rows=1 width=108) (actual time=0.000..0.000 rows=1 loops=1147084)\n",
      "                                      Cache Key: c.c_nationkey\n",
      "                                      Cache Mode: logical\n",
      "                                      Hits: 381443  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                                      Worker 0:  Hits: 381447  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                                      Worker 1:  Hits: 384119  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                                      ->  Index Scan using nation_pkey on nation n  (cost=0.14..0.16 rows=1 width=108) (actual time=0.026..0.026 rows=1 loops=75)\n",
      "                                            Index Cond: (n_nationkey = c.c_nationkey)\n",
      "Planning Time: 5.545 ms\n",
      "Execution Time: 31998.846 ms\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "\n",
    "    cur.execute(\"SET enable_seqscan = off;\")\n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_10_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalize Aggregate  (cost=1275875.34..1275875.35 rows=1 width=32) (actual time=21797.578..21809.007 rows=1 loops=1)\n",
      "  ->  Gather  (cost=1275875.10..1275875.31 rows=2 width=64) (actual time=21796.586..21808.983 rows=3 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Partial Aggregate  (cost=1274875.10..1274875.11 rows=1 width=64) (actual time=21771.187..21771.188 rows=1 loops=3)\n",
      "              ->  Parallel Bitmap Heap Scan on part_lineitem_order  (cost=10276.50..1269383.28 rows=313818 width=18) (actual time=69.307..21375.595 rows=249741 loops=3)\n",
      "                    Recheck Cond: ((l_shipdate >= '1995-09-01'::date) AND (l_shipdate < '1995-10-01 00:00:00'::timestamp without time zone))\n",
      "                    Rows Removed by Index Recheck: 9982884\n",
      "                    Heap Blocks: exact=16183 lossy=155307\n",
      "                    ->  Bitmap Index Scan on idx_plo_shipdate  (cost=0.00..10088.20 rows=753164 width=0) (actual time=83.657..83.657 rows=749223 loops=1)\n",
      "                          Index Cond: ((l_shipdate >= '1995-09-01'::date) AND (l_shipdate < '1995-10-01 00:00:00'::timestamp without time zone))\n",
      "Planning Time: 4.199 ms\n",
      "Execution Time: 21809.071 ms\n"
     ]
    }
   ],
   "source": [
    "explain_analyze(query_14_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate  (cost=241282.81..241282.83 rows=1 width=32) (actual time=1598.072..1598.078 rows=1 loops=1)\n",
      "  ->  Bitmap Heap Scan on part_lineitem_order  (cost=43634.94..241230.24 rows=21028 width=8) (actual time=264.046..1597.398 rows=5526 loops=1)\n",
      "        Recheck Cond: ((p_container = 'MED BOX'::bpchar) AND (p_brand = 'Brand#23'::bpchar))\n",
      "        Rows Removed by Index Recheck: 304391\n",
      "        Filter: (l_quantity < avg_quantity)\n",
      "        Rows Removed by Filter: 55859\n",
      "        Heap Blocks: exact=3130 lossy=4537\n",
      "        ->  BitmapAnd  (cost=43634.94..43634.94 rows=63084 width=0) (actual time=262.502..262.505 rows=0 loops=1)\n",
      "              ->  Bitmap Index Scan on idx_plo_container  (cost=0.00..17042.85 rows=1557638 width=0) (actual time=158.896..158.896 rows=1504601 loops=1)\n",
      "                    Index Cond: (p_container = 'MED BOX'::bpchar)\n",
      "              ->  Bitmap Index Scan on idx_plo_brand  (cost=0.00..26581.33 rows=2429435 width=0) (actual time=99.333..99.333 rows=2391264 loops=1)\n",
      "                    Index Cond: (p_brand = 'Brand#23'::bpchar)\n",
      "Planning Time: 0.162 ms\n",
      "Execution Time: 1598.595 ms\n"
     ]
    }
   ],
   "source": [
    "explain_analyze(query_17_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Materialisation + indexes\n",
    "\n",
    "to optimize query 14 we could put an index on shipdate\n",
    "\n",
    "to optimize query 17 we could put an index on l_partkey\n",
    "\n",
    "to optimizze query 10 we could put an index on orderdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create idx_pl_shipdate ON part_lineitem (l_shipdate): 41.588475942611694 seconds\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_pl_shipdate ON part_lineitem (l_shipdate);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create idx_pl_shipdate ON part_lineitem (l_shipdate): {end_time - start_time} seconds\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create idx_pl_brand ON part_lineitem (p_brand): 57.2357919216156 seconds\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_pl_brand ON part_lineitem (p_brand);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create idx_pl_brand ON part_lineitem (p_brand): {end_time - start_time} seconds\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create idx_pl_container ON part_lineitem (p_container): 59.95706009864807 seconds\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_pl_container ON part_lineitem (p_container);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create idx_pl_container ON part_lineitem (p_container): {end_time - start_time} seconds\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalize Aggregate  (cost=1275875.34..1275875.35 rows=1 width=32) (actual time=22617.626..22627.679 rows=1 loops=1)\n",
      "  ->  Gather  (cost=1275875.10..1275875.31 rows=2 width=64) (actual time=22616.526..22627.654 rows=3 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Partial Aggregate  (cost=1274875.10..1274875.11 rows=1 width=64) (actual time=22576.878..22576.880 rows=1 loops=3)\n",
      "              ->  Parallel Bitmap Heap Scan on part_lineitem_order  (cost=10276.50..1269383.28 rows=313818 width=18) (actual time=103.201..22201.052 rows=249741 loops=3)\n",
      "                    Recheck Cond: ((l_shipdate >= '1995-09-01'::date) AND (l_shipdate < '1995-10-01 00:00:00'::timestamp without time zone))\n",
      "                    Rows Removed by Index Recheck: 9982884\n",
      "                    Heap Blocks: exact=16002 lossy=154642\n",
      "                    ->  Bitmap Index Scan on idx_plo_shipdate  (cost=0.00..10088.20 rows=753164 width=0) (actual time=131.234..131.235 rows=749223 loops=1)\n",
      "                          Index Cond: ((l_shipdate >= '1995-09-01'::date) AND (l_shipdate < '1995-10-01 00:00:00'::timestamp without time zone))\n",
      "Planning Time: 1.247 ms\n",
      "Execution Time: 22628.237 ms\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = off;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_material = on;\")\n",
    "    conn.commit()\n",
    "    \n",
    "explain_analyze(query_14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate  (cost=241282.81..241282.83 rows=1 width=32) (actual time=1665.278..1665.282 rows=1 loops=1)\n",
      "  ->  Bitmap Heap Scan on part_lineitem_order  (cost=43634.94..241230.24 rows=21028 width=8) (actual time=139.719..1664.263 rows=5526 loops=1)\n",
      "        Recheck Cond: ((p_container = 'MED BOX'::bpchar) AND (p_brand = 'Brand#23'::bpchar))\n",
      "        Rows Removed by Index Recheck: 304391\n",
      "        Filter: (l_quantity < avg_quantity)\n",
      "        Rows Removed by Filter: 55859\n",
      "        Heap Blocks: exact=3130 lossy=4537\n",
      "        ->  BitmapAnd  (cost=43634.94..43634.94 rows=63084 width=0) (actual time=138.213..138.216 rows=0 loops=1)\n",
      "              ->  Bitmap Index Scan on idx_plo_container  (cost=0.00..17042.85 rows=1557638 width=0) (actual time=57.710..57.711 rows=1504601 loops=1)\n",
      "                    Index Cond: (p_container = 'MED BOX'::bpchar)\n",
      "              ->  Bitmap Index Scan on idx_plo_brand  (cost=0.00..26581.33 rows=2429435 width=0) (actual time=76.879..76.880 rows=2391264 loops=1)\n",
      "                    Index Cond: (p_brand = 'Brand#23'::bpchar)\n",
      "Planning Time: 0.141 ms\n",
      "Execution Time: 1665.976 ms\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = off;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_material = on;\")\n",
    "    conn.commit()\n",
    "    \n",
    "explain_analyze(query_17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index Name: idx_pl_shipdate\n",
      "Index Definition: CREATE INDEX idx_pl_shipdate ON public.part_lineitem USING btree (l_shipdate)\n",
      "\n",
      "Index Name: idx_pl_brand\n",
      "Index Definition: CREATE INDEX idx_pl_brand ON public.part_lineitem USING btree (p_brand)\n",
      "\n",
      "Index Name: idx_pl_container\n",
      "Index Definition: CREATE INDEX idx_pl_container ON public.part_lineitem USING btree (p_container)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_indexes('part_lineitem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create idx_coln_orderdate ON customer_order_lineitem_nation (o_orderdate): 49.34825897216797 seconds\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_coln_orderdate ON customer_order_lineitem_nation (o_orderdate);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create idx_coln_orderdate ON customer_order_lineitem_nation (o_orderdate): {end_time - start_time} seconds\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index Name: idx_coln_orderdate\n",
      "Index Definition: CREATE INDEX idx_coln_orderdate ON public.customer_order_lineitem_nation USING btree (o_orderdate)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_indexes('customer_order_lineitem_nation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create idx_coln_customer ON customer_order_lineitem_nation (c_custkey): 64.0774028301239 seconds\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_coln_customer ON customer_order_lineitem_nation (c_custkey);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create idx_coln_customer ON customer_order_lineitem_nation (c_custkey): {end_time - start_time} seconds\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = off;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = off;\")\n",
    "    cur.execute(\"SET enable_material = on;\")\n",
    "    conn.commit()\n",
    "explain_analyze(query_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We can see that the gain of using 2 different materialized views wrt using a single one with part order lineitem are the same. the only useful indexes on part order lineitem are p_brand and p_container that speed up a lot the query.\n",
    "\n",
    "since we risparmiare time and space by creating only one mv, we choose to use that, also because it can be helpful for many other queries, in fact the tables part order lineitem are the \"core\" of the db."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
