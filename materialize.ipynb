{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import time\n",
    "\n",
    "# establish a connection to the PostgreSQL database\n",
    "conn = psycopg2.connect(\n",
    "    dbname = \"dw_cs\", \n",
    "    user = \"postgres\", \n",
    "    host= 'localhost',      # change this to your host\n",
    "    password = \"postgres\",  # change this to your password\n",
    "    port = 5432\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_indexes(table_name):\n",
    "\n",
    "    with conn.cursor() as cur:\n",
    "        query = f\"\"\"\n",
    "        SELECT\n",
    "            indexname,\n",
    "            indexdef\n",
    "        FROM\n",
    "            pg_indexes\n",
    "        WHERE\n",
    "            tablename = '{table_name}';\n",
    "        \"\"\"\n",
    "\n",
    "        cur.execute(query)      \n",
    "        \n",
    "        indexes = cur.fetchall()\n",
    "        \n",
    "        for index in indexes:\n",
    "            print(f\"Index Name: {index[0]}\")\n",
    "            print(f\"Index Definition: {index[1]}\\n\")\n",
    "\n",
    "# function to explain-analyze a query\n",
    "\n",
    "def explain_analyze(query, analyze = True):\n",
    "    conn.rollback()\n",
    "    with conn.cursor() as cur:\n",
    "        if analyze:\n",
    "            cur.execute(f\"EXPLAIN ANALYZE {query}\")\n",
    "        else:\n",
    "            cur.execute(f\"EXPLAIN {query}\")\n",
    "        explain = cur.fetchall()\n",
    "\n",
    "        for line in explain:\n",
    "            print(line[0])\n",
    "            \n",
    "\n",
    "def collect_size(table : str) -> None:\n",
    "    conn.rollback()\n",
    "    with conn.cursor() as cur:\n",
    "\n",
    "        cur.execute(f\"SELECT pg_relation_size('{table}');\")\n",
    "        size = cur.fetchall()\n",
    "        size_mb = size[0][0] / (1024**2)\n",
    "        size_gb = size[0][0] / (1024**3)\n",
    "        print(f\"Relation size: {size_mb:.2f} MB\")\n",
    "        print(f\"Relation size: {size_gb:.2f} GB\")\n",
    "\n",
    "        cur.execute(f\"SELECT pg_table_size('{table}');\")\n",
    "        size = cur.fetchall()\n",
    "        size_mb = size[0][0] / (1024**2)\n",
    "        size_gb = size[0][0] / (1024**3)\n",
    "        print(f\"Table (relation + TOAST) size: {size_mb:.2f} MB\")\n",
    "        print(f\"Table (relation + TOAST) size: {size_gb:.2f} GB\")\n",
    "\n",
    "        cur.execute(f\"SELECT pg_indexes_size('{table}');\")\n",
    "        size = cur.fetchall()\n",
    "        print(f\"Index size for table {table}: {size[0][0] / (1024**2):.2f} MB\")\n",
    "        print(f\"Index size for table {table}: {size[0][0] / (1024**3):.2f} GB\")\n",
    "\n",
    "        cur.execute(f\"SELECT pg_total_relation_size('{table}');\")\n",
    "        size = cur.fetchall()\n",
    "        size_mb = size[0][0] / (1024**2)\n",
    "        size_gb = size[0][0] / (1024**3)\n",
    "        print(f\"Total size (relation + TOAST + index): {size_mb:.2f} MB\")\n",
    "        print(f\"Total size (relation + TOAST + index): {size_gb:.2f} GB \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index Name: nation_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX nation_pkey ON public.nation USING btree (n_nationkey)\n",
      "\n",
      "Index Name: part_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX part_pkey ON public.part USING btree (p_partkey)\n",
      "\n",
      "Index Name: supplier_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX supplier_pkey ON public.supplier USING btree (s_suppkey)\n",
      "\n",
      "Index Name: customer_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX customer_pkey ON public.customer USING btree (c_custkey)\n",
      "\n",
      "Index Name: region_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX region_pkey ON public.region USING btree (r_regionkey)\n",
      "\n",
      "Index Name: partsupp_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX partsupp_pkey ON public.partsupp USING btree (ps_partkey, ps_suppkey)\n",
      "\n",
      "Index Name: orders_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX orders_pkey ON public.orders USING btree (o_orderkey)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = ['nation', 'part', 'supplier', 'customer', 'lineitem', 'region', 'partsupp', 'orders']\n",
    "\n",
    "conn.rollback()\n",
    "for table in a:\n",
    "    check_indexes(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 1\n",
    "\n",
    "Is it useful to create a mv for this query? We don't expect so much gain because of the sequential scan on shipdate.\n",
    "\n",
    "We try to filter for shipdate, creating a mv, then we put an index on (l_returnflag, l_linestatus) and then we perform a CLUSTER on this index.\n",
    "\n",
    "We don't do this on the original table for two reasons: one is to use a mv and the other is not to modify the original table and possibly alter the timings of the queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m cur\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDROP MATERIALIZED VIEW IF EXISTS lineitem_aggregates;\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 29\u001b[0m \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_materialized\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime taken to create materialized view: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/encodings/utf_8.py:15\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(input, errors)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m### Codec APIs\u001b[39;00m\n\u001b[1;32m     13\u001b[0m encode \u001b[38;5;241m=\u001b[39m codecs\u001b[38;5;241m.\u001b[39mutf_8_encode\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28minput\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mutf_8_decode(\u001b[38;5;28minput\u001b[39m, errors, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mIncrementalEncoder\u001b[39;00m(codecs\u001b[38;5;241m.\u001b[39mIncrementalEncoder):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "query_materialized = \"\"\"\n",
    "\n",
    "CREATE MATERIALIZED VIEW lineitem_aggregates AS\n",
    "SELECT\n",
    "    l_returnflag,\n",
    "    l_linestatus,\n",
    "    l_extendedprice,\n",
    "    l_discount,\n",
    "    l_tax,\n",
    "    l_quantity\n",
    "FROM\n",
    "    lineitem\n",
    "WHERE \n",
    "    l_shipdate <= DATE '1998-12-01' - INTERVAL '90' DAY;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    start_time = time.time()\n",
    "    cur.execute(query_materialized)\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken to create materialized view: {end_time - start_time} seconds\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of materialised view: 3387.5078125 MB\n",
      "Size of materialised view: 3.3081130981445312 GB\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(\"SELECT pg_total_relation_size('lineitem_aggregates');\")\n",
    "    size = cur.fetchall()\n",
    "    print(f\"Size of materialised view: {size[0][0]/(1024**2)} MB\")\n",
    "    print(f\"Size of materialised view: {size[0][0]/(1024**3)} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_1 = \"\"\"\n",
    "SELECT\n",
    "    l_returnflag,\n",
    "    l_linestatus,\n",
    "    SUM(l_quantity) AS sum_qty,\n",
    "    SUM(l_extendedprice) AS sum_base_price,\n",
    "    SUM(l_extendedprice * (1 - l_discount)) AS sum_disc_price,\n",
    "    SUM(l_extendedprice * (1 - l_discount) * (1 + l_tax)) AS sum_charge,\n",
    "    AVG(l_quantity) AS avg_qty,\n",
    "    AVG(l_extendedprice) AS avg_price,\n",
    "    AVG(l_discount) AS avg_disc,\n",
    "    COUNT(*) AS count_order\n",
    "FROM\n",
    "    lineitem_aggregates\n",
    "GROUP BY\n",
    "    l_returnflag,\n",
    "    l_linestatus\n",
    "ORDER BY\n",
    "    l_returnflag,\n",
    "    l_linestatus;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalize GroupAggregate  (cost=2736532.36..2749566.35 rows=40000 width=248) (actual time=32398.445..32399.860 rows=4 loops=1)\n",
      "  Group Key: l_returnflag, l_linestatus\n",
      "  ->  Gather Merge  (cost=2736532.36..2745866.35 rows=80000 width=248) (actual time=32398.421..32399.822 rows=12 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Sort  (cost=2735532.34..2735632.34 rows=40000 width=248) (actual time=32341.086..32341.089 rows=4 loops=3)\n",
      "              Sort Key: l_returnflag, l_linestatus\n",
      "              Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 0:  Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 1:  Sort Method: quicksort  Memory: 27kB\n",
      "              ->  Partial HashAggregate  (cost=2378645.97..2727823.30 rows=40000 width=248) (actual time=32341.002..32341.044 rows=4 loops=3)\n",
      "                    Group Key: l_returnflag, l_linestatus\n",
      "                    Planned Partitions: 8  Batches: 1  Memory Usage: 217kB\n",
      "                    Worker 0:  Batches: 1  Memory Usage: 217kB\n",
      "                    Worker 1:  Batches: 1  Memory Usage: 217kB\n",
      "                    ->  Parallel Seq Scan on lineitem_aggregates  (cost=0.00..518513.33 rows=8491333 width=144) (actual time=0.254..16060.527 rows=19714203 loops=3)\n",
      "Planning Time: 1.529 ms\n",
      "Execution Time: 32400.631 ms\n",
      "Finalize GroupAggregate  (cost=2736532.36..2749566.35 rows=40000 width=248) (actual time=124490.976..124492.509 rows=4 loops=1)\n",
      "  Group Key: l_returnflag, l_linestatus\n",
      "  ->  Gather Merge  (cost=2736532.36..2745866.35 rows=80000 width=248) (actual time=124490.927..124492.432 rows=12 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Sort  (cost=2735532.34..2735632.34 rows=40000 width=248) (actual time=124486.536..124486.537 rows=4 loops=3)\n",
      "              Sort Key: l_returnflag, l_linestatus\n",
      "              Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 0:  Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 1:  Sort Method: quicksort  Memory: 27kB\n",
      "              ->  Partial HashAggregate  (cost=2378645.97..2727823.30 rows=40000 width=248) (actual time=124486.451..124486.505 rows=4 loops=3)\n",
      "                    Group Key: l_returnflag, l_linestatus\n",
      "                    Planned Partitions: 8  Batches: 1  Memory Usage: 217kB\n",
      "                    Worker 0:  Batches: 1  Memory Usage: 217kB\n",
      "                    Worker 1:  Batches: 1  Memory Usage: 217kB\n",
      "                    ->  Parallel Seq Scan on lineitem_aggregates  (cost=0.00..518513.33 rows=8491333 width=144) (actual time=0.300..41647.824 rows=19714203 loops=3)\n",
      "Planning Time: 0.144 ms\n",
      "Execution Time: 124492.618 ms\n",
      "Finalize GroupAggregate  (cost=2736532.36..2749566.35 rows=40000 width=248) (actual time=23966.207..23967.404 rows=4 loops=1)\n",
      "  Group Key: l_returnflag, l_linestatus\n",
      "  ->  Gather Merge  (cost=2736532.36..2745866.35 rows=80000 width=248) (actual time=23966.189..23967.346 rows=12 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Sort  (cost=2735532.34..2735632.34 rows=40000 width=248) (actual time=23961.957..23961.958 rows=4 loops=3)\n",
      "              Sort Key: l_returnflag, l_linestatus\n",
      "              Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 0:  Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 1:  Sort Method: quicksort  Memory: 27kB\n",
      "              ->  Partial HashAggregate  (cost=2378645.97..2727823.30 rows=40000 width=248) (actual time=23961.900..23961.937 rows=4 loops=3)\n",
      "                    Group Key: l_returnflag, l_linestatus\n",
      "                    Planned Partitions: 8  Batches: 1  Memory Usage: 217kB\n",
      "                    Worker 0:  Batches: 1  Memory Usage: 217kB\n",
      "                    Worker 1:  Batches: 1  Memory Usage: 217kB\n",
      "                    ->  Parallel Seq Scan on lineitem_aggregates  (cost=0.00..518513.33 rows=8491333 width=144) (actual time=0.030..6119.744 rows=19714203 loops=3)\n",
      "Planning Time: 0.271 ms\n",
      "Execution Time: 23967.465 ms\n",
      "Finalize GroupAggregate  (cost=2736532.36..2749566.35 rows=40000 width=248) (actual time=23490.592..23491.698 rows=4 loops=1)\n",
      "  Group Key: l_returnflag, l_linestatus\n",
      "  ->  Gather Merge  (cost=2736532.36..2745866.35 rows=80000 width=248) (actual time=23490.569..23491.657 rows=12 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Sort  (cost=2735532.34..2735632.34 rows=40000 width=248) (actual time=23486.998..23486.998 rows=4 loops=3)\n",
      "              Sort Key: l_returnflag, l_linestatus\n",
      "              Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 0:  Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 1:  Sort Method: quicksort  Memory: 27kB\n",
      "              ->  Partial HashAggregate  (cost=2378645.97..2727823.30 rows=40000 width=248) (actual time=23486.941..23486.981 rows=4 loops=3)\n",
      "                    Group Key: l_returnflag, l_linestatus\n",
      "                    Planned Partitions: 8  Batches: 1  Memory Usage: 217kB\n",
      "                    Worker 0:  Batches: 1  Memory Usage: 217kB\n",
      "                    Worker 1:  Batches: 1  Memory Usage: 217kB\n",
      "                    ->  Parallel Seq Scan on lineitem_aggregates  (cost=0.00..518513.33 rows=8491333 width=144) (actual time=0.030..6031.589 rows=19714203 loops=3)\n",
      "Planning Time: 0.204 ms\n",
      "Execution Time: 23491.738 ms\n",
      "Finalize GroupAggregate  (cost=2736532.36..2749566.35 rows=40000 width=248) (actual time=23327.529..23328.788 rows=4 loops=1)\n",
      "  Group Key: l_returnflag, l_linestatus\n",
      "  ->  Gather Merge  (cost=2736532.36..2745866.35 rows=80000 width=248) (actual time=23327.512..23328.751 rows=12 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Sort  (cost=2735532.34..2735632.34 rows=40000 width=248) (actual time=23321.433..23321.434 rows=4 loops=3)\n",
      "              Sort Key: l_returnflag, l_linestatus\n",
      "              Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 0:  Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 1:  Sort Method: quicksort  Memory: 27kB\n",
      "              ->  Partial HashAggregate  (cost=2378645.97..2727823.30 rows=40000 width=248) (actual time=23321.359..23321.410 rows=4 loops=3)\n",
      "                    Group Key: l_returnflag, l_linestatus\n",
      "                    Planned Partitions: 8  Batches: 1  Memory Usage: 217kB\n",
      "                    Worker 0:  Batches: 1  Memory Usage: 217kB\n",
      "                    Worker 1:  Batches: 1  Memory Usage: 217kB\n",
      "                    ->  Parallel Seq Scan on lineitem_aggregates  (cost=0.00..518513.33 rows=8491333 width=144) (actual time=0.025..5672.330 rows=19714203 loops=3)\n",
      "Planning Time: 0.191 ms\n",
      "Execution Time: 23328.828 ms\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    explain_analyze(query_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "times:\n",
    "\n",
    "28183.447 ms\n",
    "24790.548 ms\n",
    "22829.961 ms\n",
    "24030.231 ms\n",
    "24016.974 ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to use an index and then cluster on lineitem_aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to create index: 153.5242578983307 seconds\n",
      "Size of idx_lineitem_returnflag: 390.890625 MB\n",
      "Size of idx_lineitem_returnflag: 0.3817291259765625 GB\n",
      "Size of idx_lineitem_linestatus: 390.890625 MB\n",
      "Size of idx_lineitem_linestatus: 0.3817291259765625 GB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"DROP INDEX IF EXISTS idx_lineitem_returnflag_linestatus;\")\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_lineitem_returnflag ON lineitem_aggregates (l_returnflag);\")\n",
    "    cur.execute(\"CREATE INDEX idx_lineitem_linestatus ON lineitem_aggregates (l_linestatus);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken to create index: {end_time - start_time} seconds\")\n",
    "    # start_time = time.time()\n",
    "\n",
    "    cur.execute(\"SELECT pg_relation_size('idx_lineitem_returnflag');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of idx_lineitem_returnflag: {index_size/(1024**2)} MB\")\n",
    "    print(f\"Size of idx_lineitem_returnflag: {index_size/(1024**3)} GB\")\n",
    "    cur.execute(\"SELECT pg_relation_size('idx_lineitem_linestatus');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of idx_lineitem_linestatus: {index_size/(1024**2)} MB\")\n",
    "    print(f\"Size of idx_lineitem_linestatus: {index_size/(1024**3)} GB\")\n",
    "\n",
    "    # cur.execute(\"CLUSTER lineitem_aggregates USING idx_lineitem_returnflag_linestatus;\")\n",
    "    # end_time = time.time()\n",
    "    # print(f\"Time taken to cluster table: {end_time - start_time} seconds\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of materialised view: 4169.5 MB\n",
      "Size of materialised view: 4.07177734375 GB\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(\"SELECT pg_total_relation_size('lineitem_aggregates');\")\n",
    "    size = cur.fetchall()\n",
    "    print(f\"Size of materialised view: {size[0][0]/(1024**2)} MB\")\n",
    "    print(f\"Size of materialised view: {size[0][0]/(1024**3)} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalize GroupAggregate  (cost=7098677.59..7111711.58 rows=40000 width=248) (actual time=25052.829..25053.959 rows=4 loops=1)\n",
      "  Group Key: l_returnflag, l_linestatus\n",
      "  ->  Gather Merge  (cost=7098677.59..7108011.58 rows=80000 width=248) (actual time=25052.812..25053.909 rows=12 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Sort  (cost=7097677.57..7097777.57 rows=40000 width=248) (actual time=25049.591..25049.593 rows=4 loops=3)\n",
      "              Sort Key: l_returnflag, l_linestatus\n",
      "              Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 0:  Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 1:  Sort Method: quicksort  Memory: 27kB\n",
      "              ->  Partial HashAggregate  (cost=6078330.61..7089968.53 rows=40000 width=248) (actual time=25049.527..25049.566 rows=4 loops=3)\n",
      "                    Group Key: l_returnflag, l_linestatus\n",
      "                    Planned Partitions: 8  Batches: 1  Memory Usage: 217kB\n",
      "                    Worker 0:  Batches: 1  Memory Usage: 217kB\n",
      "                    Worker 1:  Batches: 1  Memory Usage: 217kB\n",
      "                    ->  Parallel Seq Scan on lineitem_aggregates  (cost=0.00..680027.53 rows=24642753 width=144) (actual time=0.172..8762.456 rows=19714203 loops=3)\n",
      "Planning Time: 1.567 ms\n",
      "Execution Time: 25054.163 ms\n",
      "Finalize GroupAggregate  (cost=7098677.59..7111711.58 rows=40000 width=248) (actual time=24303.747..24304.785 rows=4 loops=1)\n",
      "  Group Key: l_returnflag, l_linestatus\n",
      "  ->  Gather Merge  (cost=7098677.59..7108011.58 rows=80000 width=248) (actual time=24303.719..24304.741 rows=12 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Sort  (cost=7097677.57..7097777.57 rows=40000 width=248) (actual time=24301.946..24301.947 rows=4 loops=3)\n",
      "              Sort Key: l_returnflag, l_linestatus\n",
      "              Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 0:  Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 1:  Sort Method: quicksort  Memory: 27kB\n",
      "              ->  Partial HashAggregate  (cost=6078330.61..7089968.53 rows=40000 width=248) (actual time=24301.893..24301.928 rows=4 loops=3)\n",
      "                    Group Key: l_returnflag, l_linestatus\n",
      "                    Planned Partitions: 8  Batches: 1  Memory Usage: 217kB\n",
      "                    Worker 0:  Batches: 1  Memory Usage: 217kB\n",
      "                    Worker 1:  Batches: 1  Memory Usage: 217kB\n",
      "                    ->  Parallel Seq Scan on lineitem_aggregates  (cost=0.00..680027.53 rows=24642753 width=144) (actual time=2.873..8032.150 rows=19714203 loops=3)\n",
      "Planning Time: 0.223 ms\n",
      "Execution Time: 24304.930 ms\n",
      "Finalize GroupAggregate  (cost=7098677.59..7111711.58 rows=40000 width=248) (actual time=24146.248..24147.323 rows=4 loops=1)\n",
      "  Group Key: l_returnflag, l_linestatus\n",
      "  ->  Gather Merge  (cost=7098677.59..7108011.58 rows=80000 width=248) (actual time=24146.222..24147.284 rows=12 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Sort  (cost=7097677.57..7097777.57 rows=40000 width=248) (actual time=24144.047..24144.048 rows=4 loops=3)\n",
      "              Sort Key: l_returnflag, l_linestatus\n",
      "              Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 0:  Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 1:  Sort Method: quicksort  Memory: 27kB\n",
      "              ->  Partial HashAggregate  (cost=6078330.61..7089968.53 rows=40000 width=248) (actual time=24143.993..24144.028 rows=4 loops=3)\n",
      "                    Group Key: l_returnflag, l_linestatus\n",
      "                    Planned Partitions: 8  Batches: 1  Memory Usage: 217kB\n",
      "                    Worker 0:  Batches: 1  Memory Usage: 217kB\n",
      "                    Worker 1:  Batches: 1  Memory Usage: 217kB\n",
      "                    ->  Parallel Seq Scan on lineitem_aggregates  (cost=0.00..680027.53 rows=24642753 width=144) (actual time=0.265..7437.082 rows=19714203 loops=3)\n",
      "Planning Time: 0.200 ms\n",
      "Execution Time: 24147.375 ms\n",
      "Finalize GroupAggregate  (cost=7098677.59..7111711.58 rows=40000 width=248) (actual time=24092.843..24093.929 rows=4 loops=1)\n",
      "  Group Key: l_returnflag, l_linestatus\n",
      "  ->  Gather Merge  (cost=7098677.59..7108011.58 rows=80000 width=248) (actual time=24092.817..24093.893 rows=12 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Sort  (cost=7097677.57..7097777.57 rows=40000 width=248) (actual time=24090.680..24090.681 rows=4 loops=3)\n",
      "              Sort Key: l_returnflag, l_linestatus\n",
      "              Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 0:  Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 1:  Sort Method: quicksort  Memory: 27kB\n",
      "              ->  Partial HashAggregate  (cost=6078330.61..7089968.53 rows=40000 width=248) (actual time=24090.629..24090.664 rows=4 loops=3)\n",
      "                    Group Key: l_returnflag, l_linestatus\n",
      "                    Planned Partitions: 8  Batches: 1  Memory Usage: 217kB\n",
      "                    Worker 0:  Batches: 1  Memory Usage: 217kB\n",
      "                    Worker 1:  Batches: 1  Memory Usage: 217kB\n",
      "                    ->  Parallel Seq Scan on lineitem_aggregates  (cost=0.00..680027.53 rows=24642753 width=144) (actual time=0.268..6739.017 rows=19714203 loops=3)\n",
      "Planning Time: 0.103 ms\n",
      "Execution Time: 24094.021 ms\n",
      "Finalize GroupAggregate  (cost=7098677.59..7111711.58 rows=40000 width=248) (actual time=23720.320..23721.276 rows=4 loops=1)\n",
      "  Group Key: l_returnflag, l_linestatus\n",
      "  ->  Gather Merge  (cost=7098677.59..7108011.58 rows=80000 width=248) (actual time=23720.294..23721.231 rows=12 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Sort  (cost=7097677.57..7097777.57 rows=40000 width=248) (actual time=23718.152..23718.153 rows=4 loops=3)\n",
      "              Sort Key: l_returnflag, l_linestatus\n",
      "              Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 0:  Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 1:  Sort Method: quicksort  Memory: 27kB\n",
      "              ->  Partial HashAggregate  (cost=6078330.61..7089968.53 rows=40000 width=248) (actual time=23718.100..23718.135 rows=4 loops=3)\n",
      "                    Group Key: l_returnflag, l_linestatus\n",
      "                    Planned Partitions: 8  Batches: 1  Memory Usage: 217kB\n",
      "                    Worker 0:  Batches: 1  Memory Usage: 217kB\n",
      "                    Worker 1:  Batches: 1  Memory Usage: 217kB\n",
      "                    ->  Parallel Seq Scan on lineitem_aggregates  (cost=0.00..680027.53 rows=24642753 width=144) (actual time=0.270..6159.075 rows=19714203 loops=3)\n",
      "Planning Time: 0.198 ms\n",
      "Execution Time: 23721.366 ms\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = off;\")\n",
    "    cur.execute(\"SET enable_indexscan = off;\")\n",
    "    conn.commit()\n",
    "\n",
    "for i in range(5):\n",
    "    explain_analyze(query_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "times:\n",
    "\n",
    "20844.343 ms\n",
    "23613.642 ms\n",
    "23635.747 ms\n",
    "24402.178 ms\n",
    "23427.414 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalize GroupAggregate  (cost=7098677.59..7111711.58 rows=40000 width=248) (actual time=23624.877..23626.058 rows=4 loops=1)\n",
      "  Group Key: l_returnflag, l_linestatus\n",
      "  ->  Gather Merge  (cost=7098677.59..7108011.58 rows=80000 width=248) (actual time=23624.858..23626.019 rows=12 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Sort  (cost=7097677.57..7097777.57 rows=40000 width=248) (actual time=23622.403..23622.403 rows=4 loops=3)\n",
      "              Sort Key: l_returnflag, l_linestatus\n",
      "              Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 0:  Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 1:  Sort Method: quicksort  Memory: 27kB\n",
      "              ->  Partial HashAggregate  (cost=6078330.61..7089968.53 rows=40000 width=248) (actual time=23622.340..23622.382 rows=4 loops=3)\n",
      "                    Group Key: l_returnflag, l_linestatus\n",
      "                    Planned Partitions: 8  Batches: 1  Memory Usage: 217kB\n",
      "                    Worker 0:  Batches: 1  Memory Usage: 217kB\n",
      "                    Worker 1:  Batches: 1  Memory Usage: 217kB\n",
      "                    ->  Parallel Seq Scan on lineitem_aggregates  (cost=0.00..680027.53 rows=24642753 width=144) (actual time=0.224..5798.923 rows=19714203 loops=3)\n",
      "Planning Time: 5.285 ms\n",
      "Execution Time: 23626.129 ms\n",
      "Finalize GroupAggregate  (cost=7098677.59..7111711.58 rows=40000 width=248) (actual time=122475.202..122476.753 rows=4 loops=1)\n",
      "  Group Key: l_returnflag, l_linestatus\n",
      "  ->  Gather Merge  (cost=7098677.59..7108011.58 rows=80000 width=248) (actual time=122475.181..122476.704 rows=12 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Sort  (cost=7097677.57..7097777.57 rows=40000 width=248) (actual time=122471.751..122471.752 rows=4 loops=3)\n",
      "              Sort Key: l_returnflag, l_linestatus\n",
      "              Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 0:  Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 1:  Sort Method: quicksort  Memory: 27kB\n",
      "              ->  Partial HashAggregate  (cost=6078330.61..7089968.53 rows=40000 width=248) (actual time=122471.663..122471.717 rows=4 loops=3)\n",
      "                    Group Key: l_returnflag, l_linestatus\n",
      "                    Planned Partitions: 8  Batches: 1  Memory Usage: 217kB\n",
      "                    Worker 0:  Batches: 1  Memory Usage: 217kB\n",
      "                    Worker 1:  Batches: 1  Memory Usage: 217kB\n",
      "                    ->  Parallel Seq Scan on lineitem_aggregates  (cost=0.00..680027.53 rows=24642753 width=144) (actual time=0.442..39004.146 rows=19714203 loops=3)\n",
      "Planning Time: 0.105 ms\n",
      "Execution Time: 122476.819 ms\n",
      "Finalize GroupAggregate  (cost=7098677.59..7111711.58 rows=40000 width=248) (actual time=23137.926..23139.090 rows=4 loops=1)\n",
      "  Group Key: l_returnflag, l_linestatus\n",
      "  ->  Gather Merge  (cost=7098677.59..7108011.58 rows=80000 width=248) (actual time=23137.908..23139.038 rows=12 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Sort  (cost=7097677.57..7097777.57 rows=40000 width=248) (actual time=23135.681..23135.682 rows=4 loops=3)\n",
      "              Sort Key: l_returnflag, l_linestatus\n",
      "              Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 0:  Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 1:  Sort Method: quicksort  Memory: 27kB\n",
      "              ->  Partial HashAggregate  (cost=6078330.61..7089968.53 rows=40000 width=248) (actual time=23135.617..23135.652 rows=4 loops=3)\n",
      "                    Group Key: l_returnflag, l_linestatus\n",
      "                    Planned Partitions: 8  Batches: 1  Memory Usage: 217kB\n",
      "                    Worker 0:  Batches: 1  Memory Usage: 217kB\n",
      "                    Worker 1:  Batches: 1  Memory Usage: 217kB\n",
      "                    ->  Parallel Seq Scan on lineitem_aggregates  (cost=0.00..680027.53 rows=24642753 width=144) (actual time=0.448..5358.582 rows=19714203 loops=3)\n",
      "Planning Time: 0.239 ms\n",
      "Execution Time: 23139.177 ms\n",
      "Finalize GroupAggregate  (cost=7098677.59..7111711.58 rows=40000 width=248) (actual time=22916.348..22917.672 rows=4 loops=1)\n",
      "  Group Key: l_returnflag, l_linestatus\n",
      "  ->  Gather Merge  (cost=7098677.59..7108011.58 rows=80000 width=248) (actual time=22916.331..22917.625 rows=12 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Sort  (cost=7097677.57..7097777.57 rows=40000 width=248) (actual time=22912.704..22912.705 rows=4 loops=3)\n",
      "              Sort Key: l_returnflag, l_linestatus\n",
      "              Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 0:  Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 1:  Sort Method: quicksort  Memory: 27kB\n",
      "              ->  Partial HashAggregate  (cost=6078330.61..7089968.53 rows=40000 width=248) (actual time=22912.651..22912.686 rows=4 loops=3)\n",
      "                    Group Key: l_returnflag, l_linestatus\n",
      "                    Planned Partitions: 8  Batches: 1  Memory Usage: 217kB\n",
      "                    Worker 0:  Batches: 1  Memory Usage: 217kB\n",
      "                    Worker 1:  Batches: 1  Memory Usage: 217kB\n",
      "                    ->  Parallel Seq Scan on lineitem_aggregates  (cost=0.00..680027.53 rows=24642753 width=144) (actual time=0.938..5327.934 rows=19714203 loops=3)\n",
      "Planning Time: 0.505 ms\n",
      "Execution Time: 22917.770 ms\n",
      "Finalize GroupAggregate  (cost=7098677.59..7111711.58 rows=40000 width=248) (actual time=23320.410..23321.491 rows=4 loops=1)\n",
      "  Group Key: l_returnflag, l_linestatus\n",
      "  ->  Gather Merge  (cost=7098677.59..7108011.58 rows=80000 width=248) (actual time=23320.373..23321.452 rows=12 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Sort  (cost=7097677.57..7097777.57 rows=40000 width=248) (actual time=23316.875..23316.875 rows=4 loops=3)\n",
      "              Sort Key: l_returnflag, l_linestatus\n",
      "              Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 0:  Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 1:  Sort Method: quicksort  Memory: 27kB\n",
      "              ->  Partial HashAggregate  (cost=6078330.61..7089968.53 rows=40000 width=248) (actual time=23316.819..23316.856 rows=4 loops=3)\n",
      "                    Group Key: l_returnflag, l_linestatus\n",
      "                    Planned Partitions: 8  Batches: 1  Memory Usage: 217kB\n",
      "                    Worker 0:  Batches: 1  Memory Usage: 217kB\n",
      "                    Worker 1:  Batches: 1  Memory Usage: 217kB\n",
      "                    ->  Parallel Seq Scan on lineitem_aggregates  (cost=0.00..680027.53 rows=24642753 width=144) (actual time=0.279..5744.743 rows=19714203 loops=3)\n",
      "Planning Time: 0.115 ms\n",
      "Execution Time: 23321.551 ms\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    conn.commit()\n",
    "\n",
    "for i in range(5):\n",
    "    explain_analyze(query_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "times:\n",
    "\n",
    "29820.779 ms\n",
    "27852.622 ms\n",
    "27640.681 ms\n",
    "27931.446 ms\n",
    "27325.999 ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably the partition somehow helps in the execution of the query, and a sequential scan is perfect for this purpose: it makes sense that using an index is not useful since the rows are already ordered, on the contrary slows down the execution because of the cost of the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('lineitem_aggregates', 'idx_lineitem_returnflag', False), ('lineitem_aggregates', 'idx_lineitem_linestatus', False)]\n"
     ]
    }
   ],
   "source": [
    "check = \"\"\"\n",
    "SELECT\n",
    "    t.relname AS table_name,\n",
    "    i.relname AS index_name,\n",
    "    ix.indisclustered\n",
    "FROM\n",
    "    pg_class t\n",
    "    JOIN pg_index ix ON t.oid = ix.indrelid\n",
    "    JOIN pg_class i ON ix.indexrelid = i.oid\n",
    "WHERE\n",
    "    t.relname = 'lineitem_aggregates';\n",
    "\"\"\"\n",
    "\n",
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(check)\n",
    "    row = cur.fetchall()\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"drop materialized view lineitem_aggregates;\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Materialized on part lineitem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to create materialized view: 310.9520151615143 seconds\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = on;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = on;\")\n",
    "    cur.execute(\"SET enable_mergejoin = on;\")\n",
    "    cur.execute(\"SET enable_hashjoin = on;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    cur.execute(\"SET enable_hashagg = on;\")\n",
    "    conn.commit()\n",
    "\n",
    "query_materialized = \"\"\"\n",
    "\n",
    "CREATE MATERIALIZED VIEW part_lineitem AS\n",
    "SELECT\n",
    "    l_returnflag,\n",
    "    l_linestatus,\n",
    "    l_quantity,\n",
    "    l_extendedprice,\n",
    "    l_discount,\n",
    "    l_tax,\n",
    "    l_shipdate,\n",
    "    l_partkey,\n",
    "    p_partkey,\n",
    "    p_brand,\n",
    "    p_container,\n",
    "    SUBSTRING(p_type FROM 1 FOR 5) AS p_type_prefix,\n",
    "    0.2 * AVG(l_quantity) OVER (PARTITION BY l_partkey) AS avg_quantity\n",
    "FROM\n",
    "    lineitem l\n",
    "JOIN\n",
    "    part p ON l.l_partkey = p.p_partkey;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "with conn.cursor() as cur:\n",
    "    start_time = time.time()\n",
    "    cur.execute(query_materialized)\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken to create materialized view: {end_time - start_time} seconds\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We enable hash join since we are not interested in indexes performance in executing the join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of materialised view: 6581.5078125 MB\n",
      "Size of materialised view: 6.427253723144531 GB\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(\"SELECT pg_total_relation_size('part_lineitem');\")\n",
    "    size = cur.fetchall()\n",
    "    print(f\"Size of materialised view: {size[0][0]/(1024**2)} MB\")\n",
    "    print(f\"Size of materialised view: {size[0][0]/(1024**3)} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.rollback()\n",
    "check_indexes('part_lineitem')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = on;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = on;\")\n",
    "    cur.execute(\"SET enable_mergejoin = on;\")\n",
    "    cur.execute(\"SET enable_hashjoin = on;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    cur.execute(\"SET enable_hashagg = on;\")\n",
    "    cur.execute(\"SET enable_material = on;\")\n",
    "    conn.commit()\n",
    "\n",
    "query_14 = \"\"\"\n",
    "SELECT\n",
    "    100.00 * SUM(CASE\n",
    "        WHEN p_type_prefix LIKE 'PROMO'\n",
    "        THEN l_extendedprice * (1 - l_discount)\n",
    "        ELSE 0\n",
    "    END) / SUM(l_extendedprice * (1 - l_discount)) AS promo_revenue\n",
    "FROM\n",
    "    part_lineitem\n",
    "WHERE\n",
    "    l_shipdate >= DATE '1995-09-01'\n",
    "    AND l_shipdate < DATE '1995-09-01' + INTERVAL '1' MONTH;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalize Aggregate  (cost=970534.18..970534.19 rows=1 width=32) (actual time=36047.043..36049.397 rows=1 loops=1)\n",
      "  ->  Gather  (cost=970533.94..970534.15 rows=2 width=64) (actual time=36044.942..36049.075 rows=3 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Partial Aggregate  (cost=969533.94..969533.95 rows=1 width=64) (actual time=36035.166..36035.168 rows=1 loops=3)\n",
      "              ->  Parallel Seq Scan on part_lineitem  (cost=0.00..968796.80 rows=42122 width=96) (actual time=0.279..35848.123 rows=249741 loops=3)\n",
      "                    Filter: ((l_shipdate >= '1995-09-01'::date) AND (l_shipdate < '1995-10-01 00:00:00'::timestamp without time zone))\n",
      "                    Rows Removed by Filter: 19745610\n",
      "Planning Time: 0.798 ms\n",
      "Execution Time: 36049.752 ms\n"
     ]
    }
   ],
   "source": [
    "explain_analyze(query_14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with the lack of gain in performance is that the optimizer performs a sequential scan because there is no index on shipdate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate and size of the result table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: \n",
      " (Decimal('16.6475949416150953'),)\n",
      "Size of query_14 result table: 0.015625 MB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(f\"CREATE TEMP TABLE temp_result AS {query_14};\")\n",
    "    cur.execute(\"SELECT * FROM temp_result;\")\n",
    "    result = cur.fetchone()\n",
    "    print(f\"First row: \\n {result}\")\n",
    "    cur.execute(\"SELECT pg_total_relation_size('temp_result');\")\n",
    "    size = cur.fetchall()\n",
    "    print(f\"Size of query_14 result table: {size[0][0]/(1024**2)} MB\")\n",
    "    cur.execute(\"DROP TABLE temp_result;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we expect to get the most gain in performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_17 = \"\"\"\n",
    "SELECT\n",
    "    SUM(l_extendedprice) / 7.0 AS avg_yearly\n",
    "FROM\n",
    "    part_lineitem\n",
    "WHERE\n",
    "    p_brand = 'Brand#23'\n",
    "    AND p_container = 'MED BOX'\n",
    "    AND l_quantity < avg_quantity;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalize Aggregate  (cost=990858.00..990858.01 rows=1 width=32) (actual time=15263.910..15265.350 rows=1 loops=1)\n",
      "  ->  Gather  (cost=990857.78..990857.99 rows=2 width=32) (actual time=15263.831..15265.340 rows=3 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Partial Aggregate  (cost=989857.78..989857.79 rows=1 width=32) (actual time=15259.045..15259.045 rows=1 loops=3)\n",
      "              ->  Parallel Seq Scan on part_lineitem  (cost=0.00..989857.60 rows=70 width=32) (actual time=79.155..15258.522 rows=1842 loops=3)\n",
      "                    Filter: ((l_quantity < avg_quantity) AND (p_brand = 'Brand#23'::bpchar) AND (p_container = 'MED BOX'::bpchar))\n",
      "                    Rows Removed by Filter: 19993509\n",
      "Planning Time: 665.693 ms\n",
      "Execution Time: 15265.404 ms\n"
     ]
    }
   ],
   "source": [
    "explain_analyze(query_17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very good! We can see that the only cost is in scanning the table and filtering for the conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate and size of result table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: \n",
      " (Decimal('3295493.512857142857'),)\n",
      "Size of query_1 result table: 0.015625 MB\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(f\"CREATE TEMP TABLE temp_result AS {query_17};\")\n",
    "    cur.execute(\"SELECT * FROM temp_result;\")\n",
    "    result = cur.fetchone()\n",
    "    print(f\"First row: \\n {result}\")\n",
    "    cur.execute(\"SELECT pg_total_relation_size('temp_result');\")\n",
    "    size = cur.fetchall()\n",
    "    print(f\"Size of query_1 result table: {size[0][0]/(1024**2)} MB\")\n",
    "    cur.execute(\"DROP TABLE temp_result;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Indexes on part lineitem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create idx_pl_shipdate ON part_lineitem (l_shipdate): 30.162781953811646 seconds\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_pl_shipdate ON part_lineitem (l_shipdate);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create idx_pl_shipdate ON part_lineitem (l_shipdate): {end_time - start_time} seconds\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of idx_pl_shipdate: 397.546875 MB\n",
      "Size of idx_pl_shipdate: 0.3882293701171875 GB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:    \n",
    "    cur.execute(\"SELECT pg_relation_size('idx_pl_shipdate');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of idx_pl_shipdate: {index_size/(1024**2)} MB\")\n",
    "    print(f\"Size of idx_pl_shipdate: {index_size/(1024**3)} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create idx_pl_brand ON part_lineitem (p_brand): 58.95485210418701 seconds\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_pl_brand ON part_lineitem (p_brand);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create idx_pl_brand ON part_lineitem (p_brand): {end_time - start_time} seconds\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of idx_pl_brand: 403.140625 MB\n",
      "Size of idx_pl_brand: 0.3936920166015625 GB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:    \n",
    "    cur.execute(\"SELECT pg_relation_size('idx_pl_brand');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of idx_pl_brand: {index_size/(1024**2)} MB\")\n",
    "    print(f\"Size of idx_pl_brand: {index_size/(1024**3)} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create idx_pl_container ON part_lineitem (p_container): 60.34345507621765 seconds\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_pl_container ON part_lineitem (p_container);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create idx_pl_container ON part_lineitem (p_container): {end_time - start_time} seconds\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of idx_pl_container: 403.1484375 MB\n",
      "Size of idx_pl_container: 0.39369964599609375 GB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:    \n",
    "    cur.execute(\"SELECT pg_relation_size('idx_pl_container');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of idx_pl_container: {index_size/(1024**2)} MB\")\n",
    "    print(f\"Size of idx_pl_container: {index_size/(1024**3)} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalize Aggregate  (cost=1214874.74..1214874.76 rows=1 width=32) (actual time=19381.340..19395.889 rows=1 loops=1)\n",
      "  ->  Gather  (cost=1214874.51..1214874.72 rows=2 width=64) (actual time=19380.980..19395.876 rows=3 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Partial Aggregate  (cost=1213874.51..1213874.52 rows=1 width=64) (actual time=19375.856..19375.857 rows=1 loops=3)\n",
      "              ->  Parallel Bitmap Heap Scan on part_lineitem  (cost=9882.66..1208594.56 rows=301711 width=18) (actual time=107.708..19034.300 rows=249741 loops=3)\n",
      "                    Recheck Cond: ((l_shipdate >= '1995-09-01'::date) AND (l_shipdate < '1995-10-01 00:00:00'::timestamp without time zone))\n",
      "                    Rows Removed by Index Recheck: 10773120\n",
      "                    Heap Blocks: exact=11467 lossy=154789\n",
      "                    ->  Bitmap Index Scan on idx_pl_shipdate  (cost=0.00..9701.64 rows=724107 width=0) (actual time=88.514..88.514 rows=749223 loops=1)\n",
      "                          Index Cond: ((l_shipdate >= '1995-09-01'::date) AND (l_shipdate < '1995-10-01 00:00:00'::timestamp without time zone))\n",
      "Planning Time: 7.079 ms\n",
      "Execution Time: 19395.941 ms\n"
     ]
    }
   ],
   "source": [
    "explain_analyze(query_14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the index on l_shipdate is used and it brings a significative improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate  (cost=218970.71..218970.72 rows=1 width=32) (actual time=1422.670..1422.673 rows=1 loops=1)\n",
      "  ->  Bitmap Heap Scan on part_lineitem  (cost=41274.20..218923.70 rows=18805 width=8) (actual time=143.534..1421.748 rows=5526 loops=1)\n",
      "        Recheck Cond: ((p_container = 'MED BOX'::bpchar) AND (p_brand = 'Brand#23'::bpchar))\n",
      "        Rows Removed by Index Recheck: 346780\n",
      "        Filter: (l_quantity < avg_quantity)\n",
      "        Rows Removed by Filter: 55859\n",
      "        Heap Blocks: exact=3124 lossy=4777\n",
      "        ->  BitmapAnd  (cost=41274.20..41274.20 rows=56414 width=0) (actual time=140.630..140.631 rows=0 loops=1)\n",
      "              ->  Bitmap Index Scan on idx_pl_container  (cost=0.00..16102.00 rows=1471658 width=0) (actual time=54.228..54.228 rows=1504601 loops=1)\n",
      "                    Index Cond: (p_container = 'MED BOX'::bpchar)\n",
      "              ->  Bitmap Index Scan on idx_pl_brand  (cost=0.00..25162.55 rows=2299465 width=0) (actual time=82.913..82.913 rows=2391264 loops=1)\n",
      "                    Index Cond: (p_brand = 'Brand#23'::bpchar)\n",
      "Planning Time: 3.572 ms\n",
      "Execution Time: 1424.115 ms\n"
     ]
    }
   ],
   "source": [
    "explain_analyze(query_17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the index on p_brand and p_container are used and they bring a very significative improvement!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Materialized customer_order_lineitem_nation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hash Join  (cost=773460.56..4508342.52 rows=59986052 width=265)\n",
      "  Hash Cond: (c.c_nationkey = n.n_nationkey)\n",
      "  ->  Hash Join  (cost=773459.00..4324183.78 rows=59986052 width=165)\n",
      "        Hash Cond: (o.o_custkey = c.c_custkey)\n",
      "        ->  Hash Join  (cost=671655.00..3329726.95 rows=59986052 width=22)\n",
      "              Hash Cond: (l.l_orderkey = o.o_orderkey)\n",
      "              ->  Seq Scan on lineitem l  (cost=0.00..1724403.52 rows=59986052 width=18)\n",
      "              ->  Hash  (cost=410912.00..410912.00 rows=15000000 width=12)\n",
      "                    ->  Seq Scan on orders o  (cost=0.00..410912.00 rows=15000000 width=12)\n",
      "        ->  Hash  (cost=50827.00..50827.00 rows=1500000 width=147)\n",
      "              ->  Seq Scan on customer c  (cost=0.00..50827.00 rows=1500000 width=147)\n",
      "  ->  Hash  (cost=1.25..1.25 rows=25 width=108)\n",
      "        ->  Seq Scan on nation n  (cost=0.00..1.25 rows=25 width=108)\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = on;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = on;\")\n",
    "    cur.execute(\"SET enable_mergejoin = on;\")\n",
    "    cur.execute(\"SET enable_hashjoin = on;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    cur.execute(\"SET enable_hashagg = on;\")\n",
    "    conn.commit()\n",
    "\n",
    "query_materialized = \"\"\"\n",
    "\n",
    "CREATE MATERIALIZED VIEW customer_order_lineitem_nation AS\n",
    "SELECT\n",
    "    c.c_custkey,\n",
    "    c.c_name,\n",
    "    c.c_acctbal,\n",
    "    n.n_name,\n",
    "    c.c_address,\n",
    "    c.c_phone,\n",
    "    c.c_comment,\n",
    "    -- c.c_nationkey, not needed in the query, so not included\n",
    "    l.l_returnflag,\n",
    "    -- l.l_orderkey, not needed in the query, so not included\n",
    "    l.l_discount,\n",
    "    l.l_extendedprice,\n",
    "    o.o_orderdate\n",
    "\n",
    "FROM\n",
    "    customer c\n",
    "JOIN\n",
    "    orders o ON c.c_custkey = o.o_custkey\n",
    "JOIN\n",
    "    lineitem l ON l.l_orderkey = o.o_orderkey\n",
    "JOIN\n",
    "    nation n ON c.c_nationkey = n.n_nationkey;\n",
    "\"\"\"\n",
    "\n",
    "explain_analyze(query_materialized, analyze = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to create materialized view: 437.10683703422546 seconds\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    start_time = time.time()\n",
    "    cur.execute(query_materialized)\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken to create materialized view: {end_time - start_time} seconds\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of materialised view: 12938.5078125 MB\n",
      "Size of materialised view: 12.635261535644531 GB\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(\"SELECT pg_total_relation_size('customer_order_lineitem_nation');\")\n",
    "    size = cur.fetchall()\n",
    "    print(f\"Size of materialised view: {size[0][0]/(1024**2)} MB\")\n",
    "    print(f\"Size of materialised view: {size[0][0]/(1024**3)} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_indexes('customer_order_lineitem_nation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_10 = \"\"\"\n",
    "SELECT\n",
    "    c_custkey,\n",
    "    c_name,\n",
    "    SUM(l_extendedprice * (1 - l_discount)) AS revenue,\n",
    "    c_acctbal,\n",
    "    n_name,\n",
    "    c_address,\n",
    "    c_phone,\n",
    "    c_comment\n",
    "FROM\n",
    "    customer_order_lineitem_nation\n",
    "WHERE\n",
    "    o_orderdate >= DATE '1993-10-01'\n",
    "    AND o_orderdate < DATE '1993-10-01' + INTERVAL '3' MONTH\n",
    "    AND l_returnflag = 'R'\n",
    "GROUP BY\n",
    "    c_custkey,\n",
    "    c_name,\n",
    "    c_acctbal,\n",
    "    c_phone,\n",
    "    n_name,\n",
    "    c_address,\n",
    "    c_comment\n",
    "ORDER BY\n",
    "    revenue DESC;\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort  (cost=2365597.61..2366901.03 rows=521368 width=201) (actual time=41540.225..41591.007 rows=381105 loops=1)\n",
      "  Sort Key: (sum((l_extendedprice * ('1'::numeric - l_discount)))) DESC\n",
      "  Sort Method: external merge  Disk: 71032kB\n",
      "  ->  Finalize GroupAggregate  (cost=2134754.26..2212726.66 rows=521368 width=201) (actual time=40507.944..41159.491 rows=381105 loops=1)\n",
      "        Group Key: c_custkey, c_name, c_acctbal, c_phone, n_name, c_address, c_comment\n",
      "        ->  Gather Merge  (cost=2134754.26..2196029.12 rows=452464 width=201) (actual time=40507.920..40884.069 rows=450028 loops=1)\n",
      "              Workers Planned: 2\n",
      "              Workers Launched: 2\n",
      "              ->  Partial GroupAggregate  (cost=2133754.24..2142803.52 rows=226232 width=201) (actual time=40481.177..40766.210 rows=150009 loops=3)\n",
      "                    Group Key: c_custkey, c_name, c_acctbal, c_phone, n_name, c_address, c_comment\n",
      "                    ->  Sort  (cost=2133754.24..2134319.82 rows=226232 width=181) (actual time=40480.802..40522.560 rows=382361 loops=3)\n",
      "                          Sort Key: c_custkey, c_name, c_acctbal, c_phone, n_name, c_address, c_comment\n",
      "                          Sort Method: external merge  Disk: 72416kB\n",
      "                          Worker 0:  Sort Method: external merge  Disk: 72488kB\n",
      "                          Worker 1:  Sort Method: external merge  Disk: 74080kB\n",
      "                          ->  Parallel Seq Scan on customer_order_lineitem_nation  (cost=0.00..2093526.30 rows=226232 width=181) (actual time=1.451..39052.473 rows=382361 loops=3)\n",
      "                                Filter: ((o_orderdate >= '1993-10-01'::date) AND (o_orderdate < '1994-01-01 00:00:00'::timestamp without time zone) AND (l_returnflag = 'R'::bpchar))\n",
      "                                Rows Removed by Filter: 19612989\n",
      "Planning Time: 5.117 ms\n",
      "Execution Time: 41637.828 ms\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = on;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = on;\")\n",
    "    cur.execute(\"SET enable_mergejoin = on;\")\n",
    "    cur.execute(\"SET enable_hashjoin = off;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    cur.execute(\"SET enable_hashagg = on;\")\n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: \n",
      " (1237537, 'Customer#001237537', Decimal('884989.6657'), Decimal('7840.17'), 'RUSSIA                   ', 'FNG6WgB1mopyyY,ajQTU qUPW5o', '32-367-120-4327', 'nag carefully about the regular packages. carefully reg')\n",
      "Size of query_10 result table: 78.5078125 MB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(f\"CREATE TEMP TABLE temp_result AS {query_10};\")\n",
    "    cur.execute(\"SELECT * FROM temp_result;\")\n",
    "    result = cur.fetchone()\n",
    "    print(f\"First row: \\n {result}\")\n",
    "    cur.execute(\"SELECT pg_total_relation_size('temp_result');\")\n",
    "    size = cur.fetchall()\n",
    "    print(f\"Size of query_10 result table: {size[0][0]/(1024**2)} MB\")\n",
    "    cur.execute(\"DROP TABLE temp_result;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## indexes on customer order lineitem nation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create idx_coln_orderdate ON customer_order_lineitem_nation (o_orderdate): 58.30237102508545 seconds\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_coln_orderdate ON customer_order_lineitem_nation (o_orderdate);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create idx_coln_orderdate ON customer_order_lineitem_nation (o_orderdate): {end_time - start_time} seconds\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of idx_coln_orderdate: 397.5078125 MB\n",
      "Size of idx_coln_orderdate: 0.38819122314453125 GB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:    \n",
    "    cur.execute(\"SELECT pg_relation_size('idx_coln_orderdate');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of idx_coln_orderdate: {index_size/(1024**2)} MB\")\n",
    "    print(f\"Size of idx_coln_orderdate: {index_size/(1024**3)} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create idx_coln_l_returnflag ON customer_order_lineitem_nation (l_returnflag): 50.617753982543945 seconds\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_coln_l_returnflag ON customer_order_lineitem_nation (l_returnflag);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create idx_coln_l_returnflag ON customer_order_lineitem_nation (l_returnflag): {end_time - start_time} seconds\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of idx_coln_l_returnflag: 396.4609375 MB\n",
      "Size of idx_coln_l_returnflag: 0.38716888427734375 GB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:    \n",
    "    cur.execute(\"SELECT pg_relation_size('idx_coln_l_returnflag');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of idx_coln_l_returnflag: {index_size/(1024**2)} MB\")\n",
    "    print(f\"Size of idx_coln_l_returnflag: {index_size/(1024**3)} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort  (cost=1993769.88..1995073.30 rows=521368 width=201) (actual time=27869.242..27920.840 rows=381105 loops=1)\n",
      "  Sort Key: (sum((l_extendedprice * ('1'::numeric - l_discount)))) DESC\n",
      "  Sort Method: external merge  Disk: 71032kB\n",
      "  ->  Finalize GroupAggregate  (cost=1762926.53..1840898.93 rows=521368 width=201) (actual time=26794.582..27470.836 rows=381105 loops=1)\n",
      "        Group Key: c_custkey, c_name, c_acctbal, c_phone, n_name, c_address, c_comment\n",
      "        ->  Gather Merge  (cost=1762926.53..1824201.39 rows=452464 width=201) (actual time=26794.572..27186.217 rows=471540 loops=1)\n",
      "              Workers Planned: 2\n",
      "              Workers Launched: 2\n",
      "              ->  Partial GroupAggregate  (cost=1761926.51..1770975.79 rows=226232 width=201) (actual time=26778.571..27064.860 rows=157180 loops=3)\n",
      "                    Group Key: c_custkey, c_name, c_acctbal, c_phone, n_name, c_address, c_comment\n",
      "                    ->  Sort  (cost=1761926.51..1762492.09 rows=226232 width=181) (actual time=26778.550..26819.693 rows=382361 loops=3)\n",
      "                          Sort Key: c_custkey, c_name, c_acctbal, c_phone, n_name, c_address, c_comment\n",
      "                          Sort Method: external merge  Disk: 73024kB\n",
      "                          Worker 0:  Sort Method: external merge  Disk: 73016kB\n",
      "                          Worker 1:  Sort Method: external merge  Disk: 72944kB\n",
      "                          ->  Parallel Bitmap Heap Scan on customer_order_lineitem_nation  (cost=191528.42..1721698.56 rows=226232 width=181) (actual time=614.057..25486.247 rows=382361 loops=3)\n",
      "                                Recheck Cond: ((o_orderdate >= '1993-10-01'::date) AND (o_orderdate < '1994-01-01 00:00:00'::timestamp without time zone) AND (l_returnflag = 'R'::bpchar))\n",
      "                                Rows Removed by Index Recheck: 5330305\n",
      "                                Heap Blocks: exact=18676 lossy=155626\n",
      "                                ->  BitmapAnd  (cost=191528.42..191528.42 rows=542958 width=0) (actual time=616.643..616.643 rows=0 loops=1)\n",
      "                                      ->  Bitmap Index Scan on idx_coln_orderdate  (cost=0.00..29319.08 rows=2189051 width=0) (actual time=141.209..141.209 rows=2292924 loops=1)\n",
      "                                            Index Cond: ((o_orderdate >= '1993-10-01'::date) AND (o_orderdate < '1994-01-01 00:00:00'::timestamp without time zone))\n",
      "                                      ->  Bitmap Index Scan on idx_coln_l_returnflag  (cost=0.00..161937.61 rows=14878540 width=0) (actual time=467.246..467.246 rows=14808183 loops=1)\n",
      "                                            Index Cond: (l_returnflag = 'R'::bpchar)\n",
      "Planning Time: 2.122 ms\n",
      "Execution Time: 27970.529 ms\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = on;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = on;\")\n",
    "    cur.execute(\"SET enable_mergejoin = on;\")\n",
    "    cur.execute(\"SET enable_hashjoin = off;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    cur.execute(\"SET enable_hashagg = on;\")\n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the indexes are used and reduce the execution time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mixed approach order lineitem part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_10_1 = \"\"\"\n",
    "SELECT\n",
    "    c_custkey,\n",
    "    c_name,\n",
    "    SUM(l_extendedprice * (1 - l_discount)) AS revenue,\n",
    "    c_acctbal,\n",
    "    n_name,\n",
    "    c_address,\n",
    "    c_phone,\n",
    "    c_comment\n",
    "FROM\n",
    "    part_lineitem_order\n",
    "    JOIN customer c ON c.c_custkey = o_custkey\n",
    "    JOIN nation n ON c.c_nationkey = n.n_nationkey\n",
    "WHERE\n",
    "    o_orderdate >= DATE '1993-10-01'\n",
    "    AND o_orderdate < DATE '1993-10-01' + INTERVAL '3' MONTH\n",
    "    AND l_returnflag = 'R'\n",
    "GROUP BY\n",
    "    c_custkey,\n",
    "    c_name,\n",
    "    c_acctbal,\n",
    "    c_phone,\n",
    "    n_name,\n",
    "    c_address,\n",
    "    c_comment\n",
    "ORDER BY\n",
    "    revenue DESC;\n",
    "\"\"\"\n",
    "\n",
    "query_14_1 = \"\"\"\n",
    "SELECT\n",
    "    100.00 * SUM(CASE\n",
    "        WHEN p_type_prefix LIKE 'PROMO'\n",
    "        THEN l_extendedprice * (1 - l_discount)\n",
    "        ELSE 0\n",
    "    END) / SUM(l_extendedprice * (1 - l_discount)) AS promo_revenue\n",
    "FROM\n",
    "    part_lineitem_order\n",
    "WHERE\n",
    "    l_shipdate >= DATE '1995-09-01'\n",
    "    AND l_shipdate < DATE '1995-09-01' + INTERVAL '1' MONTH;\n",
    "\"\"\"\n",
    "\n",
    "query_17_1 = \"\"\"\n",
    "SELECT\n",
    "    SUM(l_extendedprice) / 7.0 AS avg_yearly\n",
    "FROM\n",
    "    part_lineitem_order\n",
    "WHERE\n",
    "    p_brand = 'Brand#23'\n",
    "    AND p_container = 'MED BOX'\n",
    "    AND l_quantity < avg_quantity;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_materialized = \"\"\"\n",
    "\n",
    "CREATE MATERIALIZED VIEW part_lineitem_order AS\n",
    "SELECT\n",
    "    l_returnflag,\n",
    "    l_linestatus,\n",
    "    l_quantity,\n",
    "    l_extendedprice,\n",
    "    l_discount,\n",
    "    l_tax,\n",
    "    l_shipdate,\n",
    "    l_partkey,\n",
    "    p_partkey,\n",
    "    p_brand,\n",
    "    p_container,\n",
    "    SUBSTRING(p_type FROM 1 FOR 5) AS p_type_prefix,\n",
    "    0.2 * AVG(l_quantity) OVER (PARTITION BY l_partkey) AS avg_quantity,\n",
    "    o_orderkey,\n",
    "    o.o_custkey,\n",
    "    o.o_orderdate\n",
    "FROM\n",
    "    lineitem l\n",
    "JOIN\n",
    "    part p ON l.l_partkey = p.p_partkey\n",
    "JOIN\n",
    "    orders o ON l.l_orderkey = o.o_orderkey;\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to create materialized view: 366.5083260536194 seconds\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    start_time = time.time()\n",
    "    cur.execute(query_materialized)\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken to create materialized view: {end_time - start_time} seconds\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_indexes('part_lineitem_order')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"drop index idx_plo_o_orderdate;\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort  (cost=1788687.39..1790144.09 rows=582677 width=279) (actual time=22506.254..22557.367 rows=381105 loops=1)\n",
      "  Sort Key: (sum((part_lineitem_order.l_extendedprice * ('1'::numeric - part_lineitem_order.l_discount)))) DESC\n",
      "  Sort Method: external merge  Disk: 71032kB\n",
      "  ->  GroupAggregate  (cost=1372817.10..1581528.26 rows=582677 width=279) (actual time=20183.330..22139.001 rows=381105 loops=1)\n",
      "        Group Key: c.c_custkey, n.n_name\n",
      "        ->  Incremental Sort  (cost=1372817.10..1566961.34 rows=582677 width=259) (actual time=20183.317..21580.558 rows=1147084 loops=1)\n",
      "              Sort Key: c.c_custkey, n.n_name\n",
      "              Presorted Key: c.c_custkey\n",
      "              Full-sort Groups: 34124  Sort Method: quicksort  Average Memory: 31kB  Peak Memory: 31kB\n",
      "              ->  Nested Loop  (cost=1372816.80..1540740.87 rows=582677 width=259) (actual time=20183.230..21254.278 rows=1147084 loops=1)\n",
      "                    ->  Merge Join  (cost=1372816.65..1526492.65 rows=582677 width=159) (actual time=20183.053..20967.240 rows=1147084 loops=1)\n",
      "                          Merge Cond: (part_lineitem_order.o_custkey = c.c_custkey)\n",
      "                          ->  Gather Merge  (cost=1372809.32..1440671.66 rows=582677 width=16) (actual time=20182.833..20373.137 rows=1147084 loops=1)\n",
      "                                Workers Planned: 2\n",
      "                                Workers Launched: 2\n",
      "                                ->  Sort  (cost=1371809.30..1372416.25 rows=242782 width=16) (actual time=20168.044..20217.088 rows=382361 loops=3)\n",
      "                                      Sort Key: part_lineitem_order.o_custkey\n",
      "                                      Sort Method: external merge  Disk: 10832kB\n",
      "                                      Worker 0:  Sort Method: external merge  Disk: 10920kB\n",
      "                                      Worker 1:  Sort Method: external merge  Disk: 10928kB\n",
      "                                      ->  Parallel Seq Scan on part_lineitem_order  (cost=0.00..1345942.30 rows=242782 width=16) (actual time=0.386..19595.071 rows=382361 loops=3)\n",
      "                                            Filter: ((o_orderdate >= '1993-10-01'::date) AND (o_orderdate < '1994-01-01 00:00:00'::timestamp without time zone) AND (l_returnflag = 'R'::bpchar))\n",
      "                                            Rows Removed by Filter: 19612989\n",
      "                          ->  Index Scan using customer_pkey on customer c  (cost=0.43..74794.43 rows=1500000 width=147) (actual time=0.215..371.202 rows=1499998 loops=1)\n",
      "                    ->  Memoize  (cost=0.15..0.17 rows=1 width=108) (actual time=0.000..0.000 rows=1 loops=1147084)\n",
      "                          Cache Key: c.c_nationkey\n",
      "                          Cache Mode: logical\n",
      "                          Hits: 1147059  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                          ->  Index Scan using nation_pkey on nation n  (cost=0.14..0.16 rows=1 width=108) (actual time=0.007..0.007 rows=1 loops=25)\n",
      "                                Index Cond: (n_nationkey = c.c_nationkey)\n",
      "Planning Time: 10.142 ms\n",
      "Execution Time: 22589.887 ms\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = on;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = on;\")\n",
    "    cur.execute(\"SET enable_mergejoin = on;\")\n",
    "    cur.execute(\"SET enable_hashjoin = off;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    cur.execute(\"SET enable_hashagg = on;\")\n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_10_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is interesting because it performs better than the previous query on customer_order_lineitem_nation with indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate  (cost=10001820670.25..10001820670.27 rows=1 width=32) (actual time=21382.986..21382.987 rows=1 loops=1)\n",
      "  ->  Seq Scan on part_lineitem_order  (cost=10000000000.00..10001808334.78 rows=704884 width=18) (actual time=0.009..21097.899 rows=749223 loops=1)\n",
      "        Filter: ((l_shipdate >= '1995-09-01'::date) AND (l_shipdate < '1995-10-01 00:00:00'::timestamp without time zone))\n",
      "        Rows Removed by Filter: 59236829\n",
      "Planning Time: 0.075 ms\n",
      "Execution Time: 21383.006 ms\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = off;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_tidscan = off;\")\n",
    "    cur.execute(\"SET enable_material = on;\")\n",
    "    cur.execute(\"SET enable_nestloop = on;\")\n",
    "    cur.execute(\"SET enable_mergejoin = on;\")\n",
    "    cur.execute(\"SET enable_hashjoin = off;\")\n",
    "    cur.execute(\"SET enable_hashagg = on;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    cur.execute(\"SET enable_partition_pruning = off;\")\n",
    "    cur.execute(\"SET enable_partitionwise_join = off;\")\n",
    "    cur.execute(\"SET enable_partitionwise_aggregate = off;\")\n",
    "    conn.commit()\n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_14_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalize Aggregate  (cost=1346963.99..1346964.00 rows=1 width=32) (actual time=19507.897..19509.571 rows=1 loops=1)\n",
      "  ->  Gather  (cost=1346963.76..1346963.97 rows=2 width=32) (actual time=19507.781..19509.564 rows=3 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Partial Aggregate  (cost=1345963.76..1345963.77 rows=1 width=32) (actual time=19503.756..19503.757 rows=1 loops=3)\n",
      "              ->  Parallel Seq Scan on part_lineitem_order  (cost=0.00..1345942.30 rows=8586 width=8) (actual time=29.400..19503.357 rows=1842 loops=3)\n",
      "                    Filter: ((l_quantity < avg_quantity) AND (p_brand = 'Brand#23'::bpchar) AND (p_container = 'MED BOX'::bpchar))\n",
      "                    Rows Removed by Filter: 19993509\n",
      "Planning Time: 0.074 ms\n",
      "Execution Time: 19509.595 ms\n"
     ]
    }
   ],
   "source": [
    "explain_analyze(query_17_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The execution times of query 14 and 17 are similar to the ones using only part_lineitem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## indexes on order_lineitem_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create idx_plo_shipdate ON part_lineitem_order (l_shipdate): 47.12177610397339 seconds\n",
      "Size of idx_plo_shipdate: 397.546875 MB\n",
      "Size of idx_plo_shipdate: 0.3882293701171875 GB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_plo_shipdate ON part_lineitem_order (l_shipdate);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create idx_plo_shipdate ON part_lineitem_order (l_shipdate): {end_time - start_time} seconds\")\n",
    "\n",
    "    cur.execute(\"SELECT pg_relation_size('idx_plo_shipdate');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of idx_plo_shipdate: {index_size/(1024**2)} MB\")\n",
    "    print(f\"Size of idx_plo_shipdate: {index_size/(1024**3)} GB\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create idx_plo_o_orderdate ON part_lineitem_order (o_orderdate): 52.21302676200867 seconds\n",
      "Size of idx_plo_o_orderdate: 397.5078125 MB\n",
      "Size of idx_plo_o_orderdate: 0.38819122314453125 GB\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_plo_o_orderdate ON part_lineitem_order (o_orderdate);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create idx_plo_o_orderdate ON part_lineitem_order (o_orderdate): {end_time - start_time} seconds\")\n",
    "\n",
    "    cur.execute(\"SELECT pg_relation_size('idx_plo_o_orderdate');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of idx_plo_o_orderdate: {index_size/(1024**2)} MB\")\n",
    "    print(f\"Size of idx_plo_o_orderdate: {index_size/(1024**3)} GB\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of idx_plo_o_orderdate: 397.5078125 MB\n",
      "Size of idx_plo_o_orderdate: 0.38819122314453125 GB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:    \n",
    "    cur.execute(\"SELECT pg_relation_size('idx_plo_o_orderdate');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of idx_plo_o_orderdate: {index_size/(1024**2)} MB\")\n",
    "    print(f\"Size of idx_plo_o_orderdate: {index_size/(1024**3)} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create idx_plo_l_returnflag ON part_lineitem_order (l_returnflag): 59.15670895576477 seconds\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_plo_l_returnflag ON part_lineitem_order (l_returnflag);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create idx_plo_l_returnflag ON part_lineitem_order (l_returnflag): {end_time - start_time} seconds\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of idx_plo_l_returnflag: 396.4609375 MB\n",
      "Size of idx_plo_l_returnflag: 0.38716888427734375 GB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SELECT pg_relation_size('idx_plo_l_returnflag');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of idx_plo_l_returnflag: {index_size/(1024**2)} MB\")\n",
    "    print(f\"Size of idx_plo_l_returnflag: {index_size/(1024**3)} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create idx_plo_brand ON part_lineitem_order (p_brand): 49.67605805397034 seconds\n",
      "Size of idx_plo_brand: 403.140625 MB\n",
      "Size of idx_plo_brand: 0.3936920166015625 GB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_plo_brand ON part_lineitem_order (p_brand);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create idx_plo_brand ON part_lineitem_order (p_brand): {end_time - start_time} seconds\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of idx_plo_brand: 403.140625 MB\n",
      "Size of idx_plo_brand: 0.3936920166015625 GB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:  \n",
    "    cur.execute(\"SELECT pg_relation_size('idx_plo_brand');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of idx_plo_brand: {index_size/(1024**2)} MB\")\n",
    "    print(f\"Size of idx_plo_brand: {index_size/(1024**3)} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create idx_plo_container ON part_lineitem_order (p_container): 59.78866696357727 seconds\n",
      "Size of idx_plo_container: 403.1484375 MB\n",
      "Size of idx_plo_container: 0.39369964599609375 GB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_plo_container ON part_lineitem_order (p_container);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create idx_plo_container ON part_lineitem_order (p_container): {end_time - start_time} seconds\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of idx_plo_container: 403.1484375 MB\n",
      "Size of idx_plo_container: 0.39369964599609375 GB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SELECT pg_relation_size('idx_plo_container');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of idx_plo_container: {index_size/(1024**2)} MB\")\n",
    "    print(f\"Size of idx_plo_container: {index_size/(1024**3)} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tried also an index on o_custkey but it doesn't help neither is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort  (cost=1788693.04..1790149.73 rows=582677 width=279) (actual time=25865.093..25916.370 rows=381105 loops=1)\n",
      "  Sort Key: (sum((part_lineitem_order.l_extendedprice * ('1'::numeric - part_lineitem_order.l_discount)))) DESC\n",
      "  Sort Method: external merge  Disk: 71032kB\n",
      "  ->  GroupAggregate  (cost=1372815.22..1581533.91 rows=582677 width=279) (actual time=23497.687..25500.907 rows=381105 loops=1)\n",
      "        Group Key: c.c_custkey, n.n_name\n",
      "        ->  Incremental Sort  (cost=1372815.22..1566966.98 rows=582677 width=259) (actual time=23497.522..24945.533 rows=1147084 loops=1)\n",
      "              Sort Key: c.c_custkey, n.n_name\n",
      "              Presorted Key: c.c_custkey\n",
      "              Full-sort Groups: 34124  Sort Method: quicksort  Average Memory: 31kB  Peak Memory: 31kB\n",
      "              ->  Nested Loop  (cost=1372814.92..1540746.52 rows=582677 width=259) (actual time=23497.458..24619.535 rows=1147084 loops=1)\n",
      "                    ->  Merge Join  (cost=1372814.78..1526498.29 rows=582677 width=159) (actual time=23496.470..24328.519 rows=1147084 loops=1)\n",
      "                          Merge Cond: (part_lineitem_order.o_custkey = c.c_custkey)\n",
      "                          ->  Gather Merge  (cost=1372809.32..1440671.66 rows=582677 width=16) (actual time=23496.109..23685.931 rows=1147084 loops=1)\n",
      "                                Workers Planned: 2\n",
      "                                Workers Launched: 2\n",
      "                                ->  Sort  (cost=1371809.30..1372416.25 rows=242782 width=16) (actual time=23486.866..23536.948 rows=382361 loops=3)\n",
      "                                      Sort Key: part_lineitem_order.o_custkey\n",
      "                                      Sort Method: external merge  Disk: 11016kB\n",
      "                                      Worker 0:  Sort Method: external merge  Disk: 10840kB\n",
      "                                      Worker 1:  Sort Method: external merge  Disk: 10800kB\n",
      "                                      ->  Parallel Seq Scan on part_lineitem_order  (cost=0.00..1345942.30 rows=242782 width=16) (actual time=2.451..23018.679 rows=382361 loops=3)\n",
      "                                            Filter: ((o_orderdate >= '1993-10-01'::date) AND (o_orderdate < '1994-01-01 00:00:00'::timestamp without time zone) AND (l_returnflag = 'R'::bpchar))\n",
      "                                            Rows Removed by Filter: 19612989\n",
      "                          ->  Index Scan using customer_pkey on customer c  (cost=0.43..74794.43 rows=1500000 width=147) (actual time=0.357..421.399 rows=1499998 loops=1)\n",
      "                    ->  Memoize  (cost=0.15..0.17 rows=1 width=108) (actual time=0.000..0.000 rows=1 loops=1147084)\n",
      "                          Cache Key: c.c_nationkey\n",
      "                          Cache Mode: logical\n",
      "                          Hits: 1147059  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                          ->  Index Scan using nation_pkey on nation n  (cost=0.14..0.16 rows=1 width=108) (actual time=0.007..0.007 rows=1 loops=25)\n",
      "                                Index Cond: (n_nationkey = c.c_nationkey)\n",
      "Planning Time: 3.752 ms\n",
      "Execution Time: 25947.275 ms\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    cur.execute(\"SET enable_seqscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_10_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that the indexes are not used. Let's try to set seqscan = off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort  (cost=1770017.13..1771473.82 rows=582677 width=279) (actual time=31002.544..31053.932 rows=381105 loops=1)\n",
      "  Sort Key: (sum((part_lineitem_order.l_extendedprice * ('1'::numeric - part_lineitem_order.l_discount)))) DESC\n",
      "  Sort Method: external merge  Disk: 71032kB\n",
      "  ->  Finalize GroupAggregate  (cost=1389553.95..1562858.00 rows=582677 width=279) (actual time=29160.719..30545.103 rows=381105 loops=1)\n",
      "        Group Key: c.c_custkey, n.n_name\n",
      "        ->  Gather Merge  (cost=1389553.95..1550718.90 rows=485564 width=279) (actual time=29160.667..30146.203 rows=719752 loops=1)\n",
      "              Workers Planned: 2\n",
      "              Workers Launched: 2\n",
      "              ->  Partial GroupAggregate  (cost=1388553.93..1493672.74 rows=242782 width=279) (actual time=29148.643..30056.586 rows=239917 loops=3)\n",
      "                    Group Key: c.c_custkey, n.n_name\n",
      "                    ->  Incremental Sort  (cost=1388553.93..1487603.19 rows=242782 width=259) (actual time=29148.608..29785.835 rows=382361 loops=3)\n",
      "                          Sort Key: c.c_custkey, n.n_name\n",
      "                          Presorted Key: c.c_custkey\n",
      "                          Full-sort Groups: 11713  Sort Method: quicksort  Average Memory: 31kB  Peak Memory: 31kB\n",
      "                          Worker 0:  Full-sort Groups: 11743  Sort Method: quicksort  Average Memory: 31kB  Peak Memory: 31kB\n",
      "                          Worker 1:  Full-sort Groups: 11791  Sort Method: quicksort  Average Memory: 31kB  Peak Memory: 31kB\n",
      "                          ->  Nested Loop  (cost=1388553.56..1476678.00 rows=242782 width=259) (actual time=29147.837..29671.753 rows=382361 loops=3)\n",
      "                                ->  Merge Join  (cost=1388553.41..1470738.90 rows=242782 width=159) (actual time=29147.087..29560.791 rows=382361 loops=3)\n",
      "                                      Merge Cond: (part_lineitem_order.o_custkey = c.c_custkey)\n",
      "                                      ->  Sort  (cost=1388552.86..1389159.82 rows=242782 width=16) (actual time=29145.859..29196.546 rows=382361 loops=3)\n",
      "                                            Sort Key: part_lineitem_order.o_custkey\n",
      "                                            Sort Method: external merge  Disk: 10872kB\n",
      "                                            Worker 0:  Sort Method: external merge  Disk: 10864kB\n",
      "                                            Worker 1:  Sort Method: external merge  Disk: 10896kB\n",
      "                                            ->  Parallel Bitmap Heap Scan on part_lineitem_order  (cost=31895.57..1362685.86 rows=242782 width=16) (actual time=143.131..28165.783 rows=382361 loops=3)\n",
      "                                                  Recheck Cond: ((o_orderdate >= '1993-10-01'::date) AND (o_orderdate < '1994-01-01 00:00:00'::timestamp without time zone))\n",
      "                                                  Rows Removed by Index Recheck: 16710976\n",
      "                                                  Filter: (l_returnflag = 'R'::bpchar)\n",
      "                                                  Rows Removed by Filter: 381947\n",
      "                                                  Heap Blocks: exact=15226 lossy=263244\n",
      "                                                  ->  Bitmap Index Scan on idx_plo_o_orderdate  (cost=0.00..31749.90 rows=2370534 width=0) (actual time=144.052..144.059 rows=2292924 loops=1)\n",
      "                                                        Index Cond: ((o_orderdate >= '1993-10-01'::date) AND (o_orderdate < '1994-01-01 00:00:00'::timestamp without time zone))\n",
      "                                      ->  Index Scan using customer_pkey on customer c  (cost=0.43..74794.43 rows=1500000 width=147) (actual time=1.197..217.754 rows=1499996 loops=3)\n",
      "                                ->  Memoize  (cost=0.15..0.17 rows=1 width=108) (actual time=0.000..0.000 rows=1 loops=1147084)\n",
      "                                      Cache Key: c.c_nationkey\n",
      "                                      Cache Mode: logical\n",
      "                                      Hits: 381308  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                                      Worker 0:  Hits: 382083  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                                      Worker 1:  Hits: 383618  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                                      ->  Index Scan using nation_pkey on nation n  (cost=0.14..0.16 rows=1 width=108) (actual time=0.029..0.029 rows=1 loops=75)\n",
      "                                            Index Cond: (n_nationkey = c.c_nationkey)\n",
      "Planning Time: 5.963 ms\n",
      "Execution Time: 31082.989 ms\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    cur.execute(\"SET enable_seqscan = off;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_10_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we force the optimizer to use them we get worse results, so we drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(\"drop index if exists idx_plo_o_orderdate;\")\n",
    "    cur.execute(\"drop index if exists idx_plo_l_returnflag;\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalize Aggregate  (cost=953355.33..953355.34 rows=1 width=32) (actual time=17837.472..17857.493 rows=1 loops=1)\n",
      "  ->  Gather  (cost=953355.09..953355.30 rows=2 width=64) (actual time=17836.303..17857.465 rows=3 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Partial Aggregate  (cost=952355.09..952355.10 rows=1 width=64) (actual time=17795.332..17795.333 rows=1 loops=3)\n",
      "              ->  Parallel Bitmap Heap Scan on part_lineitem_order  (cost=4094.85..950168.09 rows=124971 width=96) (actual time=49.563..17500.610 rows=249741 loops=3)\n",
      "                    Recheck Cond: ((l_shipdate >= '1995-09-01'::date) AND (l_shipdate < '1995-10-01 00:00:00'::timestamp without time zone))\n",
      "                    Rows Removed by Index Recheck: 9982702\n",
      "                    Heap Blocks: exact=16214 lossy=155070\n",
      "                    ->  Bitmap Index Scan on idx_plo_shipdate  (cost=0.00..4019.87 rows=299930 width=0) (actual time=79.299..79.299 rows=749223 loops=1)\n",
      "                          Index Cond: ((l_shipdate >= '1995-09-01'::date) AND (l_shipdate < '1995-10-01 00:00:00'::timestamp without time zone))\n",
      "Planning Time: 0.082 ms\n",
      "Execution Time: 17857.528 ms\n"
     ]
    }
   ],
   "source": [
    "explain_analyze(query_14_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate  (cost=12413.42..12413.43 rows=1 width=32) (actual time=1258.450..1258.455 rows=1 loops=1)\n",
      "  ->  Bitmap Heap Scan on part_lineitem_order  (cost=6572.58..12412.17 rows=500 width=32) (actual time=157.935..1257.492 rows=5526 loops=1)\n",
      "        Recheck Cond: ((p_container = 'MED BOX'::bpchar) AND (p_brand = 'Brand#23'::bpchar))\n",
      "        Rows Removed by Index Recheck: 302709\n",
      "        Filter: (l_quantity < avg_quantity)\n",
      "        Rows Removed by Filter: 55859\n",
      "        Heap Blocks: exact=3108 lossy=4520\n",
      "        ->  BitmapAnd  (cost=6572.58..6572.58 rows=1500 width=0) (actual time=156.401..156.404 rows=0 loops=1)\n",
      "              ->  Bitmap Index Scan on idx_plo_container  (cost=0.00..3286.04 rows=299930 width=0) (actual time=66.810..66.810 rows=1504601 loops=1)\n",
      "                    Index Cond: (p_container = 'MED BOX'::bpchar)\n",
      "              ->  Bitmap Index Scan on idx_plo_brand  (cost=0.00..3286.04 rows=299930 width=0) (actual time=86.063..86.063 rows=2391264 loops=1)\n",
      "                    Index Cond: (p_brand = 'Brand#23'::bpchar)\n",
      "Planning Time: 0.146 ms\n",
      "Execution Time: 1260.090 ms\n"
     ]
    }
   ],
   "source": [
    "explain_analyze(query_17_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## indexes used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.rollback()\n",
    "check_indexes('part_lineitem_order')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index Name: idx_coln_orderdate\n",
      "Index Definition: CREATE INDEX idx_coln_orderdate ON public.customer_order_lineitem_nation USING btree (o_orderdate)\n",
      "\n",
      "Index Name: idx_coln_l_returnflag\n",
      "Index Definition: CREATE INDEX idx_coln_l_returnflag ON public.customer_order_lineitem_nation USING btree (l_returnflag)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_indexes('customer_order_lineitem_nation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index Name: idx_pl_shipdate\n",
      "Index Definition: CREATE INDEX idx_pl_shipdate ON public.part_lineitem USING btree (l_shipdate)\n",
      "\n",
      "Index Name: idx_pl_brand\n",
      "Index Definition: CREATE INDEX idx_pl_brand ON public.part_lineitem USING btree (p_brand)\n",
      "\n",
      "Index Name: idx_pl_container\n",
      "Index Definition: CREATE INDEX idx_pl_container ON public.part_lineitem USING btree (p_container)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "check_indexes('part_lineitem') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## size of materialized views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relation size: 6581.50 MB\n",
      "Relation size: 6.43 GB\n",
      "Table (relation + TOAST) size: 6583.35 MB\n",
      "Table (relation + TOAST) size: 6.43 GB\n",
      "Index size for table part_lineitem: 1203.84 MB\n",
      "Index size for table part_lineitem: 1.18 GB\n",
      "Total size (relation + TOAST + index): 7787.19 MB\n",
      "Total size (relation + TOAST + index): 7.60 GB \n",
      "\n"
     ]
    }
   ],
   "source": [
    "collect_size('part_lineitem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relation size: 7098.00 MB\n",
      "Relation size: 6.93 GB\n",
      "Table (relation + TOAST) size: 7099.99 MB\n",
      "Table (relation + TOAST) size: 6.93 GB\n",
      "Index size for table part_lineitem_order: 397.55 MB\n",
      "Index size for table part_lineitem_order: 0.39 GB\n",
      "Total size (relation + TOAST + index): 7497.54 MB\n",
      "Total size (relation + TOAST + index): 7.32 GB \n",
      "\n"
     ]
    }
   ],
   "source": [
    "collect_size('part_lineitem_order')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relation size: 12938.50 MB\n",
      "Relation size: 12.64 GB\n",
      "Table (relation + TOAST) size: 12942.11 MB\n",
      "Table (relation + TOAST) size: 12.64 GB\n",
      "Index size for table customer_order_lineitem_nation: 793.97 MB\n",
      "Index size for table customer_order_lineitem_nation: 0.78 GB\n",
      "Total size (relation + TOAST + index): 13736.08 MB\n",
      "Total size (relation + TOAST + index): 13.41 GB \n",
      "\n"
     ]
    }
   ],
   "source": [
    "collect_size('customer_order_lineitem_nation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We can see that the gain of using 2 different materialized views wrt using a single one with part order lineitem are the same. the only useful indexes on part order lineitem are p_brand and p_container that speed up a lot the query.\n",
    "\n",
    "since we risparmiare time and space by creating only one mv, we choose to use that, also because it can be helpful for many other queries, in fact the tables part order lineitem are the \"core\" of the db.\n",
    "\n",
    "so we keep only part lineitem order as mv, drop the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"drop materialized view part_lineitem;\")\n",
    "    cur.execute(\"drop materialized view customer_order_lineitem_nation;\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Final db size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database size: 30034.59 MB\n",
      "Database size: 29.33 GB \n",
      "\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    cur.execute(\"SELECT pg_database_size('dw_cs');\")\n",
    "    all_rows = cur.fetchall()\n",
    "    print(f\"Database size: {all_rows[0][0] / (1024**2):.2f} MB\")\n",
    "    print(f\"Database size: {all_rows[0][0] / (1024**3):.2f} GB \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index Name: nation_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX nation_pkey ON public.nation USING btree (n_nationkey)\n",
      "\n",
      "Index Name: part_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX part_pkey ON public.part USING btree (p_partkey)\n",
      "\n",
      "Index Name: supplier_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX supplier_pkey ON public.supplier USING btree (s_suppkey)\n",
      "\n",
      "Index Name: customer_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX customer_pkey ON public.customer USING btree (c_custkey)\n",
      "\n",
      "Index Name: region_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX region_pkey ON public.region USING btree (r_regionkey)\n",
      "\n",
      "Index Name: partsupp_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX partsupp_pkey ON public.partsupp USING btree (ps_partkey, ps_suppkey)\n",
      "\n",
      "Index Name: orders_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX orders_pkey ON public.orders USING btree (o_orderkey)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checking there are only pk indexes\n",
    "a = ['nation', 'part', 'supplier', 'customer', 'lineitem', 'region', 'partsupp', 'orders']\n",
    "\n",
    "conn.rollback()\n",
    "for table in a:\n",
    "    check_indexes(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cheking only part_lineitem_order' and lineitem_aggregates exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relation size: 7098.00 MB\n",
      "Relation size: 6.93 GB\n",
      "Table (relation + TOAST) size: 7099.99 MB\n",
      "Table (relation + TOAST) size: 6.93 GB\n",
      "Index size for table part_lineitem_order: 0.00 MB\n",
      "Index size for table part_lineitem_order: 0.00 GB\n",
      "Total size (relation + TOAST + index): 7099.99 MB\n",
      "Total size (relation + TOAST + index): 6.93 GB \n",
      "\n",
      "Relation size: 3387.50 MB\n",
      "Relation size: 3.31 GB\n",
      "Table (relation + TOAST) size: 3388.33 MB\n",
      "Table (relation + TOAST) size: 3.31 GB\n",
      "Index size for table lineitem_aggregates: 781.78 MB\n",
      "Index size for table lineitem_aggregates: 0.76 GB\n",
      "Total size (relation + TOAST + index): 4170.11 MB\n",
      "Total size (relation + TOAST + index): 4.07 GB \n",
      "\n"
     ]
    }
   ],
   "source": [
    "collect_size('part_lineitem_order')\n",
    "collect_size('lineitem_aggregates')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_indexes('part_lineitem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_indexes('customer_order_lineitem_nation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database size: 33001.04 MB\n",
      "Database size: 32.23 GB \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# size of db with mv's: part_lineitem_order' and lineitem_aggregates\n",
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    cur.execute(\"SELECT pg_database_size('dw_cs');\")\n",
    "    all_rows = cur.fetchall()\n",
    "    print(f\"Database size: {all_rows[0][0] / (1024**2):.2f} MB\")\n",
    "    print(f\"Database size: {all_rows[0][0] / (1024**3):.2f} GB \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
