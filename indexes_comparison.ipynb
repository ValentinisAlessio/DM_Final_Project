{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish a connection to the PostgreSQL database\n",
    "conn = psycopg2.connect(\n",
    "    dbname = \"dw_cs\", \n",
    "    user = \"postgres\", \n",
    "    host= 'localhost',      # change this to your host\n",
    "    password = \"postgres\",  # change this to your password\n",
    "    port = 5432\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check the indexes on a table\n",
    "\n",
    "def check_indexes(table_name):\n",
    "\n",
    "    with conn.cursor() as cur:\n",
    "        query = f\"\"\"\n",
    "        SELECT\n",
    "            indexname,\n",
    "            indexdef\n",
    "        FROM\n",
    "            pg_indexes\n",
    "        WHERE\n",
    "            tablename = '{table_name}';\n",
    "        \"\"\"\n",
    "\n",
    "        cur.execute(query)      \n",
    "        \n",
    "        indexes = cur.fetchall()\n",
    "        \n",
    "        for index in indexes:\n",
    "            print(f\"Index Name: {index[0]}\")\n",
    "            print(f\"Index Definition: {index[1]}\\n\")\n",
    "\n",
    "\n",
    "# function to explain-analyze a query\n",
    "\n",
    "def explain_analyze(query, analyze = True):\n",
    "    conn.rollback()\n",
    "    with conn.cursor() as cur:\n",
    "        if analyze:\n",
    "            cur.execute(f\"EXPLAIN ANALYZE {query}\")\n",
    "        else:\n",
    "            cur.execute(f\"EXPLAIN {query}\")\n",
    "        explain = cur.fetchall()\n",
    "\n",
    "        for line in explain:\n",
    "            print(line[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index Name: nation_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX nation_pkey ON public.nation USING btree (n_nationkey)\n",
      "\n",
      "Index Name: part_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX part_pkey ON public.part USING btree (p_partkey)\n",
      "\n",
      "Index Name: idx_p_brand\n",
      "Index Definition: CREATE INDEX idx_p_brand ON public.part USING gin (p_brand)\n",
      "\n",
      "Index Name: idx_p_container\n",
      "Index Definition: CREATE INDEX idx_p_container ON public.part USING gin (p_container)\n",
      "\n",
      "Index Name: supplier_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX supplier_pkey ON public.supplier USING btree (s_suppkey)\n",
      "\n",
      "Index Name: customer_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX customer_pkey ON public.customer USING btree (c_custkey)\n",
      "\n",
      "Index Name: idx_l_shipdate\n",
      "Index Definition: CREATE INDEX idx_l_shipdate ON public.lineitem USING btree (l_shipdate)\n",
      "\n",
      "Index Name: idx_l_partkey\n",
      "Index Definition: CREATE INDEX idx_l_partkey ON public.lineitem USING btree (l_partkey)\n",
      "\n",
      "Index Name: region_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX region_pkey ON public.region USING btree (r_regionkey)\n",
      "\n",
      "Index Name: partsupp_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX partsupp_pkey ON public.partsupp USING btree (ps_partkey, ps_suppkey)\n",
      "\n",
      "Index Name: orders_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX orders_pkey ON public.orders USING btree (o_orderkey)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = ['nation', 'part', 'supplier', 'customer', 'lineitem', 'region', 'partsupp', 'orders']\n",
    "\n",
    "conn.rollback()\n",
    "for table in a:\n",
    "    check_indexes(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = on;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_tidscan = off;\")\n",
    "    cur.execute(\"SET enable_material = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = on;\")\n",
    "    cur.execute(\"SET enable_mergejoin = on;\")\n",
    "    cur.execute(\"SET enable_hashjoin = off;\")\n",
    "    cur.execute(\"SET enable_hashagg = on;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    cur.execute(\"SET enable_partition_pruning = off;\")\n",
    "    cur.execute(\"SET enable_partitionwise_join = off;\")\n",
    "    cur.execute(\"SET enable_partitionwise_aggregate = off;\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_1 = \"\"\"\n",
    "SELECT\n",
    "    l_returnflag,\n",
    "    l_linestatus,\n",
    "    SUM(l_quantity) AS sum_qty,\n",
    "    SUM(l_extendedprice) AS sum_base_price,\n",
    "    SUM(l_extendedprice * (1 - l_discount)) AS sum_disc_price,\n",
    "    SUM(l_extendedprice * (1 - l_discount) * (1 + l_tax)) AS sum_charge,\n",
    "    AVG(l_quantity) AS avg_qty,\n",
    "    AVG(l_extendedprice) AS avg_price,\n",
    "    AVG(l_discount) AS avg_disc,\n",
    "    COUNT(*) AS count_order\n",
    "FROM\n",
    "    lineitem\n",
    "WHERE\n",
    "    l_shipdate <= DATE '1998-12-01' - INTERVAL '90' DAY\n",
    "GROUP BY\n",
    "    l_returnflag,\n",
    "    l_linestatus\n",
    "ORDER BY\n",
    "    l_returnflag,\n",
    "    l_linestatus;\n",
    "\"\"\"\n",
    "\n",
    "query_10 = \"\"\"\n",
    "SELECT\n",
    "    c_custkey,\n",
    "    c_name,\n",
    "    SUM(l_extendedprice * (1 - l_discount)) AS revenue,\n",
    "    c_acctbal,\n",
    "    n_name,\n",
    "    c_address,\n",
    "    c_phone,\n",
    "    c_comment\n",
    "FROM\n",
    "    customer,\n",
    "    orders,\n",
    "    lineitem,\n",
    "    nation\n",
    "WHERE\n",
    "    c_custkey = o_custkey\n",
    "    AND l_orderkey = o_orderkey\n",
    "    AND o_orderdate >= DATE '1993-10-01'\n",
    "    AND o_orderdate < DATE '1993-10-01' + INTERVAL '3' MONTH\n",
    "    AND l_returnflag = 'R'\n",
    "    AND c_nationkey = n_nationkey\n",
    "GROUP BY\n",
    "    c_custkey,\n",
    "    c_name,\n",
    "    c_acctbal,\n",
    "    c_phone,\n",
    "    n_name,\n",
    "    c_address,\n",
    "    c_comment\n",
    "ORDER BY\n",
    "    revenue DESC;\n",
    "\"\"\"\n",
    "\n",
    "query_14 = \"\"\"\n",
    "SELECT\n",
    "    100.00 * SUM(CASE\n",
    "        WHEN p_type LIKE 'PROMO%'\n",
    "        THEN l_extendedprice * (1 - l_discount)\n",
    "        ELSE 0\n",
    "    END) / SUM(l_extendedprice * (1 - l_discount)) AS promo_revenue\n",
    "FROM\n",
    "    lineitem,\n",
    "    part\n",
    "WHERE\n",
    "    l_partkey = p_partkey\n",
    "    AND l_shipdate >= DATE '1995-09-01'\n",
    "    AND l_shipdate < DATE '1995-09-01' + INTERVAL '1' MONTH;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "query_17 = \"\"\"\n",
    "SELECT\n",
    "    SUM(l_extendedprice) / 7.0 AS avg_yearly\n",
    "FROM\n",
    "    lineitem,\n",
    "    part\n",
    "WHERE\n",
    "    l_partkey = p_partkey\n",
    "    AND p_brand = 'Brand#23'\n",
    "    AND p_container = 'MED BOX'\n",
    "    AND l_quantity < (\n",
    "        SELECT\n",
    "            0.2 * AVG(l_quantity)\n",
    "        FROM\n",
    "            lineitem\n",
    "        WHERE\n",
    "            p_partkey = l_partkey\n",
    "    );\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalize GroupAggregate  (cost=2300104.98..2300106.93 rows=6 width=236) (actual time=37413.172..37414.824 rows=4 loops=1)\n",
      "  Group Key: l_returnflag, l_linestatus\n",
      "  ->  Gather Merge  (cost=2300104.98..2300106.38 rows=12 width=236) (actual time=37413.155..37414.782 rows=12 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Sort  (cost=2299104.95..2299104.97 rows=6 width=236) (actual time=37407.591..37407.593 rows=4 loops=3)\n",
      "              Sort Key: l_returnflag, l_linestatus\n",
      "              Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 0:  Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 1:  Sort Method: quicksort  Memory: 27kB\n",
      "              ->  Partial HashAggregate  (cost=2299104.74..2299104.87 rows=6 width=236) (actual time=37407.549..37407.554 rows=4 loops=3)\n",
      "                    Group Key: l_returnflag, l_linestatus\n",
      "                    Batches: 1  Memory Usage: 24kB\n",
      "                    Worker 0:  Batches: 1  Memory Usage: 24kB\n",
      "                    Worker 1:  Batches: 1  Memory Usage: 24kB\n",
      "                    ->  Parallel Seq Scan on lineitem  (cost=0.00..1436970.35 rows=24632411 width=25) (actual time=0.529..20891.882 rows=19714203 loops=3)\n",
      "                          Filter: (l_shipdate <= '1998-09-02 00:00:00'::timestamp without time zone)\n",
      "                          Rows Removed by Filter: 281148\n",
      "Planning Time: 2.845 ms\n",
      "Execution Time: 37414.985 ms\n"
     ]
    }
   ],
   "source": [
    "explain_analyze(query_1, analyze = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort  (cost=3344325.21..3345720.08 rows=557947 width=279) (actual time=32089.471..32140.473 rows=381105 loops=1)\n",
      "  Sort Key: (sum((lineitem.l_extendedprice * ('1'::numeric - lineitem.l_discount)))) DESC\n",
      "  Sort Method: external merge  Disk: 71032kB\n",
      "  ->  GroupAggregate  (cost=2942891.02..3146127.82 rows=557947 width=279) (actual time=29752.701..31714.944 rows=381105 loops=1)\n",
      "        Group Key: customer.c_custkey, nation.n_name\n",
      "        ->  Incremental Sort  (cost=2942891.02..3132179.14 rows=557947 width=259) (actual time=29752.688..31153.161 rows=1147084 loops=1)\n",
      "              Sort Key: customer.c_custkey, nation.n_name\n",
      "              Presorted Key: customer.c_custkey\n",
      "              Full-sort Groups: 34124  Sort Method: quicksort  Average Memory: 31kB  Peak Memory: 31kB\n",
      "              ->  Nested Loop  (cost=2942890.72..3107071.53 rows=557947 width=259) (actual time=29752.600..30822.790 rows=1147084 loops=1)\n",
      "                    ->  Merge Join  (cost=2942890.57..3093377.71 rows=557947 width=159) (actual time=29752.221..30532.355 rows=1147084 loops=1)\n",
      "                          Merge Cond: (orders.o_custkey = customer.c_custkey)\n",
      "                          ->  Gather Merge  (cost=2942883.48..3007865.60 rows=557947 width=16) (actual time=29751.942..29897.393 rows=1147084 loops=1)\n",
      "                                Workers Planned: 2\n",
      "                                Workers Launched: 2\n",
      "                                ->  Sort  (cost=2941883.46..2942464.65 rows=232478 width=16) (actual time=29738.876..29768.024 rows=382361 loops=3)\n",
      "                                      Sort Key: orders.o_custkey\n",
      "                                      Sort Method: external merge  Disk: 10344kB\n",
      "                                      Worker 0:  Sort Method: external merge  Disk: 10328kB\n",
      "                                      Worker 1:  Sort Method: external merge  Disk: 10272kB\n",
      "                                      ->  Merge Join  (cost=2881503.92..2917185.84 rows=232478 width=16) (actual time=28722.388..29586.974 rows=382361 loops=3)\n",
      "                                            Merge Cond: (lineitem.l_orderkey = orders.o_orderkey)\n",
      "                                            ->  Sort  (cost=2333118.63..2348371.33 rows=6101082 width=16) (actual time=25764.434..26234.587 rows=4936061 loops=3)\n",
      "                                                  Sort Key: lineitem.l_orderkey\n",
      "                                                  Sort Method: external merge  Disk: 140968kB\n",
      "                                                  Worker 0:  Sort Method: external merge  Disk: 140008kB\n",
      "                                                  Worker 1:  Sort Method: external merge  Disk: 139568kB\n",
      "                                                  ->  Parallel Seq Scan on lineitem  (cost=0.00..1436970.35 rows=6101082 width=16) (actual time=0.385..23577.849 rows=4936061 loops=3)\n",
      "                                                        Filter: (l_returnflag = 'R'::bpchar)\n",
      "                                                        Rows Removed by Filter: 15059290\n",
      "                                            ->  Sort  (cost=548382.24..549811.16 rows=571566 width=8) (actual time=2957.853..2995.708 rows=572881 loops=3)\n",
      "                                                  Sort Key: orders.o_orderkey\n",
      "                                                  Sort Method: external merge  Disk: 10128kB\n",
      "                                                  Worker 0:  Sort Method: external merge  Disk: 10128kB\n",
      "                                                  Worker 1:  Sort Method: external merge  Disk: 10128kB\n",
      "                                                  ->  Seq Scan on orders  (cost=0.00..485912.00 rows=571566 width=8) (actual time=0.878..2744.775 rows=573157 loops=3)\n",
      "                                                        Filter: ((o_orderdate >= '1993-10-01'::date) AND (o_orderdate < '1994-01-01 00:00:00'::timestamp without time zone))\n",
      "                                                        Rows Removed by Filter: 14426843\n",
      "                          ->  Index Scan using customer_pkey on customer  (cost=0.43..74794.43 rows=1500000 width=147) (actual time=0.268..392.040 rows=1499998 loops=1)\n",
      "                    ->  Memoize  (cost=0.15..2.17 rows=1 width=108) (actual time=0.000..0.000 rows=1 loops=1147084)\n",
      "                          Cache Key: customer.c_nationkey\n",
      "                          Cache Mode: logical\n",
      "                          Hits: 1147059  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                          ->  Index Scan using nation_pkey on nation  (cost=0.14..2.16 rows=1 width=108) (actual time=0.015..0.015 rows=1 loops=25)\n",
      "                                Index Cond: (n_nationkey = customer.c_nationkey)\n",
      "Planning Time: 5.014 ms\n",
      "Execution Time: 32176.447 ms\n"
     ]
    }
   ],
   "source": [
    "explain_analyze(query_10, analyze = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate  (cost=1800922.34..1800922.35 rows=1 width=32) (actual time=29053.529..29053.639 rows=1 loops=1)\n",
      "  ->  Merge Join  (cost=1676444.04..1786617.50 rows=817419 width=33) (actual time=28216.458..28841.330 rows=749223 loops=1)\n",
      "        Merge Cond: (part.p_partkey = lineitem.l_partkey)\n",
      "        ->  Index Scan using part_pkey on part  (cost=0.43..92913.43 rows=2000000 width=25) (actual time=0.501..325.632 rows=1999994 loops=1)\n",
      "        ->  Sort  (cost=1676443.20..1678486.75 rows=817419 width=16) (actual time=28215.933..28277.619 rows=749223 loops=1)\n",
      "              Sort Key: lineitem.l_partkey\n",
      "              Sort Method: external sort  Disk: 24296kB\n",
      "              ->  Gather  (cost=1000.00..1582197.72 rows=817419 width=16) (actual time=0.245..27746.114 rows=749223 loops=1)\n",
      "                    Workers Planned: 2\n",
      "                    Workers Launched: 2\n",
      "                    ->  Parallel Seq Scan on lineitem  (cost=0.00..1499455.82 rows=340591 width=16) (actual time=2.027..27878.044 rows=249741 loops=3)\n",
      "                          Filter: ((l_shipdate >= '1995-09-01'::date) AND (l_shipdate < '1995-10-01 00:00:00'::timestamp without time zone))\n",
      "                          Rows Removed by Filter: 19745610\n",
      "Planning Time: 7.399 ms\n",
      "Execution Time: 29059.935 ms\n"
     ]
    }
   ],
   "source": [
    "explain_analyze(query_14, analyze = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set hashjoin and hashaggregate off, we only analyze the situation with indexes.\n",
    "\n",
    "Setting bitmap scan on or off doesn't affect the choiches of the optmizer, so we set it off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried to put two indexes on l_returnflag and l_linestatus but we saw that they were not used. We have to note that they do not have many distinct values: (3,2) respectively, we could use a bitmap index, but in postgre it is not implemented.\n",
    "\n",
    "Let's see if with an index on shipdate we get better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create idx_l_shipdate_gin: 28.46113610267639 seconds\n",
      "Size of idx_l_shipdate_gin: 192.0625 MB\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    # tried also this index, but it is not helpful\n",
    "    cur.execute(\"CREATE EXTENSION IF NOT EXISTS btree_gin;\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_l_shipdate_gin ON lineitem USING gin (l_shipdate);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create idx_l_shipdate_gin: {end_time - start_time} seconds\")\n",
    "\n",
    "    cur.execute(\"SELECT pg_relation_size('idx_l_shipdate_gin');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of idx_l_shipdate_gin: {index_size/(1024**2)} MB\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroupAggregate  (cost=10013748937.34..10015965854.48 rows=6 width=236) (actual time=74891.132..119123.310 rows=4 loops=1)\n",
      "  Group Key: l_returnflag, l_linestatus\n",
      "  ->  Sort  (cost=10013748937.34..10013896731.80 rows=59117786 width=25) (actual time=59907.064..75449.645 rows=59142609 loops=1)\n",
      "        Sort Key: l_returnflag, l_linestatus\n",
      "        Sort Method: external merge  Disk: 2155336kB\n",
      "        ->  Seq Scan on lineitem  (cost=10000000000.00..10001874368.65 rows=59117786 width=25) (actual time=0.154..10817.424 rows=59142609 loops=1)\n",
      "              Filter: (l_shipdate <= '1998-09-02 00:00:00'::timestamp without time zone)\n",
      "              Rows Removed by Filter: 843443\n",
      "Planning Time: 3.503 ms\n",
      "Execution Time: 119198.998 ms\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = off;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = on;\")\n",
    "    cur.execute(\"SET enable_tidscan = off;\")\n",
    "    cur.execute(\"SET enable_material = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = off;\")\n",
    "    cur.execute(\"SET enable_mergejoin = off;\")\n",
    "    cur.execute(\"SET enable_hashjoin = off;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    cur.execute(\"SET enable_hashagg = on;\")\n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shipdate with a btree+gin index doesn't bring any advantage, so we drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    cur.execute(\"DROP INDEX IF EXISTS idx_l_shipdate_gin;\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create idx_l_shipdate: 50.349547147750854 seconds\n",
      "Size of idx_l_shipdate: 397.546875 MB\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_l_shipdate ON lineitem (l_shipdate);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create idx_l_shipdate: {end_time - start_time} seconds\")\n",
    "\n",
    "    cur.execute(\"SELECT pg_relation_size('idx_l_shipdate');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of idx_l_shipdate: {index_size/(1024**2)} MB\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalize GroupAggregate  (cost=2958736.61..2958738.57 rows=6 width=236) (actual time=28416.919..28419.355 rows=4 loops=1)\n",
      "  Group Key: l_returnflag, l_linestatus\n",
      "  ->  Gather Merge  (cost=2958736.61..2958738.01 rows=12 width=236) (actual time=28416.899..28419.313 rows=12 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Sort  (cost=2957736.59..2957736.60 rows=6 width=236) (actual time=28393.543..28393.544 rows=4 loops=3)\n",
      "              Sort Key: l_returnflag, l_linestatus\n",
      "              Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 0:  Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 1:  Sort Method: quicksort  Memory: 27kB\n",
      "              ->  Partial HashAggregate  (cost=2957736.37..2957736.51 rows=6 width=236) (actual time=28393.511..28393.516 rows=4 loops=3)\n",
      "                    Group Key: l_returnflag, l_linestatus\n",
      "                    Batches: 1  Memory Usage: 24kB\n",
      "                    Worker 0:  Batches: 1  Memory Usage: 24kB\n",
      "                    Worker 1:  Batches: 1  Memory Usage: 24kB\n",
      "                    ->  Parallel Bitmap Heap Scan on lineitem  (cost=658763.41..2095601.99 rows=24632411 width=25) (actual time=1315.726..12078.562 rows=19714203 loops=3)\n",
      "                          Recheck Cond: (l_shipdate <= '1998-09-02 00:00:00'::timestamp without time zone)\n",
      "                          Rows Removed by Index Recheck: 270333\n",
      "                          Heap Blocks: exact=11598 lossy=364637\n",
      "                          ->  Bitmap Index Scan on idx_l_shipdate  (cost=0.00..643983.96 rows=59117786 width=0) (actual time=1331.689..1331.690 rows=59142609 loops=1)\n",
      "                                Index Cond: (l_shipdate <= '1998-09-02 00:00:00'::timestamp without time zone)\n",
      "Planning Time: 6.746 ms\n",
      "Execution Time: 28419.645 ms\n"
     ]
    }
   ],
   "source": [
    "explain_analyze(query_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an index also on return flag to see if it helps both in query 1 and 10.\n",
    "\n",
    "We tried an hash on (l_returnflag, l_linestatus) but hash doesn't work with multicolumns.\n",
    "\n",
    "We try an hash on returnflag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create index on lineitem: 28.43353796005249 seconds\n",
      "Size of idx_l_returnflag ON lineitem (l_returnflag): 127.328125 MB\n",
      "Size of idx_l_returnflag ON lineitem (l_returnflag): 0.1243438720703125 GB\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    # tried also hash index but it doesn't work, after 5 minutes it was still running\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_l_returnflag ON lineitem USING gin (l_returnflag, l_linestatus);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create index on lineitem: {end_time - start_time} seconds\")\n",
    "\n",
    "    cur.execute(\"SELECT pg_relation_size('idx_l_returnflag');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of idx_l_returnflag ON lineitem (l_returnflag): {index_size/(1024**2)} MB\")\n",
    "    print(f\"Size of idx_l_returnflag ON lineitem (l_returnflag): {index_size/(1024**3)} GB\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalize GroupAggregate  (cost=2958736.61..2958738.57 rows=6 width=236) (actual time=34572.293..34575.039 rows=4 loops=1)\n",
      "  Group Key: l_returnflag, l_linestatus\n",
      "  ->  Gather Merge  (cost=2958736.61..2958738.01 rows=12 width=236) (actual time=34572.267..34574.994 rows=12 loops=1)\n",
      "        Workers Planned: 2\n",
      "        Workers Launched: 2\n",
      "        ->  Sort  (cost=2957736.59..2957736.60 rows=6 width=236) (actual time=34551.508..34551.512 rows=4 loops=3)\n",
      "              Sort Key: l_returnflag, l_linestatus\n",
      "              Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 0:  Sort Method: quicksort  Memory: 27kB\n",
      "              Worker 1:  Sort Method: quicksort  Memory: 27kB\n",
      "              ->  Partial HashAggregate  (cost=2957736.37..2957736.51 rows=6 width=236) (actual time=34551.454..34551.461 rows=4 loops=3)\n",
      "                    Group Key: l_returnflag, l_linestatus\n",
      "                    Batches: 1  Memory Usage: 24kB\n",
      "                    Worker 0:  Batches: 1  Memory Usage: 24kB\n",
      "                    Worker 1:  Batches: 1  Memory Usage: 24kB\n",
      "                    ->  Parallel Bitmap Heap Scan on lineitem  (cost=658763.41..2095601.99 rows=24632411 width=25) (actual time=1863.985..13179.297 rows=19714203 loops=3)\n",
      "                          Recheck Cond: (l_shipdate <= '1998-09-02 00:00:00'::timestamp without time zone)\n",
      "                          Rows Removed by Index Recheck: 270333\n",
      "                          Heap Blocks: exact=11560 lossy=364663\n",
      "                          ->  Bitmap Index Scan on idx_l_shipdate  (cost=0.00..643983.96 rows=59117786 width=0) (actual time=1877.231..1877.234 rows=59142609 loops=1)\n",
      "                                Index Cond: (l_shipdate <= '1998-09-02 00:00:00'::timestamp without time zone)\n",
      "Planning Time: 19.436 ms\n",
      "Execution Time: 34575.239 ms\n"
     ]
    }
   ],
   "source": [
    "explain_analyze(query_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not used so we drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"DROP EXTENSION IF EXISTS btree_gin CASCADE;\")\n",
    "    cur.execute(\"drop INDEX if exists idx_l_returnflag;\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see an improvement using an index on l_shipdate with a bitmapscan. \n",
    "\n",
    "What I would suggest is to keep the index on l_shipdate since it may help us also in query 14, where shipdate has high selectivity and probably will help more.\n",
    "\n",
    "The index on l_returnflag is not used, I also tried to use an index on (l_returnflag, l_linestatus), but it was not used, anyway it will be helpful in query 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate and record the size of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: \n",
      " ('A', 'F', Decimal('377518399'), Decimal('566065727797.25'), Decimal('537759104278.0656'), Decimal('559276670892.116819'), Decimal('25.5009751030070973'), Decimal('38237.151008958546'), Decimal('0.05000657454024320463'), 14804077)\n",
      "Size of query_1 result table: 0.015625 MB\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = off;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_tidscan = off;\")\n",
    "    cur.execute(\"SET enable_material = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = off;\")\n",
    "    cur.execute(\"SET enable_mergejoin = off;\")\n",
    "    cur.execute(\"SET enable_hashjoin = on;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    conn.commit()\n",
    "    \n",
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(f\"CREATE TEMP TABLE temp_result AS {query_1};\")\n",
    "    cur.execute(\"SELECT * FROM temp_result;\")\n",
    "    result = cur.fetchone()\n",
    "    print(f\"First row: \\n {result}\")\n",
    "    cur.execute(\"SELECT pg_total_relation_size('temp_result');\")\n",
    "    size = cur.fetchall()\n",
    "    print(f\"Size of query_1 result table: {size[0][0]/(1024**2)} MB\")\n",
    "    cur.execute(\"DROP TABLE temp_result;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "o_orderdate is quite selective 3 months / 7*12 months, so probably an index can be beneficial.\n",
    "\n",
    "ordering by revenue, which is computed in the query, can't be optimised.\n",
    "\n",
    "what can be optimised is the join, where there are already indexes on the pks.\n",
    "\n",
    "l_return flag is not selective, but we saw it helps in speeding up the query.\n",
    "\n",
    "i put an index on o_custkey and l_orderkey but the first was never used and the second brings worse results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    # tried hash index but it doesn't work, after 15 minutes it was still running\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_l_returnflag ON lineitem USING hash (l_returnflag);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create index on lineitem: {end_time - start_time} seconds\")\n",
    "\n",
    "    cur.execute(\"SELECT pg_relation_size('idx_l_returnflag');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of idx_l_returnflag ON lineitem (l_returnflag): {index_size/(1024**2)} MB\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_analyze(query_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"drop index idx_l_returnflag;\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extension cerated\n",
      "Time to create index on lineitem: 19.962371826171875 seconds\n",
      "Size of idx_l_returnflag ON lineitem (l_returnflag): 64.25 MB\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"create EXTENSION IF not EXISTS btree_gin;\") # otherwise it doesn't work\n",
    "    print(\"extension cerated\")\n",
    "    cur.execute(\"CREATE INDEX idx_l_returnflag ON lineitem USING gin (l_returnflag);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create index on lineitem: {end_time - start_time} seconds\")\n",
    "\n",
    "    cur.execute(\"SELECT pg_relation_size('idx_l_returnflag');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of idx_l_returnflag ON lineitem (l_returnflag): {index_size/(1024**2)} MB\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort  (cost=3578165.76..3579560.62 rows=557947 width=279) (actual time=42074.437..42125.476 rows=381105 loops=1)\n",
      "  Sort Key: (sum((lineitem.l_extendedprice * ('1'::numeric - lineitem.l_discount)))) DESC\n",
      "  Sort Method: external merge  Disk: 71032kB\n",
      "  ->  Finalize GroupAggregate  (cost=3210635.78..3379968.36 rows=557947 width=279) (actual time=40584.766..41685.294 rows=381105 loops=1)\n",
      "        Group Key: customer.c_custkey, nation.n_name\n",
      "        ->  Gather Merge  (cost=3210635.78..3368344.46 rows=464956 width=279) (actual time=40584.751..41395.453 rows=464801 loops=1)\n",
      "              Workers Planned: 2\n",
      "              Workers Launched: 2\n",
      "              ->  Partial GroupAggregate  (cost=3209635.76..3313676.98 rows=232478 width=279) (actual time=40567.435..41338.972 rows=154934 loops=3)\n",
      "                    Group Key: customer.c_custkey, nation.n_name\n",
      "                    ->  Incremental Sort  (cost=3209635.76..3307865.03 rows=232478 width=259) (actual time=40567.415..41131.195 rows=382361 loops=3)\n",
      "                          Sort Key: customer.c_custkey, nation.n_name\n",
      "                          Presorted Key: customer.c_custkey\n",
      "                          Full-sort Groups: 11540  Sort Method: quicksort  Average Memory: 31kB  Peak Memory: 31kB\n",
      "                          Worker 0:  Full-sort Groups: 11522  Sort Method: quicksort  Average Memory: 31kB  Peak Memory: 31kB\n",
      "                          Worker 1:  Full-sort Groups: 11511  Sort Method: quicksort  Average Memory: 32kB  Peak Memory: 32kB\n",
      "                          ->  Nested Loop  (cost=3209635.37..3297403.52 rows=232478 width=259) (actual time=40566.967..41018.010 rows=382361 loops=3)\n",
      "                                ->  Merge Join  (cost=3209635.22..3291666.16 rows=232478 width=159) (actual time=40566.458..40917.958 rows=382361 loops=3)\n",
      "                                      Merge Cond: (orders.o_custkey = customer.c_custkey)\n",
      "                                      ->  Sort  (cost=3209634.68..3210215.88 rows=232478 width=16) (actual time=40565.471..40594.614 rows=382361 loops=3)\n",
      "                                            Sort Key: orders.o_custkey\n",
      "                                            Sort Method: external merge  Disk: 10328kB\n",
      "                                            Worker 0:  Sort Method: external merge  Disk: 10312kB\n",
      "                                            Worker 1:  Sort Method: external merge  Disk: 10304kB\n",
      "                                            ->  Merge Join  (cost=2425245.06..3184937.06 rows=232478 width=16) (actual time=36096.717..40317.274 rows=382361 loops=3)\n",
      "                                                  Merge Cond: (lineitem.l_orderkey = orders.o_orderkey)\n",
      "                                                  ->  Sort  (cost=2425241.57..2440494.28 rows=6101082 width=16) (actual time=36096.008..36590.261 rows=4936061 loops=3)\n",
      "                                                        Sort Key: lineitem.l_orderkey\n",
      "                                                        Sort Method: external merge  Disk: 140504kB\n",
      "                                                        Worker 0:  Sort Method: external merge  Disk: 140104kB\n",
      "                                                        Worker 1:  Sort Method: external merge  Disk: 139936kB\n",
      "                                                        ->  Parallel Bitmap Heap Scan on lineitem  (cost=99004.51..1529093.30 rows=6101082 width=16) (actual time=907.754..33177.501 rows=4936061 loops=3)\n",
      "                                                              Recheck Cond: (l_returnflag = 'R'::bpchar)\n",
      "                                                              Rows Removed by Index Recheck: 14537804\n",
      "                                                              Heap Blocks: exact=12770 lossy=363137\n",
      "                                                              ->  Bitmap Index Scan on idx_l_returnflag  (cost=0.00..95343.87 rows=14642596 width=0) (actual time=915.996..915.997 rows=14808183 loops=1)\n",
      "                                                                    Index Cond: (l_returnflag = 'R'::bpchar)\n",
      "                                                  ->  Index Scan using orders_pkey on orders  (cost=0.43..725439.44 rows=571566 width=8) (actual time=0.697..3353.521 rows=573157 loops=3)\n",
      "                                                        Filter: ((o_orderdate >= '1993-10-01'::date) AND (o_orderdate < '1994-01-01 00:00:00'::timestamp without time zone))\n",
      "                                                        Rows Removed by Filter: 14426840\n",
      "                                      ->  Index Scan using customer_pkey on customer  (cost=0.43..74794.43 rows=1500000 width=147) (actual time=0.972..191.058 rows=1499990 loops=3)\n",
      "                                ->  Memoize  (cost=0.15..2.17 rows=1 width=108) (actual time=0.000..0.000 rows=1 loops=1147084)\n",
      "                                      Cache Key: customer.c_nationkey\n",
      "                                      Cache Mode: logical\n",
      "                                      Hits: 382865  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                                      Worker 0:  Hits: 382156  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                                      Worker 1:  Hits: 381988  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                                      ->  Index Scan using nation_pkey on nation  (cost=0.14..2.16 rows=1 width=108) (actual time=0.020..0.020 rows=1 loops=75)\n",
      "                                            Index Cond: (n_nationkey = customer.c_nationkey)\n",
      "Planning Time: 7.557 ms\n",
      "Execution Time: 42174.985 ms\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = off;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "\n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort  (cost=10003486042.81..10003487437.68 rows=557947 width=279) (actual time=33693.838..33744.622 rows=381105 loops=1)\n",
      "  Sort Key: (sum((lineitem.l_extendedprice * ('1'::numeric - lineitem.l_discount)))) DESC\n",
      "  Sort Method: external merge  Disk: 71032kB\n",
      "  ->  Finalize GroupAggregate  (cost=10003118512.84..10003287845.41 rows=557947 width=279) (actual time=32212.419..33320.381 rows=381105 loops=1)\n",
      "        Group Key: customer.c_custkey, nation.n_name\n",
      "        ->  Gather Merge  (cost=10003118512.84..10003276221.52 rows=464956 width=279) (actual time=32212.413..33027.966 rows=450382 loops=1)\n",
      "              Workers Planned: 2\n",
      "              Workers Launched: 2\n",
      "              ->  Partial GroupAggregate  (cost=10003117512.81..10003221554.03 rows=232478 width=279) (actual time=32168.229..32949.752 rows=150127 loops=3)\n",
      "                    Group Key: customer.c_custkey, nation.n_name\n",
      "                    ->  Incremental Sort  (cost=10003117512.81..10003215742.08 rows=232478 width=259) (actual time=32168.208..32738.872 rows=382361 loops=3)\n",
      "                          Sort Key: customer.c_custkey, nation.n_name\n",
      "                          Presorted Key: customer.c_custkey\n",
      "                          Full-sort Groups: 11634  Sort Method: quicksort  Average Memory: 31kB  Peak Memory: 31kB\n",
      "                          Worker 0:  Full-sort Groups: 11483  Sort Method: quicksort  Average Memory: 32kB  Peak Memory: 32kB\n",
      "                          Worker 1:  Full-sort Groups: 11415  Sort Method: quicksort  Average Memory: 31kB  Peak Memory: 31kB\n",
      "                          ->  Nested Loop  (cost=10003117512.42..10003205280.57 rows=232478 width=259) (actual time=32167.159..32625.180 rows=382361 loops=3)\n",
      "                                ->  Merge Join  (cost=10003117512.28..10003199543.22 rows=232478 width=159) (actual time=32166.810..32522.287 rows=382361 loops=3)\n",
      "                                      Merge Cond: (orders.o_custkey = customer.c_custkey)\n",
      "                                      ->  Sort  (cost=10003117511.73..10003118092.93 rows=232478 width=16) (actual time=32166.144..32193.273 rows=382361 loops=3)\n",
      "                                            Sort Key: orders.o_custkey\n",
      "                                            Sort Method: external merge  Disk: 10424kB\n",
      "                                            Worker 0:  Sort Method: external merge  Disk: 10288kB\n",
      "                                            Worker 1:  Sort Method: external merge  Disk: 10224kB\n",
      "                                            ->  Merge Join  (cost=10002333122.11..10003092814.12 rows=232478 width=16) (actual time=28169.160..31886.781 rows=382361 loops=3)\n",
      "                                                  Merge Cond: (lineitem.l_orderkey = orders.o_orderkey)\n",
      "                                                  ->  Sort  (cost=10002333118.63..10002348371.33 rows=6101082 width=16) (actual time=28160.474..28679.992 rows=4936061 loops=3)\n",
      "                                                        Sort Key: lineitem.l_orderkey\n",
      "                                                        Sort Method: external merge  Disk: 142176kB\n",
      "                                                        Worker 0:  Sort Method: external merge  Disk: 140024kB\n",
      "                                                        Worker 1:  Sort Method: external merge  Disk: 138360kB\n",
      "                                                        ->  Parallel Seq Scan on lineitem  (cost=10000000000.00..10001436970.35 rows=6101082 width=16) (actual time=4.807..26074.512 rows=4936061 loops=3)\n",
      "                                                              Filter: (l_returnflag = 'R'::bpchar)\n",
      "                                                              Rows Removed by Filter: 15059290\n",
      "                                                  ->  Index Scan using orders_pkey on orders  (cost=0.43..725439.44 rows=571566 width=8) (actual time=1.268..2832.594 rows=573105 loops=3)\n",
      "                                                        Filter: ((o_orderdate >= '1993-10-01'::date) AND (o_orderdate < '1994-01-01 00:00:00'::timestamp without time zone))\n",
      "                                                        Rows Removed by Filter: 14425576\n",
      "                                      ->  Index Scan using customer_pkey on customer  (cost=0.43..74794.43 rows=1500000 width=147) (actual time=0.647..192.757 rows=1499992 loops=3)\n",
      "                                ->  Memoize  (cost=0.15..2.17 rows=1 width=108) (actual time=0.000..0.000 rows=1 loops=1147084)\n",
      "                                      Cache Key: customer.c_nationkey\n",
      "                                      Cache Mode: logical\n",
      "                                      Hits: 386463  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                                      Worker 0:  Hits: 381468  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                                      Worker 1:  Hits: 379078  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                                      ->  Index Scan using nation_pkey on nation  (cost=0.14..2.16 rows=1 width=108) (actual time=0.014..0.014 rows=1 loops=75)\n",
      "                                            Index Cond: (n_nationkey = customer.c_nationkey)\n",
      "Planning Time: 15.754 ms\n",
      "Execution Time: 33785.799 ms\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = off;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = off;\")\n",
    "\n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"drop INDEX idx_l_returnflag;\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create index on lineitem: 59.03293704986572 seconds\n",
      "Size of idx_l_returnflag ON lineitem (l_returnflag): 396.4609375 MB\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_l_returnflag ON lineitem (l_returnflag);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create index on lineitem: {end_time - start_time} seconds\")\n",
    "\n",
    "    cur.execute(\"SELECT pg_relation_size('idx_l_returnflag');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of idx_l_returnflag ON lineitem (l_returnflag): {index_size/(1024**2)} MB\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort  (cost=34913159.69..34914554.56 rows=557947 width=279) (actual time=26842.652..26893.302 rows=381105 loops=1)\n",
      "  Sort Key: (sum((lineitem.l_extendedprice * ('1'::numeric - lineitem.l_discount)))) DESC\n",
      "  Sort Method: external merge  Disk: 71032kB\n",
      "  ->  Finalize GroupAggregate  (cost=34545629.72..34714962.30 rows=557947 width=279) (actual time=25321.837..26437.974 rows=381105 loops=1)\n",
      "        Group Key: customer.c_custkey, nation.n_name\n",
      "        ->  Gather Merge  (cost=34545629.72..34703338.40 rows=464956 width=279) (actual time=25321.829..26144.228 rows=450868 loops=1)\n",
      "              Workers Planned: 2\n",
      "              Workers Launched: 2\n",
      "              ->  Partial GroupAggregate  (cost=34544629.70..34648670.92 rows=232478 width=279) (actual time=25306.516..26090.030 rows=150289 loops=3)\n",
      "                    Group Key: customer.c_custkey, nation.n_name\n",
      "                    ->  Incremental Sort  (cost=34544629.70..34642858.97 rows=232478 width=259) (actual time=25306.499..25878.258 rows=382361 loops=3)\n",
      "                          Sort Key: customer.c_custkey, nation.n_name\n",
      "                          Presorted Key: customer.c_custkey\n",
      "                          Full-sort Groups: 11712  Sort Method: quicksort  Average Memory: 32kB  Peak Memory: 32kB\n",
      "                          Worker 0:  Full-sort Groups: 11473  Sort Method: quicksort  Average Memory: 31kB  Peak Memory: 31kB\n",
      "                          Worker 1:  Full-sort Groups: 11351  Sort Method: quicksort  Average Memory: 31kB  Peak Memory: 31kB\n",
      "                          ->  Nested Loop  (cost=34544629.31..34632397.46 rows=232478 width=259) (actual time=25306.059..25764.492 rows=382361 loops=3)\n",
      "                                ->  Merge Join  (cost=34544629.16..34626660.10 rows=232478 width=159) (actual time=25305.925..25661.441 rows=382361 loops=3)\n",
      "                                      Merge Cond: (orders.o_custkey = customer.c_custkey)\n",
      "                                      ->  Sort  (cost=34544628.62..34545209.81 rows=232478 width=16) (actual time=25301.837..25329.488 rows=382361 loops=3)\n",
      "                                            Sort Key: orders.o_custkey\n",
      "                                            Sort Method: external merge  Disk: 10496kB\n",
      "                                            Worker 0:  Sort Method: external merge  Disk: 10280kB\n",
      "                                            Worker 1:  Sort Method: external merge  Disk: 10168kB\n",
      "                                            ->  Merge Join  (cost=33760239.00..34519931.00 rows=232478 width=16) (actual time=21848.435..25055.389 rows=382361 loops=3)\n",
      "                                                  Merge Cond: (lineitem.l_orderkey = orders.o_orderkey)\n",
      "                                                  ->  Sort  (cost=33760235.51..33775488.22 rows=6101082 width=16) (actual time=21844.097..22293.907 rows=4936061 loops=3)\n",
      "                                                        Sort Key: lineitem.l_orderkey\n",
      "                                                        Sort Method: external merge  Disk: 142016kB\n",
      "                                                        Worker 0:  Sort Method: external merge  Disk: 139888kB\n",
      "                                                        Worker 1:  Sort Method: external merge  Disk: 138656kB\n",
      "                                                        ->  Parallel Index Scan using idx_l_returnflag on lineitem  (cost=0.56..32864087.24 rows=6101082 width=16) (actual time=0.226..19745.810 rows=4936061 loops=3)\n",
      "                                                              Index Cond: (l_returnflag = 'R'::bpchar)\n",
      "                                                  ->  Index Scan using orders_pkey on orders  (cost=0.43..725439.44 rows=571566 width=8) (actual time=0.876..2433.021 rows=573130 loops=3)\n",
      "                                                        Filter: ((o_orderdate >= '1993-10-01'::date) AND (o_orderdate < '1994-01-01 00:00:00'::timestamp without time zone))\n",
      "                                                        Rows Removed by Filter: 14426125\n",
      "                                      ->  Index Scan using customer_pkey on customer  (cost=0.43..74794.43 rows=1500000 width=147) (actual time=4.075..195.565 rows=1499990 loops=3)\n",
      "                                ->  Memoize  (cost=0.15..2.17 rows=1 width=108) (actual time=0.000..0.000 rows=1 loops=1147084)\n",
      "                                      Cache Key: customer.c_nationkey\n",
      "                                      Cache Mode: logical\n",
      "                                      Hits: 388942  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                                      Worker 0:  Hits: 381097  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                                      Worker 1:  Hits: 376970  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                                      ->  Index Scan using nation_pkey on nation  (cost=0.14..2.16 rows=1 width=108) (actual time=0.006..0.006 rows=1 loops=75)\n",
      "                                            Index Cond: (n_nationkey = customer.c_nationkey)\n",
      "Planning Time: 8.785 ms\n",
      "Execution Time: 26934.370 ms\n"
     ]
    }
   ],
   "source": [
    "explain_analyze(query_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the same reason of not creating a btree+gin index on shipdate, we create a btree index also on o_orderdate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create idx_o_orderdate ON orders (o_orderdate): 10.481804132461548 seconds\n",
      "Size of idx_o_orderdate: 100.1796875 MB\n",
      "Size of idx_o_orderdate: 0.09783172607421875 GB\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_o_orderdate ON orders (o_orderdate);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create idx_o_orderdate ON orders (o_orderdate): {end_time - start_time} seconds\")\n",
    "    cur.execute(\"SELECT pg_relation_size('idx_o_orderdate');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of idx_o_orderdate: {index_size/(1024**2)} MB\")\n",
    "    print(f\"Size of idx_o_orderdate: {index_size/(1024**3)} GB\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create idx_l_orderkey ON orders (l_orderkey): 52.030105113983154 seconds\n",
      "Size of idx_l_orderkey: 999.71875 MB\n",
      "Size of idx_l_orderkey: 0.976287841796875 GB\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_l_orderkey ON lineitem USING gin (l_orderkey);\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create idx_l_orderkey ON orders (l_orderkey): {end_time - start_time} seconds\")\n",
    "    cur.execute(\"SELECT pg_relation_size('idx_l_orderkey');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of idx_l_orderkey: {index_size/(1024**2)} MB\")\n",
    "    print(f\"Size of idx_l_orderkey: {index_size/(1024**3)} GB\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the selectivity of l_returnflag = 'R'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14808183,)\n",
      "(59986052,)\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SELECT COUNT(*) FROM lineitem WHERE l_returnflag = 'R';\")\n",
    "    rows = cur.fetchall()\n",
    "    for row in rows:\n",
    "        print(row)\n",
    "    cur.execute(\"SELECT COUNT(*) FROM lineitem;\")\n",
    "    rows = cur.fetchall()\n",
    "    for row in rows:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort  (cost=3324959.15..3326354.02 rows=557947 width=279) (actual time=41403.214..41454.335 rows=381105 loops=1)\n",
      "  Sort Key: (sum((lineitem.l_extendedprice * ('1'::numeric - lineitem.l_discount)))) DESC\n",
      "  Sort Method: external merge  Disk: 71032kB\n",
      "  ->  GroupAggregate  (cost=2923524.96..3126761.75 rows=557947 width=279) (actual time=39229.932..41026.039 rows=381105 loops=1)\n",
      "        Group Key: customer.c_custkey, nation.n_name\n",
      "        ->  Incremental Sort  (cost=2923524.96..3112813.08 rows=557947 width=259) (actual time=39229.917..40471.320 rows=1147084 loops=1)\n",
      "              Sort Key: customer.c_custkey, nation.n_name\n",
      "              Presorted Key: customer.c_custkey\n",
      "              Full-sort Groups: 34124  Sort Method: quicksort  Average Memory: 31kB  Peak Memory: 31kB\n",
      "              ->  Nested Loop  (cost=2923524.66..3087705.46 rows=557947 width=259) (actual time=39229.846..40144.081 rows=1147084 loops=1)\n",
      "                    ->  Merge Join  (cost=2923524.51..3074011.64 rows=557947 width=159) (actual time=39229.381..39856.102 rows=1147084 loops=1)\n",
      "                          Merge Cond: (orders.o_custkey = customer.c_custkey)\n",
      "                          ->  Gather Merge  (cost=2923517.42..2988499.54 rows=557947 width=16) (actual time=39227.978..39372.479 rows=1147084 loops=1)\n",
      "                                Workers Planned: 2\n",
      "                                Workers Launched: 2\n",
      "                                ->  Sort  (cost=2922517.39..2923098.59 rows=232478 width=16) (actual time=39179.021..39207.673 rows=382361 loops=3)\n",
      "                                      Sort Key: orders.o_custkey\n",
      "                                      Sort Method: external merge  Disk: 10568kB\n",
      "                                      Worker 0:  Sort Method: external merge  Disk: 10144kB\n",
      "                                      Worker 1:  Sort Method: external merge  Disk: 10232kB\n",
      "                                      ->  Merge Join  (cost=2862137.86..2897819.78 rows=232478 width=16) (actual time=38145.044..39035.671 rows=382361 loops=3)\n",
      "                                            Merge Cond: (lineitem.l_orderkey = orders.o_orderkey)\n",
      "                                            ->  Sort  (cost=2333118.63..2348371.33 rows=6101082 width=16) (actual time=28327.555..28814.297 rows=4936061 loops=3)\n",
      "                                                  Sort Key: lineitem.l_orderkey\n",
      "                                                  Sort Method: external merge  Disk: 143432kB\n",
      "                                                  Worker 0:  Sort Method: external merge  Disk: 138120kB\n",
      "                                                  Worker 1:  Sort Method: external merge  Disk: 139008kB\n",
      "                                                  ->  Parallel Seq Scan on lineitem  (cost=0.00..1436970.35 rows=6101082 width=16) (actual time=0.211..26001.345 rows=4936061 loops=3)\n",
      "                                                        Filter: (l_returnflag = 'R'::bpchar)\n",
      "                                                        Rows Removed by Filter: 15059290\n",
      "                                            ->  Sort  (cost=529016.18..530445.09 rows=571566 width=8) (actual time=9817.391..9866.704 rows=573105 loops=3)\n",
      "                                                  Sort Key: orders.o_orderkey\n",
      "                                                  Sort Method: external merge  Disk: 10128kB\n",
      "                                                  Worker 0:  Sort Method: external merge  Disk: 10128kB\n",
      "                                                  Worker 1:  Sort Method: external merge  Disk: 10128kB\n",
      "                                                  ->  Bitmap Heap Scan on orders  (cost=7814.99..466545.94 rows=571566 width=8) (actual time=63.045..9274.842 rows=573157 loops=3)\n",
      "                                                        Recheck Cond: ((o_orderdate >= '1993-10-01'::date) AND (o_orderdate < '1994-01-01 00:00:00'::timestamp without time zone))\n",
      "                                                        Rows Removed by Index Recheck: 10885890\n",
      "                                                        Heap Blocks: exact=34987 lossy=198319\n",
      "                                                        ->  Bitmap Index Scan on idx_o_orderdate  (cost=0.00..7672.10 rows=571566 width=0) (actual time=56.063..56.064 rows=573157 loops=3)\n",
      "                                                              Index Cond: ((o_orderdate >= '1993-10-01'::date) AND (o_orderdate < '1994-01-01 00:00:00'::timestamp without time zone))\n",
      "                          ->  Index Scan using customer_pkey on customer  (cost=0.43..74794.43 rows=1500000 width=147) (actual time=1.399..243.557 rows=1499998 loops=1)\n",
      "                    ->  Memoize  (cost=0.15..2.17 rows=1 width=108) (actual time=0.000..0.000 rows=1 loops=1147084)\n",
      "                          Cache Key: customer.c_nationkey\n",
      "                          Cache Mode: logical\n",
      "                          Hits: 1147059  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                          ->  Index Scan using nation_pkey on nation  (cost=0.14..2.16 rows=1 width=108) (actual time=0.019..0.019 rows=1 loops=25)\n",
      "                                Index Cond: (n_nationkey = customer.c_nationkey)\n",
      "Planning Time: 6.451 ms\n",
      "Execution Time: 41493.509 ms\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = on;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort  (cost=34913159.69..34914554.56 rows=557947 width=279) (actual time=29314.443..29365.071 rows=381105 loops=1)\n",
      "  Sort Key: (sum((lineitem.l_extendedprice * ('1'::numeric - lineitem.l_discount)))) DESC\n",
      "  Sort Method: external merge  Disk: 71032kB\n",
      "  ->  Finalize GroupAggregate  (cost=34545629.72..34714962.30 rows=557947 width=279) (actual time=27868.519..28947.569 rows=381105 loops=1)\n",
      "        Group Key: customer.c_custkey, nation.n_name\n",
      "        ->  Gather Merge  (cost=34545629.72..34703338.40 rows=464956 width=279) (actual time=27868.504..28664.107 rows=451154 loops=1)\n",
      "              Workers Planned: 2\n",
      "              Workers Launched: 2\n",
      "              ->  Partial GroupAggregate  (cost=34544629.70..34648670.92 rows=232478 width=279) (actual time=27828.736..28585.299 rows=150385 loops=3)\n",
      "                    Group Key: customer.c_custkey, nation.n_name\n",
      "                    ->  Incremental Sort  (cost=34544629.70..34642858.97 rows=232478 width=259) (actual time=27828.719..28381.246 rows=382361 loops=3)\n",
      "                          Sort Key: customer.c_custkey, nation.n_name\n",
      "                          Presorted Key: customer.c_custkey\n",
      "                          Full-sort Groups: 11756  Sort Method: quicksort  Average Memory: 32kB  Peak Memory: 32kB\n",
      "                          Worker 0:  Full-sort Groups: 11375  Sort Method: quicksort  Average Memory: 32kB  Peak Memory: 32kB\n",
      "                          Worker 1:  Full-sort Groups: 11424  Sort Method: quicksort  Average Memory: 32kB  Peak Memory: 32kB\n",
      "                          ->  Nested Loop  (cost=34544629.31..34632397.46 rows=232478 width=259) (actual time=27828.309..28271.726 rows=382361 loops=3)\n",
      "                                ->  Merge Join  (cost=34544629.16..34626660.10 rows=232478 width=159) (actual time=27828.166..28172.622 rows=382361 loops=3)\n",
      "                                      Merge Cond: (orders.o_custkey = customer.c_custkey)\n",
      "                                      ->  Sort  (cost=34544628.62..34545209.81 rows=232478 width=16) (actual time=27827.475..27853.736 rows=382361 loops=3)\n",
      "                                            Sort Key: orders.o_custkey\n",
      "                                            Sort Method: external merge  Disk: 10528kB\n",
      "                                            Worker 0:  Sort Method: external merge  Disk: 10192kB\n",
      "                                            Worker 1:  Sort Method: external merge  Disk: 10232kB\n",
      "                                            ->  Merge Join  (cost=33760239.00..34519931.00 rows=232478 width=16) (actual time=24410.668..27594.864 rows=382361 loops=3)\n",
      "                                                  Merge Cond: (lineitem.l_orderkey = orders.o_orderkey)\n",
      "                                                  ->  Sort  (cost=33760235.51..33775488.22 rows=6101082 width=16) (actual time=24403.126..24855.510 rows=4936061 loops=3)\n",
      "                                                        Sort Key: lineitem.l_orderkey\n",
      "                                                        Sort Method: external merge  Disk: 143000kB\n",
      "                                                        Worker 0:  Sort Method: external merge  Disk: 138248kB\n",
      "                                                        Worker 1:  Sort Method: external merge  Disk: 139312kB\n",
      "                                                        ->  Parallel Index Scan using idx_l_returnflag on lineitem  (cost=0.56..32864087.24 rows=6101082 width=16) (actual time=1.586..22180.597 rows=4936061 loops=3)\n",
      "                                                              Index Cond: (l_returnflag = 'R'::bpchar)\n",
      "                                                  ->  Index Scan using orders_pkey on orders  (cost=0.43..725439.44 rows=571566 width=8) (actual time=0.689..2417.176 rows=573130 loops=3)\n",
      "                                                        Filter: ((o_orderdate >= '1993-10-01'::date) AND (o_orderdate < '1994-01-01 00:00:00'::timestamp without time zone))\n",
      "                                                        Rows Removed by Filter: 14426125\n",
      "                                      ->  Index Scan using customer_pkey on customer  (cost=0.43..74794.43 rows=1500000 width=147) (actual time=0.676..187.512 rows=1499992 loops=3)\n",
      "                                ->  Memoize  (cost=0.15..2.17 rows=1 width=108) (actual time=0.000..0.000 rows=1 loops=1147084)\n",
      "                                      Cache Key: customer.c_nationkey\n",
      "                                      Cache Mode: logical\n",
      "                                      Hits: 390196  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                                      Worker 0:  Hits: 377590  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                                      Worker 1:  Hits: 379223  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                                      ->  Index Scan using nation_pkey on nation  (cost=0.14..2.16 rows=1 width=108) (actual time=0.006..0.006 rows=1 loops=75)\n",
      "                                            Index Cond: (n_nationkey = customer.c_nationkey)\n",
      "Planning Time: 24.361 ms\n",
      "Execution Time: 29405.989 ms\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = off;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = off;\")\n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we note that here we get better results using index scan and not bitmapscan.\n",
    "\n",
    "We can see that we get a small improvement using the index on l_returnflag, but the index on orderdate is not used because of the query definition, so we drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(\"DROP INDEX idx_o_orderdate;\")\n",
    "    cur.execute(\"DROP INDEX idx_l_orderkey;\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort  (cost=34913159.69..34914554.56 rows=557947 width=279) (actual time=28433.389..28484.250 rows=381105 loops=1)\n",
      "  Sort Key: (sum((lineitem.l_extendedprice * ('1'::numeric - lineitem.l_discount)))) DESC\n",
      "  Sort Method: external merge  Disk: 71032kB\n",
      "  ->  Finalize GroupAggregate  (cost=34545629.72..34714962.30 rows=557947 width=279) (actual time=26959.210..28041.918 rows=381105 loops=1)\n",
      "        Group Key: customer.c_custkey, nation.n_name\n",
      "        ->  Gather Merge  (cost=34545629.72..34703338.40 rows=464956 width=279) (actual time=26959.202..27758.215 rows=451144 loops=1)\n",
      "              Workers Planned: 2\n",
      "              Workers Launched: 2\n",
      "              ->  Partial GroupAggregate  (cost=34544629.70..34648670.92 rows=232478 width=279) (actual time=26931.973..27693.280 rows=150381 loops=3)\n",
      "                    Group Key: customer.c_custkey, nation.n_name\n",
      "                    ->  Incremental Sort  (cost=34544629.70..34642858.97 rows=232478 width=259) (actual time=26931.954..27488.675 rows=382361 loops=3)\n",
      "                          Sort Key: customer.c_custkey, nation.n_name\n",
      "                          Presorted Key: customer.c_custkey\n",
      "                          Full-sort Groups: 11731  Sort Method: quicksort  Average Memory: 32kB  Peak Memory: 32kB\n",
      "                          Worker 0:  Full-sort Groups: 11437  Sort Method: quicksort  Average Memory: 31kB  Peak Memory: 31kB\n",
      "                          Worker 1:  Full-sort Groups: 11368  Sort Method: quicksort  Average Memory: 32kB  Peak Memory: 32kB\n",
      "                          ->  Nested Loop  (cost=34544629.31..34632397.46 rows=232478 width=259) (actual time=26931.534..27378.865 rows=382361 loops=3)\n",
      "                                ->  Merge Join  (cost=34544629.16..34626660.10 rows=232478 width=159) (actual time=26931.245..27279.099 rows=382361 loops=3)\n",
      "                                      Merge Cond: (orders.o_custkey = customer.c_custkey)\n",
      "                                      ->  Sort  (cost=34544628.62..34545209.81 rows=232478 width=16) (actual time=26930.679..26957.099 rows=382361 loops=3)\n",
      "                                            Sort Key: orders.o_custkey\n",
      "                                            Sort Method: external merge  Disk: 10512kB\n",
      "                                            Worker 0:  Sort Method: external merge  Disk: 10248kB\n",
      "                                            Worker 1:  Sort Method: external merge  Disk: 10184kB\n",
      "                                            ->  Merge Join  (cost=33760239.00..34519931.00 rows=232478 width=16) (actual time=23526.203..26700.935 rows=382361 loops=3)\n",
      "                                                  Merge Cond: (lineitem.l_orderkey = orders.o_orderkey)\n",
      "                                                  ->  Sort  (cost=33760235.51..33775488.22 rows=6101082 width=16) (actual time=23515.301..23953.964 rows=4936061 loops=3)\n",
      "                                                        Sort Key: lineitem.l_orderkey\n",
      "                                                        Sort Method: external merge  Disk: 143152kB\n",
      "                                                        Worker 0:  Sort Method: external merge  Disk: 138936kB\n",
      "                                                        Worker 1:  Sort Method: external merge  Disk: 138456kB\n",
      "                                                        ->  Parallel Index Scan using idx_l_returnflag on lineitem  (cost=0.56..32864087.24 rows=6101082 width=16) (actual time=0.301..21304.691 rows=4936061 loops=3)\n",
      "                                                              Index Cond: (l_returnflag = 'R'::bpchar)\n",
      "                                                  ->  Index Scan using orders_pkey on orders  (cost=0.43..725439.44 rows=571566 width=8) (actual time=0.332..2414.042 rows=573137 loops=3)\n",
      "                                                        Filter: ((o_orderdate >= '1993-10-01'::date) AND (o_orderdate < '1994-01-01 00:00:00'::timestamp without time zone))\n",
      "                                                        Rows Removed by Filter: 14426361\n",
      "                                      ->  Index Scan using customer_pkey on customer  (cost=0.43..74794.43 rows=1500000 width=147) (actual time=0.550..190.292 rows=1499982 loops=3)\n",
      "                                ->  Memoize  (cost=0.15..2.17 rows=1 width=108) (actual time=0.000..0.000 rows=1 loops=1147084)\n",
      "                                      Cache Key: customer.c_nationkey\n",
      "                                      Cache Mode: logical\n",
      "                                      Hits: 389723  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                                      Worker 0:  Hits: 379698  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                                      Worker 1:  Hits: 377588  Misses: 25  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n",
      "                                      ->  Index Scan using nation_pkey on nation  (cost=0.14..2.16 rows=1 width=108) (actual time=0.012..0.012 rows=1 loops=75)\n",
      "                                            Index Cond: (n_nationkey = customer.c_nationkey)\n",
      "Planning Time: 2.029 ms\n",
      "Execution Time: 28523.779 ms\n"
     ]
    }
   ],
   "source": [
    "explain_analyze(query_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate and record the size of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: \n",
      " (1237537, 'Customer#001237537', Decimal('884989.6657'), Decimal('7840.17'), 'RUSSIA                   ', 'FNG6WgB1mopyyY,ajQTU qUPW5o', '32-367-120-4327', 'nag carefully about the regular packages. carefully reg')\n",
      "Size of query_10 result table: 78.5078125 MB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(f\"CREATE TEMP TABLE temp_result AS {query_10};\")\n",
    "    cur.execute(\"SELECT * FROM temp_result;\")\n",
    "    result = cur.fetchone()\n",
    "    print(f\"First row: \\n {result}\")\n",
    "    cur.execute(\"SELECT pg_total_relation_size('temp_result');\")\n",
    "    size = cur.fetchall()\n",
    "    print(f\"Size of query_10 result table: {size[0][0]/(1024**2)} MB\")\n",
    "    cur.execute(\"DROP TABLE temp_result;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shipdate is selective and we know that we have already an index on it, so we can leverage it \n",
    "\n",
    "we know we have a btree index in p_partkey\n",
    "\n",
    "since l_partkey will be fundamental for the next query, we can create now the index and check if it helps/is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate  (cost=1752182.01..1752182.03 rows=1 width=32) (actual time=20325.198..20325.602 rows=1 loops=1)\n",
      "  ->  Merge Join  (cost=1627703.71..1737877.17 rows=817419 width=33) (actual time=19561.520..20119.528 rows=749223 loops=1)\n",
      "        Merge Cond: (part.p_partkey = lineitem.l_partkey)\n",
      "        ->  Index Scan using part_pkey on part  (cost=0.43..92913.43 rows=2000000 width=25) (actual time=0.861..266.734 rows=1999994 loops=1)\n",
      "        ->  Sort  (cost=1627702.87..1629746.42 rows=817419 width=16) (actual time=19560.646..19620.759 rows=749223 loops=1)\n",
      "              Sort Key: lineitem.l_partkey\n",
      "              Sort Method: external sort  Disk: 24288kB\n",
      "              ->  Gather  (cost=12155.11..1533457.40 rows=817419 width=16) (actual time=85.373..18451.143 rows=749223 loops=1)\n",
      "                    Workers Planned: 2\n",
      "                    Workers Launched: 2\n",
      "                    ->  Parallel Bitmap Heap Scan on lineitem  (cost=11155.11..1450715.50 rows=340591 width=16) (actual time=74.458..18929.124 rows=249741 loops=3)\n",
      "                          Recheck Cond: ((l_shipdate >= '1995-09-01'::date) AND (l_shipdate < '1995-10-01 00:00:00'::timestamp without time zone))\n",
      "                          Rows Removed by Index Recheck: 6279649\n",
      "                          Heap Blocks: exact=14079 lossy=116636\n",
      "                          ->  Bitmap Index Scan on idx_l_shipdate  (cost=0.00..10950.76 rows=817419 width=0) (actual time=76.185..76.185 rows=749223 loops=1)\n",
      "                                Index Cond: ((l_shipdate >= '1995-09-01'::date) AND (l_shipdate < '1995-10-01 00:00:00'::timestamp without time zone))\n",
      "Planning Time: 3.890 ms\n",
      "Execution Time: 20331.197 ms\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = on;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = on;\")\n",
    "    cur.execute(\"SET enable_mergejoin = on;\")\n",
    "    cur.execute(\"SET enable_hashjoin = off;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    cur.execute(\"SET enable_hashagg = on;\")\n",
    "    \n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate and record size result table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: \n",
      " (Decimal('16.6475949416150953'),)\n",
      "Size of query_14 result table: 0.015625 MB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(f\"CREATE TEMP TABLE temp_result AS {query_14};\")\n",
    "    cur.execute(\"SELECT * FROM temp_result;\")\n",
    "    result = cur.fetchone()\n",
    "    print(f\"First row: \\n {result}\")\n",
    "    cur.execute(\"SELECT pg_total_relation_size('temp_result');\")\n",
    "    size = cur.fetchall()\n",
    "    print(f\"Size of query_14 result table: {size[0][0]/(1024**2)} MB\")\n",
    "    cur.execute(\"DROP TABLE temp_result;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This query takes a lot of time if we don't use indexes.\n",
    "\n",
    "The index on l_partkey is fundamental.\n",
    "\n",
    "We tried hash indexes on p_brand and p_container but they are not used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create idx_l_partkey ON lineitem (l_partkey): 144.65980434417725 seconds\n",
      "Size of idx_l_partkey: 416.328125 MB\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    #cur.execute(\"CREATE EXTENSION IF NOT EXISTS btree_gin;\") # otherwise it doesn't work\n",
    "    cur.execute(\"CREATE INDEX idx_l_partkey ON lineitem USING gin (l_partkey);\")    \n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create idx_l_partkey ON lineitem (l_partkey): {end_time - start_time} seconds\")\n",
    "    cur.execute(\"SELECT pg_relation_size('idx_l_partkey');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of idx_l_partkey: {index_size/(1024**2)} MB\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate  (cost=10797725.67..10797725.68 rows=1 width=32) (actual time=18863.726..18863.733 rows=1 loops=1)\n",
      "  ->  Nested Loop  (cost=20.06..10797675.63 rows=20015 width=8) (actual time=106.231..18862.449 rows=5526 loops=1)\n",
      "        ->  Seq Scan on part  (cost=0.00..70962.00 rows=2002 width=4) (actual time=24.950..349.157 rows=2044 loops=1)\n",
      "              Filter: ((p_brand = 'Brand#23'::bpchar) AND (p_container = 'MED BOX'::bpchar))\n",
      "              Rows Removed by Filter: 1997956\n",
      "        ->  Bitmap Heap Scan on lineitem  (cost=20.06..5357.89 rows=11 width=17) (actual time=8.713..9.056 rows=3 loops=2044)\n",
      "              Recheck Cond: (l_partkey = part.p_partkey)\n",
      "              Filter: (l_quantity < (SubPlan 1))\n",
      "              Rows Removed by Filter: 27\n",
      "              Heap Blocks: exact=61385\n",
      "              ->  Bitmap Index Scan on idx_l_partkey  (cost=0.00..20.06 rows=33 width=0) (actual time=0.531..0.531 rows=30 loops=2044)\n",
      "                    Index Cond: (l_partkey = part.p_partkey)\n",
      "              SubPlan 1\n",
      "                ->  Aggregate  (cost=157.74..157.75 rows=1 width=32) (actual time=0.274..0.274 rows=1 loops=61385)\n",
      "                      ->  Bitmap Heap Scan on lineitem lineitem_1  (cost=25.78..157.66 rows=33 width=5) (actual time=0.005..0.270 rows=31 loops=61385)\n",
      "                            Recheck Cond: (part.p_partkey = l_partkey)\n",
      "                            Heap Blocks: exact=1904213\n",
      "                            ->  Bitmap Index Scan on idx_l_partkey  (cost=0.00..25.77 rows=33 width=0) (actual time=0.003..0.003 rows=31 loops=61385)\n",
      "                                  Index Cond: (l_partkey = part.p_partkey)\n",
      "Planning Time: 75.572 ms\n",
      "Execution Time: 18960.725 ms\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = on;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = off;\")\n",
    "    cur.execute(\"SET enable_nestloop = on;\")\n",
    "    cur.execute(\"SET enable_mergejoin = on;\")\n",
    "    cur.execute(\"SET enable_hashjoin = off;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    cur.execute(\"SET enable_hashagg = on;\")\n",
    "    conn.commit()\n",
    "\n",
    "explain_analyze(query_17, analyze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"drop index idx_l_partkey;\") \n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create idx_l_partkey ON lineitem (l_partkey): 139.54524493217468 seconds\n",
      "Size of idx_l_partkey: 1896.65625 MB\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_l_partkey ON lineitem USING hash (l_partkey);\")    \n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create idx_l_partkey ON lineitem (l_partkey): {end_time - start_time} seconds\")\n",
    "    cur.execute(\"SELECT pg_relation_size('idx_l_partkey');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of idx_l_partkey: {index_size/(1024**2)} MB\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate  (cost=1937971.06..1937971.07 rows=1 width=32) (actual time=140288.301..140288.418 rows=1 loops=1)\n",
      "  ->  Hash Join  (cost=54687.22..1937921.02 rows=20015 width=8) (actual time=1004.053..140286.656 rows=5526 loops=1)\n",
      "        Hash Cond: (lineitem.l_partkey = part.p_partkey)\n",
      "        Join Filter: (lineitem.l_quantity < (SubPlan 1))\n",
      "        Rows Removed by Join Filter: 55859\n",
      "        ->  Seq Scan on lineitem  (cost=0.00..1724403.52 rows=59986052 width=17) (actual time=0.206..21705.621 rows=59986052 loops=1)\n",
      "        ->  Hash  (cost=54662.20..54662.20 rows=2002 width=4) (actual time=963.074..963.186 rows=2044 loops=1)\n",
      "              Buckets: 2048  Batches: 1  Memory Usage: 88kB\n",
      "              ->  Gather  (cost=1000.00..54662.20 rows=2002 width=4) (actual time=3.697..961.572 rows=2044 loops=1)\n",
      "                    Workers Planned: 2\n",
      "                    Workers Launched: 2\n",
      "                    ->  Parallel Seq Scan on part  (cost=0.00..53462.00 rows=834 width=4) (actual time=1.310..952.566 rows=681 loops=3)\n",
      "                          Filter: ((p_brand = 'Brand#23'::bpchar) AND (p_container = 'MED BOX'::bpchar))\n",
      "                          Rows Removed by Filter: 665985\n",
      "        SubPlan 1\n",
      "          ->  Aggregate  (cost=136.66..136.68 rows=1 width=32) (actual time=1.840..1.840 rows=1 loops=61385)\n",
      "                ->  Index Scan using idx_l_partkey on lineitem lineitem_1  (cost=0.00..136.58 rows=33 width=5) (actual time=0.138..1.836 rows=31 loops=61385)\n",
      "                      Index Cond: (l_partkey = part.p_partkey)\n",
      "Planning Time: 11.599 ms\n",
      "Execution Time: 140288.628 ms\n"
     ]
    }
   ],
   "source": [
    "explain_analyze(query_17, analyze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that the hash index is not useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"drop index idx_l_partkey;\") \n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create idx_l_partkey ON lineitem (l_partkey): 48.10466003417969 seconds\n",
      "Size of idx_l_partkey: 429.5078125 MB\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_l_partkey ON lineitem (l_partkey);\")    \n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create idx_l_partkey ON lineitem (l_partkey): {end_time - start_time} seconds\")\n",
    "    cur.execute(\"SELECT pg_relation_size('idx_l_partkey');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of idx_l_partkey: {index_size/(1024**2)} MB\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate  (cost=9428617.44..9428617.45 rows=1 width=32) (actual time=10267.602..10267.603 rows=1 loops=1)\n",
      "  ->  Nested Loop  (cost=0.87..9428567.40 rows=20015 width=8) (actual time=7.576..10266.618 rows=5526 loops=1)\n",
      "        ->  Index Scan using part_pkey on part  (cost=0.43..102913.43 rows=2002 width=4) (actual time=1.014..404.634 rows=2044 loops=1)\n",
      "              Filter: ((p_brand = 'Brand#23'::bpchar) AND (p_container = 'MED BOX'::bpchar))\n",
      "              Rows Removed by Filter: 1997956\n",
      "        ->  Index Scan using idx_l_partkey on lineitem  (cost=0.44..4658.06 rows=11 width=17) (actual time=4.590..4.824 rows=3 loops=2044)\n",
      "              Index Cond: (l_partkey = part.p_partkey)\n",
      "              Filter: (l_quantity < (SubPlan 1))\n",
      "              Rows Removed by Filter: 27\n",
      "              SubPlan 1\n",
      "                ->  Aggregate  (cost=137.10..137.11 rows=1 width=32) (actual time=0.148..0.148 rows=1 loops=61385)\n",
      "                      ->  Index Scan using idx_l_partkey on lineitem lineitem_1  (cost=0.44..137.02 rows=33 width=5) (actual time=0.001..0.145 rows=31 loops=61385)\n",
      "                            Index Cond: (l_partkey = part.p_partkey)\n",
      "Planning Time: 3.848 ms\n",
      "Execution Time: 10267.675 ms\n"
     ]
    }
   ],
   "source": [
    "explain_analyze(query_17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we get better results using btree index on l_partkey wrt btree+gin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create idx_p_brand ON part (p_brand): 0.5964438915252686 seconds\n",
      "Size of idx_p_brand: 3.140625 MB\n",
      "Size of idx_p_brand: 0.0030670166015625 GB\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_p_brand ON part USING gin (p_brand);\")    \n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create idx_p_brand ON part (p_brand): {end_time - start_time} seconds\")\n",
    "    cur.execute(\"SELECT pg_relation_size('idx_p_brand');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of idx_p_brand: {index_size/(1024**2)} MB\")\n",
    "    print(f\"Size of idx_p_brand: {index_size/(1024**3)} GB\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create idx_p_container ON part (p_container): 0.7287259101867676 seconds\n",
      "Size of idx_p_container: 3.765625 MB\n",
      "Size of idx_p_container: 0.0036773681640625 GB\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"CREATE INDEX idx_p_container ON part USING gin (p_container);\")    \n",
    "    end_time = time.time()\n",
    "    print(f\"Time to create idx_p_container ON part (p_container): {end_time - start_time} seconds\")\n",
    "    cur.execute(\"SELECT pg_relation_size('idx_p_container');\")\n",
    "    index_size = cur.fetchone()[0]\n",
    "    print(f\"Size of idx_p_container: {index_size/(1024**2)} MB\")\n",
    "    print(f\"Size of idx_p_container: {index_size/(1024**3)} GB\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate  (cost=9333134.47..9333134.48 rows=1 width=32) (actual time=10055.052..10055.054 rows=1 loops=1)\n",
      "  ->  Nested Loop  (cost=862.17..9333084.43 rows=20015 width=8) (actual time=33.863..10054.087 rows=5526 loops=1)\n",
      "        ->  Bitmap Heap Scan on part  (cost=861.73..7430.46 rows=2002 width=4) (actual time=27.656..45.512 rows=2044 loops=1)\n",
      "              Recheck Cond: ((p_container = 'MED BOX'::bpchar) AND (p_brand = 'Brand#23'::bpchar))\n",
      "              Heap Blocks: exact=1998\n",
      "              ->  BitmapAnd  (cost=861.73..861.73 rows=2002 width=0) (actual time=27.258..27.259 rows=0 loops=1)\n",
      "                    ->  Bitmap Index Scan on idx_p_container  (cost=0.00..323.66 rows=49000 width=0) (actual time=11.837..11.837 rows=50186 loops=1)\n",
      "                          Index Cond: (p_container = 'MED BOX'::bpchar)\n",
      "                    ->  Bitmap Index Scan on idx_p_brand  (cost=0.00..536.82 rows=81733 width=0) (actual time=13.332..13.332 rows=79826 loops=1)\n",
      "                          Index Cond: (p_brand = 'Brand#23'::bpchar)\n",
      "        ->  Index Scan using idx_l_partkey on lineitem  (cost=0.44..4658.06 rows=11 width=17) (actual time=4.685..4.896 rows=3 loops=2044)\n",
      "              Index Cond: (l_partkey = part.p_partkey)\n",
      "              Filter: (l_quantity < (SubPlan 1))\n",
      "              Rows Removed by Filter: 27\n",
      "              SubPlan 1\n",
      "                ->  Aggregate  (cost=137.10..137.11 rows=1 width=32) (actual time=0.151..0.151 rows=1 loops=61385)\n",
      "                      ->  Index Scan using idx_l_partkey on lineitem lineitem_1  (cost=0.44..137.02 rows=33 width=5) (actual time=0.001..0.148 rows=31 loops=61385)\n",
      "                            Index Cond: (l_partkey = part.p_partkey)\n",
      "Planning Time: 2.973 ms\n",
      "Execution Time: 10055.125 ms\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SET enable_seqscan = off;\")\n",
    "    cur.execute(\"SET enable_indexscan = on;\")\n",
    "    cur.execute(\"SET enable_bitmapscan = on;\")\n",
    "    cur.execute(\"SET enable_indexonlyscan = on;\")\n",
    "    cur.execute(\"SET enable_nestloop = on;\")\n",
    "    cur.execute(\"SET enable_mergejoin = on;\")\n",
    "    cur.execute(\"SET enable_hashjoin = off;\")\n",
    "    cur.execute(\"SET enable_sort = on;\")\n",
    "    cur.execute(\"SET enable_hashagg = on;\")\n",
    "    conn.commit()\n",
    "    \n",
    "explain_analyze(query_17, analyze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing with an index on l_partkey with gin wrt a btree the cost is \n",
    "\n",
    "Bitmap Heap Scan on lineitem  (cost=20.06..5357.89 rows=11 width=17) vs \n",
    "\n",
    "Index Scan using idx_l_partkey on lineitem  (cost=0.44..4658.06 rows=11 width=17)\n",
    "\n",
    "since also the creation time is better for l_partkey with btre and the sapce neded is similar: 416 mb vs 429 mb, we keep the index on l_shipdate with btree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the indexes on p_brand and p_container are not used, so we drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"DROP INDEX IF EXISTS idx_p_container;\")\n",
    "    cur.execute(\"DROP INDEX IF EXISTS idx_p_brand;\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Decimal('3295493.512857142857'),)\n",
      "Size of query_17 result table: 0.015625 MB\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "    \n",
    "    cur.execute(f\"CREATE TEMP TABLE temp_result AS {query_17};\")\n",
    "    cur.execute(\"SELECT * FROM temp_result;\")\n",
    "    result = cur.fetchall()\n",
    "    for row in result:\n",
    "        print(row)\n",
    "\n",
    "    cur.execute(\"SELECT pg_total_relation_size('temp_result');\")\n",
    "    size = cur.fetchall()\n",
    "    print(f\"Size of query_17 result table: {size[0][0]/(1024**2)} MB\")\n",
    "    cur.execute(\"DROP TABLE temp_result;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexes used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index Name: nation_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX nation_pkey ON public.nation USING btree (n_nationkey)\n",
      "\n",
      "Index Name: part_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX part_pkey ON public.part USING btree (p_partkey)\n",
      "\n",
      "Index Name: supplier_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX supplier_pkey ON public.supplier USING btree (s_suppkey)\n",
      "\n",
      "Index Name: customer_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX customer_pkey ON public.customer USING btree (c_custkey)\n",
      "\n",
      "Index Name: idx_l_shipdate\n",
      "Index Definition: CREATE INDEX idx_l_shipdate ON public.lineitem USING btree (l_shipdate)\n",
      "\n",
      "Index Name: idx_l_returnflag\n",
      "Index Definition: CREATE INDEX idx_l_returnflag ON public.lineitem USING btree (l_returnflag)\n",
      "\n",
      "Index Name: idx_l_partkey\n",
      "Index Definition: CREATE INDEX idx_l_partkey ON public.lineitem USING btree (l_partkey)\n",
      "\n",
      "Index Name: region_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX region_pkey ON public.region USING btree (r_regionkey)\n",
      "\n",
      "Index Name: partsupp_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX partsupp_pkey ON public.partsupp USING btree (ps_partkey, ps_suppkey)\n",
      "\n",
      "Index Name: orders_pkey\n",
      "Index Definition: CREATE UNIQUE INDEX orders_pkey ON public.orders USING btree (o_orderkey)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = ['nation', 'part', 'supplier', 'customer', 'lineitem', 'region', 'partsupp', 'orders']\n",
    "\n",
    "conn.rollback()\n",
    "for table in a:\n",
    "    check_indexes(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
